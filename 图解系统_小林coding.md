[toc]

### 1. 硬件结构

#### 1.1 CPU如何执行程序?
1. 计算机基本结构
    中央处理器，内存，输入设备，输出设备，总线
2. 中央处理器
   - 位宽:32位，64位
   - 寄存器
     - 通⽤寄存器，⽤来存放需要进⾏运算的数据
     - 程序计数器，⽤来存储 CPU 要执⾏下⼀条指令「所在的内存地址」
     - 指令寄存器，⽤来存放程序计数器指向的指令
3. 总线
   - 地址总线，⽤于指定 CPU 将要操作的内存地址
   - 数据总线，⽤于读写内存的数据
   - 控制总线，⽤于发送和接收信号，⽐如中断、设备复位等信号
4. 线路位宽与 CPU 位宽
   - 串行，并行
   - 线路位宽，避免低效率的串⾏传输的⽅式，线路的位宽最好⼀次就能访问到所有的内存地址，2^32=4G
   - CPU 的位宽不要⼩于线路位宽,32 位的 CPU 最好和 32 位宽的线路搭配
5. 程序执⾏的基本过程
   - ⼀个程序执⾏的时候， CPU 会根据程序计数器⾥的内存地址，从内存⾥⾯把需要执⾏
的指令读取到指令寄存器⾥⾯执⾏，然后根据指令⻓度⾃增，开始顺序读取下⼀条指令
   - 程序语言->汇编代码->机器码(通过汇编器)
   - 指令
     - 指令的内容是⼀串⼆进制数字的机器码
     - 不同的 CPU 有不同的指令集，也就是对应着不同的汇编语⾔和不同的机器码
     - 类型：数据传输类型，运算类型，跳转类型，信号类型，闲置类型
   - CPU 的指令周期
      Fetch（取得指令）-> Decode（指令译码）->  Execution（执⾏指令）-> Store（数据回写）
   - CPU 的时钟周期
      - 每⼀次脉冲信号⾼低电平的转换就是⼀个周期 
      - 1GHz，时钟频率为1G，时钟周期为1ns
   - CPU 的执行时间
     - CPU 的执行时间=CPU 时钟周期数（CPU Cycles）X 时钟周期时间（Clock Cycle Time）
     - CPU 时钟周期数=指令数 X 每条指令的平均时钟周期数(CPI)
     - 指令数:编译器优化
     - CPI:厂商优化
     - CCT:计算机主频
6. 32位和64位
   - 只有运算⼤数字的时候， 64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不⼤
   - 64 位 CPU 可以寻址更⼤的内存空间，32 位的寄存器存不下 64 位的指令
   - 硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽

#### 1.2 存储器金字塔
1. 存储器的层次结构
   - CPU 并不会直接和每⼀种存储器设备直接打交道，⽽是每⼀种存储器设备只和它相邻的存储器设备打交道
   - 目的
    缓存:依次寻找并取数据
   - 寄存器
    0.5CCT
   - CPU高速缓存(CPU Cache)
        SRAM静态随机存储器
        L1(数据缓存，指令缓存):1ns
        L2:4ns
        L3:20~60CCT
   - 内存
        DRAM动态随机存取存储器
        100ns
   - SSD/HDD
        SSD:150μs
        HDD:10ms

#### 1.3 写出让CPU跑得更快的代码
1. 计算密集型程序，写出能够配合 CPU Cache ⼯作机制的代码
2. CPU Cache 的数据结构和读取过程
   - 缓存块(CPU Line)
      - CPU Line 是 CPU从内存读取数据的基本单位
      - 数据结构
            索引，组标记，有效位，数据块
      - 字
            CPU读取CPU Cache不读取CPU Line中的整个数据块，而是读一个数据片段 
   - 直接映射 Cache（Direct Mapped Cache）
      - 内存块(Block)
            读取的时候我们要拿到数据所在内存块的地址
      - 直接映射
            使⽤「取模运算」，取模运算的结果就是内存块地址对应的 CPU Line（缓存块）的地址
      - 组标记（Tag）
            区别不同的内存块
      - 内存的访问地址
            包括组标记，CPU Line索引，偏移量
   - CPU从Cache加载内存地址对应的Cache中的数据
      -  没有对应的高速缓存地址，所以我们先要判断数据是否存储在cache内
      -  局部性原理，每一层Cache中都缓存最近使用的数据
        1. 根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Line 的地址
        2. 找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是⽆效的， CPU 就会直接访问内存，**并重新加载数据**，如果数据有效，则往下执⾏
        3. 对⽐内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话， CPU 就会直接访问内存，**并重新加载数据**，如果是的话，则往下执⾏
        4. 根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字

3. 提高缓存命中率
   - 缓存命中
      访问的数据在 CPU Cache 中的话，意味着缓存命中
   - 提升数据缓存的命中率
     - 对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升
     - 一般是64字节
   - 提升指令缓存的命中率
     - 对于指令缓存，有规律的条件分⽀语句能够让 CPU 的分⽀预测器发挥作⽤，进⼀步提⾼执⾏的效率
     - likey,unlikely宏
     - 例:先排序后遍历，循环命中次数多
   - 提升多核 CPU 的缓存命中率
     - 如果⼀个进程在不同核⼼来回切换，各个核⼼的缓存命中率就会受到影响，相反如果进程都在同⼀个核⼼上执⾏，那么其数据的 L1和 L2 Cache 的缓存命中率可以得到有效提⾼，缓存命中率⾼就意味着 CPU 可以减少访问 内存的频率
     - sched_setaffinity，把线程绑定在某⼀个 CPU 核⼼上
     - 例:同时执行多个计算密集型线程

#### 1.4 CPU缓存一致性
1. CPU Cache 的数据写⼊
   - 写入Cache后需同步内存中相对应的数据
   - 写直达（Write Through）
     - 把数据同时写⼊内存和 Cache 中
     - 如果数据已经在 Cache ⾥⾯，先将数据更新到 Cache ⾥⾯，再写⼊到内存⾥⾯（因为cache从内存中读取数据要同步）
     - 如果数据没有在 Cache ⾥⾯，就直接把数据更新到内存⾥⾯
     - 缺点：每次写操作都会写回到内存，花费大量时间
   - 写回（Write Back）
     - 如果当发⽣写操作时，数据已经在 CPU Cache ⾥的话，则把数据更新到 CPU Cache ⾥，同时标记CPU Cache ⾥的这个 Cache Block 为脏（Dirty）的代表这个时候，我们 CPU Cache⾥⾯的这个 Cache Block 的数据和内存是不⼀致的，不⽤把数据写到内存⾥
     - 如果当发⽣写操作时，数据所对应的 Cache Block ⾥存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block ⾥的数据有没有被标记为脏的，如果是脏的话，我们就要把这个 Cache Block⾥的数据写回到内存，然后再把当前要写⼊的数据，写⼊到这个 Cache Block ⾥，同时也把它标记为脏的；如果 Cache Block ⾥⾯的数据没有被标记为脏，则就直接将数据写⼊到这个 Cache Block⾥，然后再把这个 Cache Block 标记为脏的就好了
     - 写回这个⽅法，在把数据写⼊到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，⽽在缓存命中的情况下，则在写⼊后 Cache后，只需把该数据对应的 Cache Block 标记为脏即可，⽽不⽤写到内存⾥

2. 缓存一致性问题（Cache Coherence）
   - 不同核心之间由于写回策略导致的缓存内数据不一致的问题
   - 同步不同核心的缓存数据
     - 写传播（Write Propagation）
         某个 CPU 核⼼⾥的 Cache 数据更新时，必须要传播到其他核⼼的 Cache
     - 事务的串形化（Transaction Serialization）
         某个 CPU 核⼼⾥对数据的操作顺序，必须在其他核⼼看起来顺序是⼀样的
         如何实现:写传播；锁
   - 总线嗅探
     - 实现写传播的方式。修改数据时通过总线把这个事件⼴播通知给其他所有的核⼼，其CPU检查是否有相同的数据存储在L1 Cache中，没有则更新
     - 带宽压力大且不能保证事务串行化
   - MESI协议
     - Modified，已修改，即前文所述“标记为脏”
     - Exclusive，独占
     - Shared，共享
     - Invalidated，已失效
     - 流程
         只有A号CPU有i的数据，则A标记为独占，若B也要用i，则A,B被标记为共享，若A修改了数据，则A标为已修改，别的CPU标记为已失效，若继续修改A则A仍为已修改，但如果i对应的cache line要被替换，则会将数据同步到内存
     - 对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送⼴播给其他 CPU 核⼼，减去了总线带宽压力

#### 1.5 CPU如何执行任务
1. CPU伪共享（False Sharing）
   - 因为多个线程同时读写同⼀个 Cache Line 的不同变量时，⽽导致 CPU Cache 失效的现象
   - 对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同⼀个Cache Line
   - __cacheline_aligned_in_smp宏定义
   - Cache Line⼤⼩字节对⻬：避免 Cache 伪共享实际上是⽤空间换时间的思想，浪费⼀部分 Cache 空间，从⽽换来性能的提升
   - 字节填充：应用层面的规避方案: Java 并发框架 Disruptor 使⽤「字节填充 + 继承」

2. CPU如何选择线程
   - 进程和线程
     - tark_struct
         在 Linux 内核中，进程和线程都是⽤ tark_struct 结构体表示的
     - 区别
      在线程的 tark_struct 结构体⾥部分资源是共享了进程已创建的资源，⽐如内存地址空间、代码段、⽂件描述符等，所以Linux 中的线程也被称为轻量级进程
     - 主线程
      没有创建线程的进程，是只有单个执⾏流，被称为主线程
   - 任务
      Linux 内核⾥的调度器，调度的对象就是 tark_struct ，我们就把这个数据结构统称为任务
     - 实时任务
        对系统的响应时间要求很⾼，即优先级高，在0~99
     - 普通任务
        对系统的响应时间没有很高要求，优先级在100~139
   - 调度类
       确保高优先级的任务能够尽可能早的被执⾏
     - Dealine调度类（实时任务）
       - 调度器：Dealine调度器
       - 运行队列：dl_rq
       - 调度策略
         SCHED_DEADLINE，距离当前时间点最近的 deadline 的任务会被优先调度
     - Realtime调度类（实时任务）
       - 调度器：RT调度器
       - 运行队列：rt_rq
       - 调度策略
         SCHED_FIFO：相同优先级先来先服务，高优先级可以插队
         SCHED_RR：对于相同优先级的任务，轮流着运⾏，每个任务都有⼀定的时间⽚，当⽤完时间⽚的任务会被放到队列尾部，以保证相同优先级任务的公平性，但高优先级仍可以插队
     - Fair调度类（普通任务）日常遇到最多
       - 调度器：CFS调度器
       - 运行队列：cfs_rq
       - 调度策略
         SCHED_NORMAL：普通任务使⽤的调度策略；
         SCHED_BATCH：后台任务的调度策略，不和终端进⾏交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级
   - 完全公平调度（Completely Fair Scheduling）
     - 概念
         分配给每个任务的 CPU 时间是⼀样，各任务安排一个虚拟运行时间vruntime
         在 CFS 算法调度的时候，会优先选择 vruntime 少的任务，确保公平性
     - 权重值
         vruntime += 实际运行时间delta_exec *　NICE_0_LOAD　／　权重
         高权重优先调度，nice越低权重越高
   - 运⾏队列（Run Queue, rq）
     - Deadline 运⾏队列 dl_rq
     - 实时任务运⾏队列 rt_rq 
     - CFS 运⾏队列 csf_rq(红黑树描述)
     - 优先级： Deadline > Realtime > Fair,优先级如下： Deadline > Realtime > Fair
   - 调整优先级
     - 默认均为普通任务
     - nice值
         -20~19,表示优先级的修正数值
          priority(new) = priority(old) + nice，值越低，表明优先级越⾼
     - 设定启动任务nice值
         nice -n -3 /usr.sbin/mysqld
     - 修改运行任务nice值
         renice -10 -p <pid>
     - 修改调度策略及优先级
         chrt -f 1 -p <pid>    
      
#### 1.6 软中断
1. 中断
   - 定义
      中断是系统⽤来响应硬件设备请求的⼀种机制，操作系统收到硬件的中断请求，会打断正在执⾏的进程，然后调⽤内核中的中断处理程序来响应请求
   - 好处
      是⼀种异步的事件处理机制，可以提⾼系统的并发处理能⼒
   - 问题
     - 中断请求会打断其他进程的运行，所以中断处理程序要快以减少对正常进程的影响
     - 临时关闭中断，当前中断处理程序执行完之前，无法响应其他中断请求，所以要快
2. 软中断
   - 为了避免中断程序执行时间过长与中断丢失的问题，将中断分为上限部分
     - 上部分硬中断:直接处理硬件请求，负责耗时短的⼯作，特点是快速执⾏
     - 下部分软中断:由内核触发，负责上半部未完成的⼯作，通常都是耗时⽐较⻓的事情，特点是延迟执⾏
   - 软中断是以内核线程的⽅式执⾏，并且每⼀个 CPU 都对应⼀个软中断内核线程，其名字在中括号内
   - 例
      网络掉包，⼀些内核⾃定义事件也属于软中断，如内核调度，RCU锁
   - 查看软中断
     - /proc/interrupts 硬中断
     - /proc/softirqs 软中断
       - 每个CPU各有其不同类型软中断的累计运行次数，同一种中断在不同CPU中基本是同一数量级
       - 类型有
            NET_RX 表示⽹络接收中断
            NET_TX 表示⽹络发送中断
            TIMER 表示定时中断
            RCU 表示 RCU 锁中断
            SCHED 表示内核调度中断
     - 查看中断次数的变化速率
         watch -d cat /proc/softirqs
     - 查看软中断内核线程
         ps aux | grep softirq
3. 定位软中断CPU使用率过高的问题
   - top,si就是软中断上的使用率
       若CPU使⽤率最⾼的进程也是软中断ksoftirqd，这种⼀般可以认为系统的开销被软中断占据了
   - watch -d cat /proc/softirqs，查看每个软中断类型的中断次数的变化速率
   - 对于⽹络 I/O ⽐较⾼的 Web 服务器， NET_RX ⽹络接收中断的变化速率相对快很多
     - sar -n DEV查看网卡网络包接受速率
     - tcpdump抓包，分析包来源

#### 1.7 为什么0.1 + 0.2不等于0.3
1. 负数用补码表示的原因
   - int，最高位为符号位，其余31位表示二进制数据
   - 补码
      就是把正数的⼆进制全部取反再加1
   - 原因
      负数不是使⽤补码的⽅式表示，还需要多⼀步操作来判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转成加法。用补码的方式则和正数加减法一样
      节约性能
2. ⼗进制⼩数与⼆进制的转换
   - 乘2取整法
      8.625二进制表示为1000.101
   - 近似值表示
      0.1的二进制为0.0001100110....无限循环，所以只能近似值表示，造成精度缺失
   - 小数二进制转十进制幂为负
3. 计算机如何存储小数
   - 定点数
   - 浮点数
     - 规格化：1000.101表示为1.000101 x 2^3
     - 尾数：000101
         尾数的长度决定了这个数的精度
     - 指数：3
         指数位的长度决定了这个数的表达范围
     - IEEE标准：符号位 指数位 尾数
         同时定义二进制浮点数左侧有效位永远为1，作为固定隐含位不表示，节约了1位空间，提高了精度
     - 有效位
         包含整数部分和小数部分
     - 偏移量
         指数有正负，为了计算方便，实际存储指数时需把指数转换成无符号整数，float指数范围为-126~127，所以其偏移量为127
   - float
     - float尾数部分为23位，加上固定隐含位24位，所以精度在十进制中为log10(2^24)约等于7.22，其有效数字为7~8位，指数部分为8位
     - 转换公式：$(-1)^{符号位}*(1+尾数位)*2^{(指数-127)}$
4. 0.1 + 0.2 == 0.3?
   - 在计算机中 0.1 + 0.2 并不等于完整的 0.3,因为有的⼩数⽆法⽤「完整」的⼆进制来表示，所以计算机⾥只能采⽤近似数的⽅式来保存，那两个近似数相加，得到的必然也是⼀个近似数
   - 二进制只能准确表达2*除*尽的数字(即一直乘2可以得到整数)的值，但对于0.1，0.2等都无法准确表达，需要精度舍入


### 2. 操作系统结构

#### 2.1 Linux内核与Windows内核

1. 内核
   - 作用
      内核作为应⽤连接硬件设备的桥梁，应⽤程序只需关⼼与内核交互，不⽤关⼼硬件的细节
   - 功能
     - 进程调度的能⼒，管理进程、线程，决定哪个进程、线程使⽤ CPU
     - 内存管理的能⼒，管理内存，决定内存的分配和回收
     - 硬件通信能⼒，管理硬件设备，为进程与硬件设备之间提供通信能⼒
     - 提供系统调用，是⽤户程序与操作系统之间的接⼝
   - 内核空间和用户空间
      用户空间的代码只能访问⼀个局部的内存空间，⽽内核空间的代码可以访问所有内存空间  
   - 用户态和内核态
      内核程序执⾏在内核态，⽤户程序执⾏在⽤户态。当应⽤程序使⽤系统调⽤时，会产⽣⼀个中断。发⽣中断后， CPU 会中断当前在执⾏的⽤户程序，转⽽跳转到中断处理程序，也就是开始执⾏内核程序。内核处理完后，主动触发中断，把 CPU 执⾏权限交回给⽤户程序，回到⽤户态继续⼯作

2. Linux设计
   - 多任务MutiTask
      多任务意味着可以有多个任务同时执⾏，这⾥的「同时」可以是并发或并⾏
      - 并发
      对于单核 CPU 时，可以让每个任务执⾏⼀⼩段时间，时间到就切换另外⼀个任务，从宏观⻆度看，⼀段时间内执⾏了多个任务，这被称为并发
      - 并行
      对于多核 CPU 时，多个任务可以同时被不同核⼼的 CPU 同时执⾏，这被称为并⾏
   - 对称多处理SMP
       - 代表着每个 CPU 的地位是相等的，对资源的使⽤权限也是相同的，多个 CPU共享同⼀个内存，每个 CPU 都可以访问完整的内存和硬件资源
       - Linux 操作系统不会有某个 CPU 单独服务应⽤程序或内核程序，⽽是每个程序都可以被分配到任意⼀个 CPU 上被执⾏
   - 可执⾏⽂件链接格式ELF
       - Linux 操作系统中可执⾏⽂件的存储格式
       - 我们编写的代码，⾸先通过「编译器」编译成汇编代码，接着通过「汇编器」变成⽬标代码，也就是⽬标⽂件，最后通过「链接器」把多个⽬标⽂件以及调⽤的各种函数库链接起来，形成⼀个可执⾏⽂件即ELF⽂件。最好通过「装载器」把 ELF ⽂件装载到内存⾥， CPU 读取内存中的指令和数据，于是程序就被执⾏起来了
   - 宏内核Monolithic Kernel（Linux）
       - Linux 内核架构就是宏内核，是⼀个完整的可执⾏程序，且拥有最⾼的权限
       - 特征是系统内核的所有模块，⽐如进程调度、内存管理、⽂件系统、设备驱动等，都运⾏在内核态。也可以动态加载内核模块，如设备驱动可以和其他模块解耦
       - 微内核（鸿蒙系统）
         - 只保留最基本的能⼒，⽐如进程调度、虚拟机内存、中断等，把⼀些应⽤放到了⽤户空间，⽐如驱动程序、⽂件系统等
         - 服务与服务之间是隔离，提⾼了操作系统的稳定性和可移植性。但驱动和硬件设备交互就需要切换到内核态导致性能损失
       - 混合类型内核（Windows）
         是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有⼀个⼩型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序

3. Windows设计
   - 同样支持多任务和对称多处理
   - Window 的内核设计是混合型内核，内核中有⼀个 MicroKernel 模块
   - Windows 的可执⾏⽂件格式叫 PE，称为可移植执⾏⽂件，扩展名通常是.exe、.dll、.sys等

### 3. 内存管理

#### 3.1 虚拟内存
1. 虚拟内存
   - 原因
      绝对物理地址会导致不能同时运行多个程序(单片机)，让操作系统为每个进程分配独⽴的⼀套「虚拟地址」，可以把进程所使⽤的地址「隔离」
   - 虚拟内存地址（Virtual Memory Address）
      程序所使⽤的内存地址
   - 物理内存地址（Physical Memory Address）
      实际存在硬件⾥⾯的空间地址
   - 过程
      进程持有的虚拟地址会通过 CPU 芯⽚中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存
   - 如何映射
      内存分段和内存分⻚
2. 内存分段
   - 段
   程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。 不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来
   - 虚拟地址
      由两部分组成， 段选择⼦和段内偏移量
   - 段选择子
      在段寄存器中，由段号，特权等标志位
      - 段号
         段表的索引
      - 段表
         保存段的基地址，段的界限和特权等级
   - 段内偏移量
      介于0和段界限之间，段基地址加上段内偏移量得到物理内存地址
   - 流程
      通过虚拟地址中的段号找到段表中对应的基地址，再加上段内偏移量就可得到物理内存地址
   - 缺点
     - 内存碎片
       - 外部内存碎片
         产⽣了多个不连续的⼩物理内存，导致新的程序⽆法被装载
       - 内部内存碎⽚
         程序所有的内存都被装载到了物理内存，但有部分的内存可能不常使⽤，导致内存的浪费
     - 内存交换
       - 用于解决外部碎片问题，先将程序所占内存读到硬盘上，再从硬盘读回内存，但需要装载再其他已占用的内存后，这就空出了连续的内存空间
       - 内存交换空间，硬盘内用于内存与硬盘的交换。如linux系统内Swap空间
       - 性能瓶颈，硬盘访问速度慢，若交换空间过大，会导致机器卡顿

#### 3.2 内存分页
1. 分页
   分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩。这样⼀个连续并且尺⼨固定的内存空间，我们叫⻚（Page）
2. 页表
   虚拟地址与物理地址之间通过⻚表来映射
3. 缺⻚异常
   当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个缺⻚异常，进⼊系统内核空间分配物理内存、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏
4. 解决内存碎片和内存交换空间太大的问题
   - 页之间可以不连续，采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存
   - 内存空间不够，系统通过换出（Swap Out），释放其他正在运⾏的进程中的「最近没被使⽤」的内存⻚⾯，需要的时候，再换⼊（Swap In）。⼀次性写⼊磁盘的也只有少数⼏个⻚，不会花太多时间， 内存交换的效率就相对⽐较⾼
   - 分⻚的⽅式使得我们在加载程序的时候，不再需要⼀次性都把程序加载到物理内存中。映射之后，只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再加载到物理内存⾥⾯去
5. 如何映射
  - 虚拟地址:页号，页内偏移
  - 页表：包含物理页每页所在物理内存基地址
  - 步骤
    - 把虚拟内存地址，切分成⻚号和偏移量
    - 根据⻚号，从⻚表⾥⾯，查询对应的物理⻚号
    - 物理⻚号，加上前⾯的偏移量，就得到了物理内存地址
6. 简单分页缺陷
   有空间上的缺陷：
   32位，虚拟内存地址有4GB(2^32)，页大小为4KB(2^12)，需要100万(2^20)个页，每个页表项需要4byte，则需要4MB内存存储一个线程的页表。100个线程则需要400MB内存，开销非常大
7. 多级页表
   - ⻚表（⼀级⻚表）分为 1024 个⻚表（⼆级⻚表），每个表（⼆级⻚表）中包含 1024 个「⻚表项」，形成⼆级分⻚
   - 映射 4GB 地址空间就需要 4KB（⼀级⻚表） + 4MB（⼆级⻚表）的内存，占用空间更大？
     - 往往不会为⼀个进程分配那么多内存
     - 局部性原理
         如果使⽤了⼆级分⻚，⼀级⻚表（4kb）就可以覆盖整个 4GB 虚拟地址空间，但如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即可以在需要时才创建⼆级⻚表。若只有20%一级页表项被使用，则消耗内存空间为:4KB（⼀级⻚表） + 20% * 4MB（⼆级⻚表） = 0.804MB <<4MB
   - 单极页表无法节约内存
      ⻚表⼀定要覆盖全部虚拟地址空间，虚拟地址在⻚表中找不到对应的⻚表项，计算机系统无法工作。不分级的⻚表就需要有 100 多万个⻚表项来映射，⽽⼆级分⻚则只需要 1024 个⻚表项（此时⼀级⻚表覆盖到了全部虚拟地址空间，⼆级⻚表在需要时创建）
   - 64位系统：四级目录
      - 全局⻚⽬录项 PGD（Page Global Directory）
      - 上层⻚⽬录项 PUD（Page Upper Directory）
      - 中间⻚⽬录项 PMD（Page Middle Directory）
      - ⻚表项 PTE（Page Table Entry）
   - ⻚表缓存TLB（Translation Lookaside Buffer）
     - 多级页表节约空间但由于多层的地址转换降低了虚拟地址到物理地址转换的效率，增加了时间开销
     - 程序具有局部性，⼀段时间内，整个程序的执⾏仅限于程序中的某⼀部分。相应地，执⾏所访问的存储空间也局限于某个内存区域
     - 最常访问的⼏个⻚表项存储到访问速度更快的硬件Cache，即页表缓存
     - CPU内内存管理单元（Memory Management Unit）芯⽚，它⽤来完成地址转换和 TLB的访问与交互。CPU寻址时先查TLB再查常规页表
     - TLB命中率很高，程序最常访问的⻚并不多
8. 段⻚式内存管理
   - 实现方式
     - 先将程序划分为多个有逻辑意义的段
     - 接着再把每个段划分为多个⻚，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚，页在段内可以不连续
   - 地址结构：段号、段内⻚号和⻚内位移
   - 三次内存访问
     - 第⼀次访问段表，通过段号得到⻚表起始地址
     - 第⼆次访问⻚表，通过页号得到物理⻚号
     - 第三次将物理⻚号与⻚内位移组合，得到物理地址
   - 增加了硬件成本和系统开销，但提⾼了内存的利⽤率
9. Linux内存管理
   - 各种地址
     - 逻辑地址，程序所使⽤的地址，通常是没被段式内存管理映射的地址
     - 线性地址(虚拟地址)通过段式内存管理映射的地址
   - Linux 内存主要采⽤的是⻚式内存管理,但由于Intel处理器发展历史，先段后页
   - 使段式映射不起作用
    把所有段的基地址设为 0 ，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被⽤于访问控制和内存保护
   - 内核空间和用户空间
     - 32位：1G，3G；64位：128T，128T，其余未定义
     - 进程在⽤户态时，只能访问⽤户空间内存
     - 进程在内核态后，才可以访问内核空间的内存
     - 每个进程都各⾃有独⽴的虚拟内存，但每个虚拟内存中的内核地址，其实关联的都是相同的物理内存，即共有同一内核空间
   - 用户空间内存，由低到高7种不同内存段
     - 程序⽂件段，包括⼆进制可执⾏代码
     - 已初始化数据段，包括静态常量
     - 未初始化数据段，包括未初始化的静态变量
     - 堆段，包括动态分配的内存，malloc()
     - ⽂件映射段，包括动态库、共享内存等mmap()
     - 栈段，包括局部变量和函数调⽤的上下⽂等。栈的⼤⼩是固定的，⼀般是 8 MB,也可自定义
  
### 4. 进程与线程

#### 4.1 基础知识
1. 进程
   - 进程
      静态文件编译后形成二进制可执行文件，运行后被装载至内存，CPU执行其命令，这个运行中的程序被称为进程
   - 并发和并行
      - 例:有⼀个会读取硬盘⽂件数据的程序被执⾏，读取⽂件时，由于硬盘的读写速度⾮常慢，CPU 不需要阻塞等待数据的返回，⽽是去执⾏另外的进程。当硬盘数据返回时， CPU 会收到个中断，于是 CPU 再继续运⾏这个进程
      - 多个程序、交替执⾏
   - 进程的状态
     - 创建状态（new）：进程正在被创建时的状态
     - 运⾏状态（Runing）：该时刻进程占⽤ CPU
     - 就绪状态（Ready）：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏
     - 阻塞状态（Blocked）/等待态/睡眠态：该进程正在等待某⼀事件发⽣（如等待输⼊/输出操作的完成）⽽暂时停⽌运⾏，这时，即使给它CPU控制权，它也⽆法运⾏
     - 结束状态（Exit）：进程正在从系统中消失时的状态
     - 挂起状态：描述进程没有占⽤实际的物理内存空间的情况
       - 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现
       - 就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏
       - 若有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运⾏的时候，再从硬盘换⼊到物理内存
       - 导致进程挂起的原因
         - 进程所使⽤的内存空间不在物理内存
         - 通过 sleep 让进程间歇性挂起
         - ⽤户希望挂起⼀个程序的执⾏，如Ctrl + Z
   - 进程的控制结构
     - 进程控制块PCB
       - PCB 是进程存在的唯⼀标识
       - 进程描述信息
         - 进程标识符：标识各个进程，每个进程都有⼀个并且唯⼀的标识符
         - ⽤户标识符：进程归属的⽤户，⽤户标识符主要为共享和保护服务
       - 进程控制和管理信息
         - 进程当前状态，如 new、 ready、 running、 waiting 或 blocked
         - 进程优先级：进程抢占 CPU 时的优先级
       - 资源分配清单
         - 有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使⽤的 I/O 设备信息
       - CPU 相关信息
         - CPU 中各个寄存器的值，当进程被切换时， CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执⾏时，能从断点处继续执⾏
     - PCB组织方式
       - 通过链表的⽅式进⾏组织，把具有相同状态的进程链在⼀起，组成各种队列
         - 就绪队列
         - 阻塞队列
         - 单核CPU只有一个运行指针
       - 索引方式
         - 索引表：同⼀状态的进程组织在⼀个索引表，索引表项指向相应的 PCB，不同状态对应不同的索引表
         - 因为进程增删操作多，所以一般采用链表
   - 进程的控制
     - 创建进程
       - 子进程继承父进程资源，终止时交还资源。终止父进程会同时终止所有子进程。但在具体操作系统中，有各自的实现方式。如Linux会把子进程交给1号进程
       - 分配PCB,PCB有限，无则创建失败
       - 分配资源，没有则进入等待状态
       - 初始化PCB
       - PCB插入就绪队列
     - 终止进程
       - 查找PCB
       - 终止执行，将CPU资源分配给其他进程
       - 终止子进程，交还资源给父进程
       - 从PCB队列中删除
     - 阻塞进程
       - 只能由另⼀个进程唤醒,有阻塞语句必有对应的唤醒语句
       - 查找PCB
       - 保护其线程，转为阻塞状态
       - PCB插入阻塞队列
     - 唤醒进程
       - 从阻塞队列中查找PCB
       - 移出并转为就绪状态
       - 插入就绪队列等待调度
   - 进程的上下文切换
     - CPU 上下⽂
         CPU 寄存器和程序计数器是 CPU 在运⾏任何任务前，所必须依赖的环境，称为CPU上下文
     - 上下文切换
         先把前⼀个任务的 CPU 上下⽂（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下⽂到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运⾏新任务
     - 切换内容
         进程是由内核管理和调度的，所以进程的切换只能发⽣在内核态。进程的上下⽂切换不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。这些信息都保存在PCB中
     - 切换场景
       - 公平调度时，一个进程时间片耗尽切换下一个进程
       - 系统资源不⾜（⽐如内存不⾜）时，要等到资源满⾜后才可以运⾏，这个时候进程也会被挂起，并由系统调度其他进程运⾏
       - sleep主动挂起
       - 调用高优先级进程
       - 硬件中断，中断挂起

2. 线程
   - 单进程和多进程的缺点
     - 单进程:函数之间不是并发执⾏，影响资源的使⽤效率
     - 多进程:进程之间如何通信，共享数据；维护进程的系统开销较⼤；
   - 线程
     - 线程是进程当中的⼀条执⾏流程
     - 线程之间可以并发运⾏且共享相同的地址空间，但每个线程各⾃都有⼀套独⽴的寄存器和栈，这样可以确保线程的控制流是相对独⽴的
     - 优点
       - ⼀个进程中可以同时存在多个线程
       - 各个线程之间可以并发执⾏
       - 各个线程之间可以共享地址空间和⽂件等资源
     - 缺点
       - 当进程中的⼀个线程崩溃时，会导致其所属进程的所有线程崩溃
       - 例：游戏的用户设计不应该使用多线程
   - 线程与进程的比较
     - 线程的创建时间⽐进程快，因为线程创建时不涉及资源管理信息而是共享它们，但进程需要
     - 线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多
     - 同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同⼀个进程的线程都具有同⼀个⻚表，切换时不需要切换⻚表。⽽对于进程，切换的时候要切换⻚表，⽽⻚表的切换过程开销是⽐较⼤的
     - 由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼
     - 最大区别:线程是调度的基本单位，⽽进程则是资源拥有的基本单0位
   - 线程的上下文切换
     - 线程和进程
       - 当进程只有⼀个线程时，可以认为进程就等于线程
       - 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下⽂切换时是不需要修改的
       - 线程也有⾃⼰的私有数据，⽐如栈和寄存器等，这些在上下⽂切换时也是需要保存的
     - 线程上下⽂切换的内容
       - 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样
       - 当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据
   - 线程的实现
     - 用户线程（User Thread） 
       - 在⽤户空间实现的线程，不是由内核管理的线程，是由⽤户态的线程库来完成线程的管理；
       - 多对⼀的关系，也就是多个⽤户线程对应同⼀个内核线程
       - 线程控制块（Thread Control Block, TCB） 也是在库⾥实现，操作系统看不到TCB只能看到整个进程的PCB
       - ⽤户线程的整个线程管理和调度，操作系统是不直接参与的，⽽是由⽤户级线程库函数来完成线程的管理，包括线程的创建、终⽌、同步和调度等
       - 优点
         - TCB 由⽤户级线程库函数来维护，可⽤于不⽀持线程技术的操作系统
         - ⽤户线程的切换也是由线程库函数来完成的，⽆需⽤户态与内核态的切换，时间开销小
       - 缺点
         - 操作系统无法管理用户线程，所以线程因发起系统调用而阻塞，进程其他用户线程都无法执行。并且当线程开始运行后，除非其主动交出CPU使用权，否则其他线程无法运行
         - 分配给每个进程的时间片一样，所以多线程执⾏时，每个线程得到的时间⽚较少，执⾏会⽐较慢
     - 内核线程（Kernel Thread）
       - 在内核中实现的线程，是由内核管理的线程
       - ⼀对⼀的关系，即⼀个⽤户线程对应⼀个内核线程
       - 优点
         - 在⼀个进程当中，如果某个内核线程发起系统调⽤⽽被阻塞，并不会影响其他内核线程的运⾏
         - 分配给线程，多线程的进程获得更多的 CPU 运⾏时间
       - 缺点
         - 需要支持线程技术的操作系统，由内核来维护进程和线程的上下⽂信息，如PCB和TCB
         - 线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，系统开销⽐较⼤
     - 轻量级进程（Light-weight process， LWP）
       - 是内核⽀持的⽤户线程，⼀个进程可有⼀个或多个 LWP，每个 LWP 是跟内核线程⼀对⼀映射的，也就是 LWP 都是由⼀个内核线程⽀持
       - LWP与普通进程的区别也在于它只有⼀个最⼩的执⾏上下⽂和调度程序所需的统计信息。LWP代表程序的执行线程，不需要那么多状态信息
       - 1 : 1 模式，即⼀个 LWP 对应 ⼀个⽤户线程
         - 优点：实现并⾏，当⼀个 LWP 阻塞，不会影响其他 LWP
         - 缺点：每⼀个⽤户线程，就产⽣⼀个内核线程，创建线程的开销较⼤
       - N : 1 ，即⼀个 LWP 对应多个⽤户线程
         - 优点：⽤户线程要开⼏个都没问题，且上下⽂切换发⽣⽤户空间，切换的效率较⾼
         - 缺点：⼀个⽤户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，**无法充分利⽤CPU**
       - M : N ，即多个 LMP 对应多个⽤户线程
         - 优点：综合了前两种优点，⼤部分的线程上下⽂发⽣在⽤户空间，且多个线程⼜可以充分利⽤多核CPU的资源
         - 线程是可以在多个不同CPU内并行执行，LWP为执行线程，当然LWP内的线程就必须在同一CPU内
       - 组合模式：结合以上模型，针对不同的应⽤特点调节内核线程的数⽬来达到物理并⾏性（并行）和逻辑并⾏性（并发）的最佳⽅案

3. 调度
   - 选择⼀个进程运⾏这⼀功能是在操作系统中完成的，通常称为调度程序（scheduler）
   - 调度时机
     - 根据状态的变化
       - 从就绪态 -> 运⾏态：当进程被创建时，会进⼊到就绪队列，操作系统会从就绪队列选择⼀个进程运⾏；
       - 从运⾏态 -> 阻塞态：当进程发⽣ I/O 事件⽽阻塞时，操作系统必须另外⼀个进程运⾏；
       - 从运⾏态 -> 结束态：当进程退出结束后，操作系统得从就绪队列选择另外⼀个进程运⾏；
     - 根据如何处理时钟中断
       - ⾮抢占式调度算法挑选⼀个进程，然后让该进程运⾏直到被阻塞，或者直到该进程退出，才会调⽤另外⼀个进程，不理会时钟中断
       - 抢占式调度算法挑选⼀个进程，然后让该进程只运⾏某段时间，如果在该时段结束时，该进程仍然在运⾏时，则会把它挂起，接着调度程序从就绪队列挑选另外⼀个进程。这种抢占式调度处理，需要在时间间隔的末端发⽣时钟中断，以便把 CPU 控制返回给调度程序进⾏调度，也就是常说的时间⽚机制
   - 调度原则
     - CPU 利⽤率：调度程序应确保 CPU 是始终匆忙的状态，这可提⾼ CPU 的利⽤率
     - 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，⻓作业的进程会占⽤较⻓的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量
     - 周转时间：周转时间是进程运⾏和阻塞时间总和，⼀个进程的周转时间越⼩越好
     - 等待时间：这个等待时间不是阻塞状态的时间，⽽是进程处于就绪队列的时间，等待的时间越⻓，⽤户越不满意
     - 响应时间：⽤户提交请求到系统第⼀次产⽣响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准
   - 调度算法
     - 在单核 CPU 系统中常⻅的调度算法
     - 先来先服务调度算法（First Come First Seved, FCFS）
       - 每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个进程接着运⾏
       - FCFS 对⻓作业有利，适⽤于 CPU 繁忙型作业的系统，⽽不适⽤于 I/O 繁忙型作业的系统。i/o型作业执行时，要经常i/o,它一i/o，就要放弃cpu，到队尾重新排队。而计算型作业一旦得到cpu，就能一直执行。
     - 最短作业优先调度算法（Shortest Job First, SJF）
       - 优先选择运⾏时间最短的进程来运⾏
       - 对于长作业不利
     - ⾼响应⽐优先调度算法（Highest Response Ratio Next, HRRN）
       - 每次把响应⽐优先级」最⾼的进程投⼊运⾏
       - 优先权 = (等待时间 + 要求服务时间)/要求服务时间
       - 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应⽐」就越⾼，这样短作业的进程容易被选中运⾏
       - 如果两个进程「要求的服务时间」相同时，「等待时间」越⻓，「响应⽐」就越⾼，这就兼顾到了⻓作业进程，因为进程的响应⽐可以随时间等待的增加⽽提⾼，当其等待时间⾜够⻓时，其响应⽐便可以升到很⾼，从⽽获得运⾏的机会
     - 时间⽚轮转调度算法（Round Robin, RR）
       - 每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏，平权
       - 如果时间⽚⽤完，进程还在运⾏，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外⼀个进程
       - 如果该进程在时间⽚结束前阻塞或结束，则 CPU ⽴即进⾏切换
       - 如果时间⽚设得太短会导致过多的进程上下⽂切换，降低了 CPU 效率
       - 如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓
       - ⼀般来说，时间⽚设为 20ms~50ms
     - 最⾼优先级调度算法（Highest Priority First， HPF）
       - 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运⾏时间优先级都不会变化；
       - 动态优先级：随着时间的推移增加等待进程的优先级
       - ⾮抢占式：当就绪队列中出现优先级⾼的进程，运⾏完当前进程，再选择优先级⾼的进程
       - 抢占式：当就绪队列中出现优先级⾼的进程，当前进程挂起，调度优先级⾼的进程运⾏
       - 缺点:导致低优先级的进程永远不会运⾏
     - 多级反馈队列调度算法（Multilevel Feedback Queue,MFQ）
       - 「多级」表示有多个队列，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短
       - 「反馈」表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列
       - 如何工作
         - 「反馈」表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列
         - 新的进程会被放⼊到第⼀级队列的末尾，按先来先服务的原则排队等待被调度，如果在第⼀级队列规定的时间⽚没运⾏完成，则将其转⼊到第⼆级队列的末尾，以此类推，直⾄完成
         - 当较⾼优先级的队列为空，才调度较低优先级的队列中的进程运⾏。如果进程运⾏时，有新进程进⼊较⾼优先级的队列，则停⽌当前运⾏的进程并将其移⼊到原队列末尾，接着让较⾼优先级的进程运⾏
       - 优点
         对于短作业可能可以在第⼀级队列很快被处理完。对于⻓作业，如果在第⼀级队列处理不完，可以移⼊下次队列等待被执⾏，虽然等待的时间变⻓了，但是运⾏时间也变更⻓了，所以该算法很好的兼顾了⻓短作业，同时有较好的响应时间

#### 4.2 进程间通信
1. 通信需经过内核
  每个进程的⽤户地址空间都是独⽴的，⼀般⽽⾔是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核
2. 管道
  - 所谓的管道，就是内核⾥⾯的⼀串缓存。从管道的⼀段写⼊的数据，实际上是缓存在内核中的，另⼀端读取，也就是从内核中读取这段数据。另外，管道传输的数据是⽆格式的流且⼤⼩受限
  - 匿名管道
    - " | " ,没有名字，用完即销毁
    - 管道传输数据是单向的，通信需两个管道
    - FIFO
    - 创建
      - int pipe(int fd[2])
      - 返回了两个描述符，⼀个是管道的读取端描述符 fd[0] ，另⼀个是管道的写⼊端描述符 fd[1]
      - 匿名管道是特殊的⽂件，只存在于内存，不存于⽂件系统中
      - 如何跨进程通信
        - 父子进程之间的通信 
          fork 创建⼦进程， 创建的⼦进程会复制⽗进程的⽂件描述符，⽗进程关闭fd[0]保留fd[1]，⼦进程关闭fd[1]保留fd[0]。如果需要双向通信，则应创建两个管道
        - shell内的通信(A|B)
          A和B都是shell父进程创建的⼦进程，A开f[1]关f[0],B关f[1]开f[0]
          在 shell ⾥通过「 | 」匿名管道将多个命令连接在⼀起，实际上就是创建了多个⼦进程。使用时应减少管道使用数目，这样可以减少创建⼦进程的系统开销
  - 命名管道
    - mkfifo myPipe
    - FIFO
    - 命名管道，它可以在不相关的进程间也能相互通信。因为创建了设备文件
  - 优缺点
    - 优点：简单，容易得知管道内数据已被另一进程读取
    - 缺点：管道这种通信⽅式效率低，不适合进程间频繁地交换数据
3. 消息队列
  - 消息队列是保存在内核中的消息链表在发送数据时，会分成⼀个⼀个独⽴的数据单元，也就是消息体（数据块），消息体是⽤户⾃定义的数据类型，消息的发送⽅和接收⽅要约定好消息体的数据类型，所以每个消息体都是固定⼤⼩的存储块，不像管道是⽆格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除
  - A 进程要给 B 进程发送消息， A 进程把数据放在对应的消息队列后就可以正常返回了， B 进程需要的时候再去读取数据就可以了
  - 生命周期
    消息队列⽣命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会⼀直存在，⽽匿名管道的⽣命周期，是随进程的创建⽽建⽴，随进程的结束⽽销毁
  - 优缺点
    - 优点
      - 适合进程间频繁地交换数据
    - 缺点
      - ⼀是通信不及时，⼆是附件也有⼤⼩限制
      - 消息队列不适合⽐较⼤数据的传输，内核中每个消息体都有⼀个最⼤⻓度的限制，所有队列所包含的全部消息体的总⻓度也有上限。宏MSGMAX 和 MSGMNB。
      - 消息队列通信过程中，存在⽤户态与内核态之间的数据拷⻉开销，写入和读取都有用户态和内核态之间的拷贝
4. 共享内存
  - 共享内存的机制，就是每个进程的虚拟内存空间中拿出⼀块虚拟地址空间来，映射到相同的物理内存
  - 优点
    不需要用户态与内核态之间的拷⻉，信息共享，⼤⼤提⾼了进程间通信的速度
  - 缺点
    如果多个进程同时修改同⼀个共享内存，可能会发生冲突
5. 信号量
  - 目的
    为了防⽌多进程竞争共享资源，⽽造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被⼀个进程访问
  - 信号量的操作
    - 信号量其实是⼀个整型的计数器，主要⽤于实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据
    - 信号量表示资源的数量
    - P 操作，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占⽤，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使⽤，进程可正常继续执⾏
    - V 操作，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运⾏；相加后如果信号量 > 0，则表明当前没有阻塞中的进程
    - P 操作是⽤在进⼊共享资源之前， V 操作是⽤在离开共享资源之后，这两个操作必须成对出现
  - 互斥信号量，信号初始化为 1
  - 同步信号量，信号初始化为 0
      用于实现多进程同步。在多进程⾥，每个进程并不⼀定是顺序执⾏的，通过同步信号量保证进程 A 应在进程 B 之前执⾏
6. 信号
  - 目的
  上⾯说的进程间通信，都是常规状态下的⼯作模式。 对于异常情况下的⼯作模式，就需要⽤「信号」的⽅式来通知进程
  - kill -l
  - 信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）
    - Ctrl+C :SIGINT,表示终止
    - Ctrl+Z ：SIGTSTP，表示暂停
    - kill -9 PID：SIGKILL，表示立即结束(注意区别)
  - 信号是进程间通信机制中**唯⼀的异步通信机制**
  - ⽤户进程对信号的处理⽅式
    - 执⾏默认操作
    - 捕捉信号，为信号定义⼀个信号处理函数。当信号发⽣时，我们就执⾏相应的信号处理函数
    - 忽略信号，不希望处理某些信号。有两个信号是应⽤进程⽆法捕捉和忽略的，即 SIGKILL 和     SEGSTOP ，它们⽤于在任何时候中断或结束某⼀进程
7. _Socket_ 还没学会！
  - 目的
    跨⽹络与不同主机上的进程之间通信，也可以在同主机进程间通信
  - int socket(int domain, int type, int protocal)
  - 根据创建Socket类型不同分为
    - 针对 TCP 协议通信的 socket 编程模型
    - 针对 UDP 协议通信的 socket 编程模型
    - 针对本地进程间通信的 socket 编程模型
8. 线程间通信
  同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，⽐如全局变量，所以对于线程间关注的不是通信⽅式，⽽是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步

#### 4.3 多线程同步
1. 竞争与协作
- 例：多线程自增同一i，发生时钟中断，导致竞争
- 互斥
  - 竞争条件（race condition）
    多线程相互竞争操作共享变量
  - 不确定性（indeterminate）
    每次运⾏都可能得到不同的结果
  - 临界区（criticalsection）
    访问共享资源的代码⽚段，⼀定不能给多线程同时执⾏
  - 互斥（mutualexclusion）
    保证⼀个线程在临界区执⾏时，其他线程应该被阻⽌进⼊临界区，这段代码执⾏过程中，最多只能出现⼀个线程
  - 互斥也可针对多进程竞争共享资源，如共享内存
- 同步
  同步，就是并发进程/线程在⼀些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步
2. 互斥与同步的实现和使⽤
- 锁
  加锁操作和解锁操作可以解决并发线程/进程的互斥问题
  - 原⼦操作指令 —— 测试和置位（Test-and-Set）指令
    - 把 old_ptr 更新为 new 的新值
    - 返回 old_ptr 的旧值；
    - 原子执行：要么全部执⾏，要么都不执⾏，不能出现执⾏到⼀半的中间状态
  - 忙等待锁或⾃旋锁（spin lock） **具体实现看PDF图**
    - 第⼀个场景是，⾸先假设⼀个线程在运⾏，调⽤ lock() ，没有其他线程持有锁，所以 flag 是 0。当调⽤ TestAndSet(flag, 1) ⽅法，返回 0，线程会跳出 while 循环，获取锁。同时也会原⼦的设置 flag为1，标志锁已经被持有。当线程离开临界区，调⽤ unlock() 将 flag 清理为 0
    - 第⼆种场景是，当某⼀个线程已经持有锁（即 flag 为1）。本线程调⽤ lock() ，然后调⽤TestAndSet(flag, 1) ，这⼀次返回 1。只要另⼀个线程⼀直持有锁， TestAndSet() 会重复返回 1，本线程会⼀直忙等。当 flag 终于被改为 0，本线程会调⽤ TestAndSet() ，返回 0 并且原⼦地设置为 1，从⽽获得锁，进⼊临界区
    - 在单处理器上，需要抢占式的调度器（即不断通过时钟中断⼀个线程，运⾏其他线程）。否则，⾃旋锁在单 CPU 上⽆法使⽤，因为⼀个⾃旋的线程永远不会放弃 CPU
  - ⽆等待锁
    获取不到锁的时候，不⽤⾃旋，把当前线程放⼊到锁的等待**队列**，然后执⾏调度程序，把 CPU让给其他线程执⾏
  - 具体实现 **《操作系统导论》第 28 章锁的内容**
- 信号量
  信号量表示资源的数量，对应的变量是⼀个整型（ sem ）变量
  - 操作
    - P 操作
      将 sem 减 1 ，相减后，如果 sem < 0 ，则进程/线程进⼊阻塞等待，否则继续，表明 P操作可能会阻塞
    - V 操作
      将 sem 加 1 ，相加后，如果 sem <= 0 ，唤醒⼀个等待中的进程/线程，表明 V 操作不会阻塞
  - 具体实现见PDF图
    使用队列
  - 实现临界区的互斥访问 s=1
    对于两个并发线程，互斥信号量的值仅取 1、 0 和 -1 三个值，分别表示：
    如果互斥信号量为 1，表示没有线程进⼊临界区；
    如果互斥信号量为 0，表示有⼀个线程进⼊临界区；
    如果互斥信号量为 -1，表示⼀个线程进⼊临界区，另⼀个线程等待进⼊
  - 实现事件同步 s=0
    A:先P后V，B先V后P
    流程：AP,BV,BP,AV,B需要A提供资源以运行

3. 经典同步问题
- **⽣产者-消费者问题**
- **哲学家就餐问题**
  - 信号量的⽅式
    导致死锁
  - 加入互斥信号量
    每次进餐只能有⼀位哲学家
  - 奇偶数编码哲学家拿叉子顺序相反
    不会出现死锁，也可以两⼈同时进餐
  - ⽤⼀个数组 state 来记录每⼀位哲学家在进程、思考还是饥饿状态
    不会出现死锁，也可以两⼈同时进餐
  - 注意
    每个进程/线程将 smart_person 函数作为主代码运⾏，⽽其他 take_forks 、 put_forks 和test 只是普通的函数，⽽⾮单独的进程/线程
  - 用途
    互斥访问有限的竞争问题（如 I/O 设备）
- **读者-写者问题**
  - 描述
    「读-读」允许，「读-写」互斥，-「写-写」互斥
  - 读者优先策略
    只要有读者正在读的状态，后来的读者都可以直接进⼊，如果读者持续不断进⼊，则写者会处于饥饿状态
  - 写者优先策略
    只要有写者准备要写⼊，写者应尽快执⾏写操作，后来的读者就必须阻塞；如果有写者持续不断写⼊，则读者就处于饥饿；但必须等到所有进⼊读者队列的读者都执⾏完读操作，通过 V(wDataMutex) 唤醒写者的写操作
  - 公平策略
     通过flag 阻⽌读者的特殊权限（特殊权限是只要读者到达，就可以进⼊读者队列）
#### 4.4 死锁
1. 概念
  当两个线程为了保护两个不同的共享资源⽽使⽤了两个互斥锁，那么这两个互斥锁应⽤不当的时候，可能会造成两个线程都在等待对⽅释放锁，在没有外⼒的作⽤下，这些线程会⼀直相互等待，就没办法继续运⾏，这种情况就是发⽣了死锁
2. 死锁只有**同时满⾜**以下四个条件才会发⽣
  - 互斥条件
    指多个线程不能同时使⽤同⼀个资源
  - 持有并等待条件
    线程 A 在等待资源 2 的同时并不会释放⾃⼰已经持有的资源 1
  - 不可剥夺条件
    当线程已经持有了资源 ， 在⾃⼰使⽤完之前不能被其他线程获取
  - 环路等待条件
    在死锁发⽣的时候， 两个线程获取资源的顺序构成了环形链
3. **模拟死锁问题的产⽣**
4. **利用工具排查死锁问题**
  - pstack + gdb
  - 多次执⾏ pstack 命令查看线程的函数调⽤过程，多次对⽐结果，确认哪⼏个线程⼀直没有变化，且是因为在等待锁，那么⼤概率是由于死锁问题导致的
  - info thread,打印了所有的线程信息
  - thread 2,切换线程
  - bt,打印线程的调⽤栈信息
  - frame 3,打印调⽤栈中的第三个帧的信息
  - 通过 p mutex_A ，打印互斥锁 A 对象信息
  - 通过 p mutex_B ，打印互斥锁 B 对象信息
5. 避免死锁问题的发⽣
  - 使⽤资源有序分配法，来破环环路等待条件
  - 资源有序分配即以相同的顺序获取资源


#### 4.5 悲观锁与乐观锁
1. 选择合适的锁
   - 不同种类的锁⾃然适⽤于不同的场景，选择了错误的锁，那么在⼀些⾼并发的场景下，可能会降低系统的性能
   - 为了选择合适的锁，我们不仅需要清楚知道加锁的成本开销有多⼤，还需要分析业务场景中访问的共享资源的⽅式，再来还要考虑并发访问共享资源时的冲突概率 
2. 互斥锁与⾃旋锁
   - 互斥锁
     - 互斥锁加锁失败后，线程会释放 CPU ，给其他线程。既然线程释放掉了 CPU，⾃然线程加锁的代码就会被阻塞
     - 对于互斥锁加锁失败⽽阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执⾏。
     - 缺点：会有两次线程上下⽂切换的成本
       - 运行->睡眠
       - 睡眠->就绪
       - 当两个线程是**属于同⼀个进程**， 因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据
       - 时间大概在几十ns到几μs之间，如果你锁住的代码执⾏时间⽐较短，那可能上下⽂切换的时间都⽐你锁住的代码执⾏时间还要⻓
     - 如果你能确定被锁住的代码执⾏时间很短，就不应该⽤互斥锁，⽽应该选⽤⾃旋锁，否则使⽤互斥锁。
   - 自旋锁
     - ⾃旋锁加锁失败后，线程会忙等待，直到它拿到锁；
     - ⾃旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「⽤户态」完成加锁和解锁操作，不会主动产⽣线程上下⽂切换，所以相⽐互斥锁来说，会快⼀些，开销也⼩⼀些。
     - 可以使用while循环实现，但最好使⽤ CPU 提供的 PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量
     - 缺点
       - 需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断⼀个线程，运⾏其他线程）。否则，⾃旋锁在单 CPU 上⽆法使⽤，因为⼀个⾃旋的线程永远不会放弃 CPU。
       - ⾃旋锁开销少，在多核系统下⼀般不会主动产⽣线程切换，适合异步、协程等在⽤户态切换请求的编程⽅式，但如果被锁住的代码执⾏时间过⻓，⾃旋的线程会⻓时间占⽤ CPU 资源，所以⾃旋的时间和被锁住的代码执⾏的时间是成「正⽐」的关系
3. 读写锁
   - 只读取共享资源⽤「读锁」加锁，如果要修改共享资源则⽤「写锁」加锁
   - 可以根据场景使用互斥锁和⾃旋锁实现
   - 适用场景
      读写锁适⽤于能明确区分读操作和写操作的场景，写锁为独占锁，而读锁可以被多个线程持有，所以读写锁在读多写少的场景，能发挥出优势
   - 读优先锁
     - 优点：并发性强
     - 缺点:会造成写线程饥饿
   - 写优先锁
     - 缺点:会造成读线程饥饿
   - 公平读写锁：先进先出
4. 乐观锁与悲观锁
   - 悲观锁
     - 适用场景
    多线程同时修改共享资源的概率⽐较⾼，于是很容易出现冲突，所以访问共享资源前，先要上锁
     - 缺点：并发性弱
     - 如互斥锁、⾃旋锁、读写锁
   - 乐观锁
     - 先修改完共享资源，再验证这段时间内有没有发⽣冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作
     - 乐观锁全程并没有加锁，所以它也叫⽆锁编程
     - 例，如在线文档编辑
     - 优点：并发性强
     - 缺点：重试的成本⾮常⾼
     - 方法：用上传前后的版本控制来判断
5. 不管使⽤的哪种锁，我们的加锁的代码范围应该尽可能的⼩，也就是加锁的粒度⼩，这样执⾏速度会⽐较快

### 5. 调度算法

#### 5.1 进程调度/⻚⾯置换/磁盘调度算法
1. 进程调度算法（CPU 调度算法）
2. ⾮抢占式调度
   - 当进程正在运⾏时，它就会⼀直运⾏，直到该进程完成或发⽣某个事件⽽被阻塞时，才会把 CPU 让给其他进程
   - 当进程从运⾏状态转到等待状态
   - 当进程从运⾏状态转到终⽌状态
3. 抢占式调度
   - 进程正在运⾏的时，可以被打断，使其把 CPU 让给其他进程
   - 当进程从运⾏状态转到就绪状态
   - 当进程从等待状态转到就绪状态
4. 常见调度算法
   - 先来先服务调度算法
   - 最短作业优先调度算法
   - ⾼响应⽐优先调度算法
   - 时间⽚轮转调度算法
   - 最⾼优先级调度算法
   - 多级反馈队列调度算法
6. 内存⻚⾯置换算法
   - 缺⻚异常（缺⻚中断）
     - 当 CPU 访问的⻚⾯不在物理内存时，便会产⽣⼀个缺⻚中断，请求操作系统将所缺⻚调⼊到物理内存
     - 与一般中断的区别
       - 缺⻚中断在指令执⾏「期间」产⽣和处理中断信号，⽽⼀般中断在⼀条指令执⾏「完成」后检查和处理中断信号。
       - 缺⻚中断返回到该指令的开始重新执⾏「该指令」，⽽⼀般中断返回回到该指令的「下⼀个指令」执⾏
     - 页表项：页号，物理页号，状态位，访问位，修改位，硬盘地址
   - 功能
     - 当出现缺⻚异常，需调⼊新⻚⾯⽽内存已满时，选择被置换的物理⻚⾯，也就是说选择⼀个物理⻚⾯换出到磁盘，然后把需要访问的⻚⾯换⼊到物理⻚
   - 最佳⻚⾯置换算法（OPT）
     - 置换在「未来」最⻓时间不访问的⻚⾯
     - 缺点：是实际系统中⽆法实现，因为程序访问⻚⾯时是动态的，我们是⽆法预知每个⻚⾯在「下⼀次」访问前的等待时间
     - 作用：衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是⾼效的
   - 先进先出置换算法（FIFO）
     - 选择在内存驻留时间很⻓的⻚⾯进⾏中置换
   - 最近最久未使⽤的置换算法（LRU）
     - 发⽣缺⻚时， 选择最⻓时间没有被访问的⻚⾯进⾏置换
     - 缺点：开销大，为了完全实现 LRU，需要在内存中维护⼀个所有⻚⾯的链表，最近最多使⽤的⻚⾯在表头，最近最少使⽤的⻚⾯在表尾巴，在每次访问内存时都必须要更新「整个链表」。在链表中找到⼀个⻚⾯，删除它，然后把它移动到表头是⼀个⾮常费时的操作。
   - 时钟⻚⾯置换算法（Lock）
     - 能优化置换的次数，也能⽅便实现
     - 近似LRU,⼜是对 FIFO 的⼀种改进
     - 把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⼀个表针指向最⽼的⻚⾯。
     - 当发⽣缺⻚中断时，算法⾸先检查表针指向的⻚⾯
     - 如果它的访问位位是 0 就淘汰该⻚⾯，并把新的⻚⾯插⼊这个位置，然后把表针前移⼀个位置；
     - 如果访问位是 1 就清除访问位，并把表针前移⼀个位置，重复这个过程直到找到了⼀个访问位为 0 的⻚⾯为⽌；
   - 最不常⽤算法（LFU）
     - 当发⽣缺⻚中断时，选择「访问次数」最少的那个⻚⾯，并将其淘汰
     - 缺点
       - 增加⼀个计数器来实现，这个硬件成本是⽐较⾼的，另外如果要对这个计数器查找哪个⻚⾯访问次数最⼩，查找链表本身，如果链表⻓度很⼤，是⾮常耗时的，效率不⾼
       - FU 算法只考虑了频率问题，没考虑时间的问题。过去有些页面访问频率很高，但现在没有访问。而当前页面频繁访问，但没有过去的多，容易被误伤
     - 解决方案
       - 可以定期减少访问的次数，⽐如当发⽣时间中断时，把过去时间访问的⻚⾯的访问次数除以 2
7. 磁盘调度算法
   - 磁盘构成： 盘面，磁道，扇区，柱面
   - 磁盘调度算法的⽬的
      优化磁盘的访问请求顺序来提⾼磁盘的访问性能
   - 寻道的时间是磁盘访问最耗时的部分
   - 先来先服务（FCFS）
     - 先到来的请求，先被服务
     - 优点：简单粗暴
     - 缺点：如果⼤量进程竞争使⽤磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过⻓
   - 最短寻道时间优先（SSF）
     - 优先选择从当前磁头位置所需寻道时间最短的请求
     - 优点：性能比FCFS高
     - 缺点: 存在某些请求的饥饿，假设是⼀个动态的请求，如果后续来的请求都是⼩于某值，那么该值对应的磁道可能永远都不会被响应。原因是磁头在⼀⼩块区域来回移动
   - 扫描算法
     - 磁头在⼀个⽅向上移动，访问所有未完成的请求，直到磁头到达该⽅向上的最后的磁道，才调换⽅向，这就是扫描（Scan）算法。
     - 优点：扫描调度算法性能较好，不会产⽣饥饿现象
     - 缺点：中间部分相⽐其他部分响应的频率会⽐较多，也就是说每个磁道的响应频率存在差异
   - 循环扫描算法（CSCAN）
     - 只有磁头朝某个特定⽅向移动时，才处理磁道访问请求，⽽返回时直接快速移动⾄最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应⼀个⽅向上的请求
     - 从小到大至最右端的磁道 199，就⽴即回到磁盘的开始处（磁道 0），在从小到达
     - 优点：对于各个位置磁道响应频率相对⽐较平均
   - LOOK 与 C-LOOK算法
     - 优化SCAN和CSCAN，就是磁头在移动到「最远的请求」位置，然后⽴即反向移动
     - LOOK：针对 SCAN优化，磁头在每个⽅向上仅仅移动到最远的请求位置，然后⽴即反向移动，⽽不需要移动到磁盘的最始端或最末端， 反向移动的途中会响应请求
     - C-LOOK：C-SCAN 算法的优化则叫 C-LOOK，它的⼯作⽅式，磁头在每个⽅向上仅仅移动到最远的请求位置，然后⽴即反向移动，⽽不需要移动到磁盘的最始端或最末端， 反向移动的途中不会响应请求