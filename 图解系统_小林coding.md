[toc]

### 1. 硬件结构

#### 1.1 CPU如何执行程序?
1. 计算机基本结构
    中央处理器，内存，输入设备，输出设备，总线
2. 中央处理器
   - 位宽:32位，64位
   - 寄存器
     - 通⽤寄存器，⽤来存放需要进⾏运算的数据
     - 程序计数器，⽤来存储 CPU 要执⾏下⼀条指令「所在的内存地址」
     - 指令寄存器，⽤来存放程序计数器指向的指令
3. 总线
   - 地址总线，⽤于指定 CPU 将要操作的内存地址
   - 数据总线，⽤于读写内存的数据
   - 控制总线，⽤于发送和接收信号，⽐如中断、设备复位等信号
4. 线路位宽与 CPU 位宽
   - 串行，并行
   - 线路位宽，避免低效率的串⾏传输的⽅式，线路的位宽最好⼀次就能访问到所有的内存地址，2^32=4G
   - CPU 的位宽不要⼩于线路位宽,32 位的 CPU 最好和 32 位宽的线路搭配
5. 程序执⾏的基本过程
   - ⼀个程序执⾏的时候， CPU 会根据程序计数器⾥的内存地址，从内存⾥⾯把需要执⾏
的指令读取到指令寄存器⾥⾯执⾏，然后根据指令⻓度⾃增，开始顺序读取下⼀条指令
   - 程序语言->汇编代码->机器码(通过汇编器)
   - 指令
     - 指令的内容是⼀串⼆进制数字的机器码
     - 不同的 CPU 有不同的指令集，也就是对应着不同的汇编语⾔和不同的机器码
     - 类型：数据传输类型，运算类型，跳转类型，信号类型，闲置类型
   - CPU 的指令周期
      Fetch（取得指令）-> Decode（指令译码）->  Execution（执⾏指令）-> Store（数据回写）
   - CPU 的时钟周期
      - 每⼀次脉冲信号⾼低电平的转换就是⼀个周期 
      - 1GHz，时钟频率为1G，时钟周期为1ns
   - CPU 的执行时间
     - CPU 的执行时间=CPU 时钟周期数（CPU Cycles）X 时钟周期时间（Clock Cycle Time）
     - CPU 时钟周期数=指令数 X 每条指令的平均时钟周期数(CPI)
     - 指令数:编译器优化
     - CPI:厂商优化
     - CCT:计算机主频
6. 32位和64位
   - 只有运算⼤数字的时候， 64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不⼤
   - 64 位 CPU 可以寻址更⼤的内存空间，32 位的寄存器存不下 64 位的指令
   - 硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽

#### 1.2 存储器金字塔
1. 存储器的层次结构
   - CPU 并不会直接和每⼀种存储器设备直接打交道，⽽是每⼀种存储器设备只和它相邻的存储器设备打交道
   - 目的
    缓存:依次寻找并取数据
   - 寄存器
    0.5CCT
   - CPU高速缓存(CPU Cache)
        SRAM静态随机存储器
        L1(数据缓存，指令缓存):1ns
        L2:4ns
        L3:20~60CCT
   - 内存
        DRAM动态随机存取存储器
        100ns
   - SSD/HDD
        SSD:150μs
        HDD:10ms

#### 1.3 写出让CPU跑得更快的代码
1. 计算密集型程序，写出能够配合 CPU Cache ⼯作机制的代码
2. CPU Cache 的数据结构和读取过程
   - 缓存块(CPU Line)
      - CPU Line 是 CPU从内存读取数据的基本单位
      - 数据结构
            索引，组标记，有效位，数据块
      - 字
            CPU读取CPU Cache不读取CPU Line中的整个数据块，而是读一个数据片段 
   - 直接映射 Cache（Direct Mapped Cache）
      - 内存块(Block)
            读取的时候我们要拿到数据所在内存块的地址
      - 直接映射
            使⽤「取模运算」，取模运算的结果就是内存块地址对应的 CPU Line（缓存块）的地址
      - 组标记（Tag）
            区别不同的内存块
      - 内存的访问地址
            包括组标记，CPU Line索引，偏移量
   - CPU从Cache加载内存地址对应的Cache中的数据
      -  没有对应的高速缓存地址，所以我们先要判断数据是否存储在cache内
      -  局部性原理，每一层Cache中都缓存最近使用的数据
        1. 根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Line 的地址
        2. 找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是⽆效的， CPU 就会直接访问内存，**并重新加载数据**，如果数据有效，则往下执⾏
        3. 对⽐内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话， CPU 就会直接访问内存，**并重新加载数据**，如果是的话，则往下执⾏
        4. 根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字

3. 提高缓存命中率
   - 缓存命中
      访问的数据在 CPU Cache 中的话，意味着缓存命中
   - 提升数据缓存的命中率
     - 对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升
     - 一般是64字节
   - 提升指令缓存的命中率
     - 对于指令缓存，有规律的条件分⽀语句能够让 CPU 的分⽀预测器发挥作⽤，进⼀步提⾼执⾏的效率
     - likey,unlikely宏
     - 例:先排序后遍历，循环命中次数多
   - 提升多核 CPU 的缓存命中率
     - 如果⼀个进程在不同核⼼来回切换，各个核⼼的缓存命中率就会受到影响，相反如果进程都在同⼀个核⼼上执⾏，那么其数据的 L1和 L2 Cache 的缓存命中率可以得到有效提⾼，缓存命中率⾼就意味着 CPU 可以减少访问 内存的频率
     - sched_setaffinity，把线程绑定在某⼀个 CPU 核⼼上
     - 例:同时执行多个计算密集型线程

#### 1.4 CPU缓存一致性
1. CPU Cache 的数据写⼊
   - 写入Cache后需同步内存中相对应的数据
   - 写直达（Write Through）
     - 把数据同时写⼊内存和 Cache 中
     - 如果数据已经在 Cache ⾥⾯，先将数据更新到 Cache ⾥⾯，再写⼊到内存⾥⾯（因为cache从内存中读取数据要同步）
     - 如果数据没有在 Cache ⾥⾯，就直接把数据更新到内存⾥⾯
     - 缺点：每次写操作都会写回到内存，花费大量时间
   - 写回（Write Back）
     - 如果当发⽣写操作时，数据已经在 CPU Cache ⾥的话，则把数据更新到 CPU Cache ⾥，同时标记CPU Cache ⾥的这个 Cache Block 为脏（Dirty）的代表这个时候，我们 CPU Cache⾥⾯的这个 Cache Block 的数据和内存是不⼀致的，不⽤把数据写到内存⾥
     - 如果当发⽣写操作时，数据所对应的 Cache Block ⾥存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block ⾥的数据有没有被标记为脏的，如果是脏的话，我们就要把这个 Cache Block⾥的数据写回到内存，然后再把当前要写⼊的数据，写⼊到这个 Cache Block ⾥，同时也把它标记为脏的；如果 Cache Block ⾥⾯的数据没有被标记为脏，则就直接将数据写⼊到这个 Cache Block⾥，然后再把这个 Cache Block 标记为脏的就好了
     - 写回这个⽅法，在把数据写⼊到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，⽽在缓存命中的情况下，则在写⼊后 Cache后，只需把该数据对应的 Cache Block 标记为脏即可，⽽不⽤写到内存⾥