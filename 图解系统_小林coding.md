[toc]

### 1. 硬件结构

#### 1.1 CPU如何执行程序?
1. 计算机基本结构
    中央处理器，内存，输入设备，输出设备，总线
2. 中央处理器
   - 位宽:32位，64位
   - 寄存器
     - 通⽤寄存器，⽤来存放需要进⾏运算的数据
     - 程序计数器，⽤来存储 CPU 要执⾏下⼀条指令「所在的内存地址」
     - 指令寄存器，⽤来存放程序计数器指向的指令
3. 总线
   - 地址总线，⽤于指定 CPU 将要操作的内存地址
   - 数据总线，⽤于读写内存的数据
   - 控制总线，⽤于发送和接收信号，⽐如中断、设备复位等信号
4. 线路位宽与 CPU 位宽
   - 串行，并行
   - 线路位宽，避免低效率的串⾏传输的⽅式，线路的位宽最好⼀次就能访问到所有的内存地址，2^32=4G
   - CPU 的位宽不要⼩于线路位宽,32 位的 CPU 最好和 32 位宽的线路搭配
5. 程序执⾏的基本过程
   - ⼀个程序执⾏的时候， CPU 会根据程序计数器⾥的内存地址，从内存⾥⾯把需要执⾏
的指令读取到指令寄存器⾥⾯执⾏，然后根据指令⻓度⾃增，开始顺序读取下⼀条指令
   - 程序语言->汇编代码->机器码(通过汇编器)
   - 指令
     - 指令的内容是⼀串⼆进制数字的机器码
     - 不同的 CPU 有不同的指令集，也就是对应着不同的汇编语⾔和不同的机器码
     - 类型：数据传输类型，运算类型，跳转类型，信号类型，闲置类型
   - CPU 的指令周期
      Fetch（取得指令）-> Decode（指令译码）->  Execution（执⾏指令）-> Store（数据回写）
   - CPU 的时钟周期
      - 每⼀次脉冲信号⾼低电平的转换就是⼀个周期 
      - 1GHz，时钟频率为1G，时钟周期为1ns
   - CPU 的执行时间
     - CPU 的执行时间=CPU 时钟周期数（CPU Cycles）X 时钟周期时间（Clock Cycle Time）
     - CPU 时钟周期数=指令数 X 每条指令的平均时钟周期数(CPI)
     - 指令数:编译器优化
     - CPI:厂商优化
     - CCT:计算机主频
6. 32位和64位
   - 只有运算⼤数字的时候， 64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不⼤
   - 64 位 CPU 可以寻址更⼤的内存空间，32 位的寄存器存不下 64 位的指令
   - 硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽

#### 1.2 存储器金字塔
1. 存储器的层次结构
   - CPU 并不会直接和每⼀种存储器设备直接打交道，⽽是每⼀种存储器设备只和它相邻的存储器设备打交道
   - 目的
    缓存:依次寻找并取数据
   - 寄存器
    0.5CCT
   - CPU高速缓存(CPU Cache)
        SRAM静态随机存储器
        L1(数据缓存，指令缓存):1ns
        L2:4ns
        L3:20~60CCT
   - 内存
        DRAM动态随机存取存储器
        100ns
   - SSD/HDD
        SSD:150μs
        HDD:10ms

#### 1.3 写出让CPU跑得更快的代码
1. 计算密集型程序，写出能够配合 CPU Cache ⼯作机制的代码
2. CPU Cache 的数据结构和读取过程
   - 缓存块(CPU Line)
      - CPU Line 是 CPU从内存读取数据的基本单位
      - 数据结构
            索引，组标记，有效位，数据块
      - 字
            CPU读取CPU Cache不读取CPU Line中的整个数据块，而是读一个数据片段 
   - 直接映射 Cache（Direct Mapped Cache）
      - 内存块(Block)
            读取的时候我们要拿到数据所在内存块的地址
      - 直接映射
            使⽤「取模运算」，取模运算的结果就是内存块地址对应的 CPU Line（缓存块）的地址
      - 组标记（Tag）
            区别不同的内存块
      - 内存的访问地址
            包括组标记，CPU Line索引，偏移量
   - CPU从Cache加载内存地址对应的Cache中的数据
      -  没有对应的高速缓存地址，所以我们先要判断数据是否存储在cache内
      -  局部性原理，每一层Cache中都缓存最近使用的数据
        1. 根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Line 的地址
        2. 找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是⽆效的， CPU 就会直接访问内存，**并重新加载数据**，如果数据有效，则往下执⾏
        3. 对⽐内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话， CPU 就会直接访问内存，**并重新加载数据**，如果是的话，则往下执⾏
        4. 根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字

3. 提高缓存命中率
   - 缓存命中
      访问的数据在 CPU Cache 中的话，意味着缓存命中
   - 提升数据缓存的命中率
     - 对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升
     - 一般是64字节
   - 提升指令缓存的命中率
     - 对于指令缓存，有规律的条件分⽀语句能够让 CPU 的分⽀预测器发挥作⽤，进⼀步提⾼执⾏的效率
     - likey,unlikely宏
     - 例:先排序后遍历，循环命中次数多
   - 提升多核 CPU 的缓存命中率
     - 如果⼀个进程在不同核⼼来回切换，各个核⼼的缓存命中率就会受到影响，相反如果进程都在同⼀个核⼼上执⾏，那么其数据的 L1和 L2 Cache 的缓存命中率可以得到有效提⾼，缓存命中率⾼就意味着 CPU 可以减少访问 内存的频率
     - sched_setaffinity，把线程绑定在某⼀个 CPU 核⼼上
     - 例:同时执行多个计算密集型线程

#### 1.4 CPU缓存一致性
1. CPU Cache 的数据写⼊
   - 写入Cache后需同步内存中相对应的数据
   - 写直达（Write Through）
     - 把数据同时写⼊内存和 Cache 中
     - 如果数据已经在 Cache ⾥⾯，先将数据更新到 Cache ⾥⾯，再写⼊到内存⾥⾯（因为cache从内存中读取数据要同步）
     - 如果数据没有在 Cache ⾥⾯，就直接把数据更新到内存⾥⾯
     - 缺点：每次写操作都会写回到内存，花费大量时间
   - 写回（Write Back）
     - 如果当发⽣写操作时，数据已经在 CPU Cache ⾥的话，则把数据更新到 CPU Cache ⾥，同时标记CPU Cache ⾥的这个 Cache Block 为脏（Dirty）的代表这个时候，我们 CPU Cache⾥⾯的这个 Cache Block 的数据和内存是不⼀致的，不⽤把数据写到内存⾥
     - 如果当发⽣写操作时，数据所对应的 Cache Block ⾥存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block ⾥的数据有没有被标记为脏的，如果是脏的话，我们就要把这个 Cache Block⾥的数据写回到内存，然后再把当前要写⼊的数据，写⼊到这个 Cache Block ⾥，同时也把它标记为脏的；如果 Cache Block ⾥⾯的数据没有被标记为脏，则就直接将数据写⼊到这个 Cache Block⾥，然后再把这个 Cache Block 标记为脏的就好了
     - 写回这个⽅法，在把数据写⼊到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，⽽在缓存命中的情况下，则在写⼊后 Cache后，只需把该数据对应的 Cache Block 标记为脏即可，⽽不⽤写到内存⾥

2. 缓存一致性问题（Cache Coherence）
   - 不同核心之间由于写回策略导致的缓存内数据不一致的问题
   - 同步不同核心的缓存数据
     - 写传播（Write Propagation）
         某个 CPU 核⼼⾥的 Cache 数据更新时，必须要传播到其他核⼼的 Cache
     - 事务的串形化（Transaction Serialization）
         某个 CPU 核⼼⾥对数据的操作顺序，必须在其他核⼼看起来顺序是⼀样的
         如何实现:写传播；锁
   - 总线嗅探
     - 实现写传播的方式。修改数据时通过总线把这个事件⼴播通知给其他所有的核⼼，其CPU检查是否有相同的数据存储在L1 Cache中，没有则更新
     - 带宽压力大且不能保证事务串行化
   - MESI协议
     - Modified，已修改，即前文所述“标记为脏”
     - Exclusive，独占
     - Shared，共享
     - Invalidated，已失效
     - 流程
         只有A号CPU有i的数据，则A标记为独占，若B也要用i，则A,B被标记为共享，若A修改了数据，则A标为已修改，别的CPU标记为已失效，若继续修改A则A仍为已修改，但如果i对应的cache line要被替换，则会将数据同步到内存
     - 对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送⼴播给其他 CPU 核⼼，减去了总线带宽压力

#### 1.5 CPU如何执行任务
1. CPU伪共享（False Sharing）
   - 因为多个线程同时读写同⼀个 Cache Line 的不同变量时，⽽导致 CPU Cache 失效的现象
   - 对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同⼀个Cache Line
   - __cacheline_aligned_in_smp宏定义
   - Cache Line⼤⼩字节对⻬：避免 Cache 伪共享实际上是⽤空间换时间的思想，浪费⼀部分 Cache 空间，从⽽换来性能的提升
   - 字节填充：应用层面的规避方案: Java 并发框架 Disruptor 使⽤「字节填充 + 继承」

2. CPU如何选择线程
   - 进程和线程
     - tark_struct
         在 Linux 内核中，进程和线程都是⽤ tark_struct 结构体表示的
     - 区别
      在线程的 tark_struct 结构体⾥部分资源是共享了进程已创建的资源，⽐如内存地址空间、代码段、⽂件描述符等，所以Linux 中的线程也被称为轻量级进程
     - 主线程
      没有创建线程的进程，是只有单个执⾏流，被称为主线程
   - 任务
      Linux 内核⾥的调度器，调度的对象就是 tark_struct ，我们就把这个数据结构统称为任务
     - 实时任务
        对系统的响应时间要求很⾼，即优先级高，在0~99
     - 普通任务
        对系统的响应时间没有很高要求，优先级在100~139
   - 调度类
       确保高优先级的任务能够尽可能早的被执⾏
     - Dealine调度类（实时任务）
       - 调度器：Dealine调度器
       - 运行队列：dl_rq
       - 调度策略
         SCHED_DEADLINE，距离当前时间点最近的 deadline 的任务会被优先调度
     - Realtime调度类（实时任务）
       - 调度器：RT调度器
       - 运行队列：rt_rq
       - 调度策略
         SCHED_FIFO：相同优先级先来先服务，高优先级可以插队
         SCHED_RR：对于相同优先级的任务，轮流着运⾏，每个任务都有⼀定的时间⽚，当⽤完时间⽚的任务会被放到队列尾部，以保证相同优先级任务的公平性，但高优先级仍可以插队
     - Fair调度类（普通任务）日常遇到最多
       - 调度器：CFS调度器
       - 运行队列：cfs_rq
       - 调度策略
         SCHED_NORMAL：普通任务使⽤的调度策略；
         SCHED_BATCH：后台任务的调度策略，不和终端进⾏交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级
   - 完全公平调度（Completely Fair Scheduling）
     - 概念
         分配给每个任务的 CPU 时间是⼀样，各任务安排一个虚拟运行时间vruntime
         在 CFS 算法调度的时候，会优先选择 vruntime 少的任务，确保公平性
     - 权重值
         vruntime += 实际运行时间delta_exec *　NICE_0_LOAD　／　权重
         高权重优先调度，nice越低权重越高
   - 运⾏队列（Run Queue, rq）
     - Deadline 运⾏队列 dl_rq
     - 实时任务运⾏队列 rt_rq 
     - CFS 运⾏队列 csf_rq(红黑树描述)
     - 优先级： Deadline > Realtime > Fair,优先级如下： Deadline > Realtime > Fair
   - 调整优先级
     - 默认均为普通任务
     - nice值
         -20~19,表示优先级的修正数值
          priority(new) = priority(old) + nice，值越低，表明优先级越⾼
     - 设定启动任务nice值
         nice -n -3 /usr.sbin/mysqld
     - 修改运行任务nice值
         renice -10 -p <pid>
     - 修改调度策略及优先级
         chrt -f 1 -p <pid>    
      
#### 1.6 软中断
1. 中断
   - 定义
      中断是系统⽤来响应硬件设备请求的⼀种机制，操作系统收到硬件的中断请求，会打断正在执⾏的进程，然后调⽤内核中的中断处理程序来响应请求
   - 好处
      是⼀种异步的事件处理机制，可以提⾼系统的并发处理能⼒
   - 问题
     - 中断请求会打断其他进程的运行，所以中断处理程序要快以减少对正常进程的影响
     - 临时关闭中断，当前中断处理程序执行完之前，无法响应其他中断请求，所以要快
2. 软中断
   - 为了避免中断程序执行时间过长与中断丢失的问题，将中断分为上限部分
     - 上部分硬中断:直接处理硬件请求，负责耗时短的⼯作，特点是快速执⾏
     - 下部分软中断:由内核触发，负责上半部未完成的⼯作，通常都是耗时⽐较⻓的事情，特点是延迟执⾏
   - 软中断是以内核线程的⽅式执⾏，并且每⼀个 CPU 都对应⼀个软中断内核线程，其名字在中括号内
   - 例
      网络掉包，⼀些内核⾃定义事件也属于软中断，如内核调度，RCU锁
   - 查看软中断
     - /proc/interrupts 硬中断
     - /proc/softirqs 软中断
       - 每个CPU各有其不同类型软中断的累计运行次数，同一种中断在不同CPU中基本是同一数量级
       - 类型有
            NET_RX 表示⽹络接收中断
            NET_TX 表示⽹络发送中断
            TIMER 表示定时中断
            RCU 表示 RCU 锁中断
            SCHED 表示内核调度中断
     - 查看中断次数的变化速率
         watch -d cat /proc/softirqs
     - 查看软中断内核线程
         ps aux | grep softirq
3. 定位软中断CPU使用率过高的问题
   - top,si就是软中断上的使用率
       若CPU使⽤率最⾼的进程也是软中断ksoftirqd，这种⼀般可以认为系统的开销被软中断占据了
   - watch -d cat /proc/softirqs，查看每个软中断类型的中断次数的变化速率
   - 对于⽹络 I/O ⽐较⾼的 Web 服务器， NET_RX ⽹络接收中断的变化速率相对快很多
     - sar -n DEV查看网卡网络包接受速率
     - tcpdump抓包，分析包来源

#### 1.7 为什么0.1 + 0.2不等于0.3
1. 负数用补码表示的原因
   - int，最高位为符号位，其余31位表示二进制数据
   - 补码
      就是把正数的⼆进制全部取反再加1
   - 原因
      负数不是使⽤补码的⽅式表示，还需要多⼀步操作来判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转成加法。用补码的方式则和正数加减法一样
      节约性能
2. ⼗进制⼩数与⼆进制的转换
   - 乘2取整法
      8.625二进制表示为1000.101
   - 近似值表示
      0.1的二进制为0.0001100110....无限循环，所以只能近似值表示，造成精度缺失
   - 小数二进制转十进制幂为负
3. 计算机如何存储小数
   - 定点数
   - 浮点数
     - 规格化：1000.101表示为1.000101 x 2^3
     - 尾数：000101
         尾数的长度决定了这个数的精度
     - 指数：3
         指数位的长度决定了这个数的表达范围
     - IEEE标准：符号位 指数位 尾数
         同时定义二进制浮点数左侧有效位永远为1，作为固定隐含位不表示，节约了1位空间，提高了精度
     - 有效位
         包含整数部分和小数部分
     - 偏移量
         指数有正负，为了计算方便，实际存储指数时需把指数转换成无符号整数，float指数范围为-126~127，所以其偏移量为127
   - float
     - float尾数部分为23位，加上固定隐含位24位，所以精度在十进制中为log10(2^24)约等于7.22，其有效数字为7~8位，指数部分为8位
     - 转换公式：$(-1)^{符号位}*(1+尾数位)*2^{(指数-127)}$
4. 0.1 + 0.2 == 0.3?
   - 在计算机中 0.1 + 0.2 并不等于完整的 0.3,因为有的⼩数⽆法⽤「完整」的⼆进制来表示，所以计算机⾥只能采⽤近似数的⽅式来保存，那两个近似数相加，得到的必然也是⼀个近似数
   - 二进制只能准确表达2*除*尽的数字(即一直乘2可以得到整数)的值，但对于0.1，0.2等都无法准确表达，需要精度舍入


### 2. 操作系统结构

#### 2.1 Linux内核与Windows内核

1. 内核
   - 作用
      内核作为应⽤连接硬件设备的桥梁，应⽤程序只需关⼼与内核交互，不⽤关⼼硬件的细节
   - 功能
     - 进程调度的能⼒，管理进程、线程，决定哪个进程、线程使⽤ CPU
     - 内存管理的能⼒，管理内存，决定内存的分配和回收
     - 硬件通信能⼒，管理硬件设备，为进程与硬件设备之间提供通信能⼒
     - 提供系统调用，是⽤户程序与操作系统之间的接⼝
   - 内核空间和用户空间
      用户空间的代码只能访问⼀个局部的内存空间，⽽内核空间的代码可以访问所有内存空间  
   - 用户态和内核态
      内核程序执⾏在内核态，⽤户程序执⾏在⽤户态。当应⽤程序使⽤系统调⽤时，会产⽣⼀个中断。发⽣中断后， CPU 会中断当前在执⾏的⽤户程序，转⽽跳转到中断处理程序，也就是开始执⾏内核程序。内核处理完后，主动触发中断，把 CPU 执⾏权限交回给⽤户程序，回到⽤户态继续⼯作

2. Linux设计
   - 多任务MutiTask
      多任务意味着可以有多个任务同时执⾏，这⾥的「同时」可以是并发或并⾏
      - 并发
      对于单核 CPU 时，可以让每个任务执⾏⼀⼩段时间，时间到就切换另外⼀个任务，从宏观⻆度看，⼀段时间内执⾏了多个任务，这被称为并发
      - 并行
      对于多核 CPU 时，多个任务可以同时被不同核⼼的 CPU 同时执⾏，这被称为并⾏
   - 对称多处理SMP
       - 代表着每个 CPU 的地位是相等的，对资源的使⽤权限也是相同的，多个 CPU共享同⼀个内存，每个 CPU 都可以访问完整的内存和硬件资源
       - Linux 操作系统不会有某个 CPU 单独服务应⽤程序或内核程序，⽽是每个程序都可以被分配到任意⼀个 CPU 上被执⾏
   - 可执⾏⽂件链接格式ELF
       - Linux 操作系统中可执⾏⽂件的存储格式
       - 我们编写的代码，⾸先通过「编译器」编译成汇编代码，接着通过「汇编器」变成⽬标代码，也就是⽬标⽂件，最后通过「链接器」把多个⽬标⽂件以及调⽤的各种函数库链接起来，形成⼀个可执⾏⽂件即ELF⽂件。最好通过「装载器」把 ELF ⽂件装载到内存⾥， CPU 读取内存中的指令和数据，于是程序就被执⾏起来了
   - 宏内核Monolithic Kernel（Linux）
       - Linux 内核架构就是宏内核，是⼀个完整的可执⾏程序，且拥有最⾼的权限
       - 特征是系统内核的所有模块，⽐如进程调度、内存管理、⽂件系统、设备驱动等，都运⾏在内核态。也可以动态加载内核模块，如设备驱动可以和其他模块解耦
       - 微内核（鸿蒙系统）
         - 只保留最基本的能⼒，⽐如进程调度、虚拟机内存、中断等，把⼀些应⽤放到了⽤户空间，⽐如驱动程序、⽂件系统等
         - 服务与服务之间是隔离，提⾼了操作系统的稳定性和可移植性。但驱动和硬件设备交互就需要切换到内核态导致性能损失
       - 混合类型内核（Windows）
         是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有⼀个⼩型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序

3. Windows设计
   - 同样支持多任务和对称多处理
   - Window 的内核设计是混合型内核，内核中有⼀个 MicroKernel 模块
   - Windows 的可执⾏⽂件格式叫 PE，称为可移植执⾏⽂件，扩展名通常是.exe、.dll、.sys等

### 3. 内存管理

#### 3.1 虚拟内存
1. 虚拟内存
   - 原因
      绝对物理地址会导致不能同时运行多个程序(单片机)，让操作系统为每个进程分配独⽴的⼀套「虚拟地址」，可以把进程所使⽤的地址「隔离」
   - 虚拟内存地址（Virtual Memory Address）
      程序所使⽤的内存地址
   - 物理内存地址（Physical Memory Address）
      实际存在硬件⾥⾯的空间地址
   - 过程
      进程持有的虚拟地址会通过 CPU 芯⽚中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存
   - 如何映射
      内存分段和内存分⻚
2. 内存分段
   - 段
   程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。 不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来
   - 虚拟地址
      由两部分组成， 段选择⼦和段内偏移量
   - 段选择子
      在段寄存器中，由段号，特权等标志位
      - 段号
         段表的索引
      - 段表
         保存段的基地址，段的界限和特权等级
   - 段内偏移量
      介于0和段界限之间，段基地址加上段内偏移量得到物理内存地址
   - 流程
      通过虚拟地址中的段号找到段表中对应的基地址，再加上段内偏移量就可得到物理内存地址
   - 缺点
     - 内存碎片
       - 外部内存碎片
         产⽣了多个不连续的⼩物理内存，导致新的程序⽆法被装载
       - 内部内存碎⽚
         程序所有的内存都被装载到了物理内存，但有部分的内存可能不常使⽤，导致内存的浪费
     - 内存交换
       - 用于解决外部碎片问题，先将程序所占内存读到硬盘上，再从硬盘读回内存，但需要装载再其他已占用的内存后，这就空出了连续的内存空间
       - 内存交换空间，硬盘内用于内存与硬盘的交换。如linux系统内Swap空间
       - 性能瓶颈，硬盘访问速度慢，若交换空间过大，会导致机器卡顿

#### 3.2 内存分页
1. 分页
   分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩。这样⼀个连续并且尺⼨固定的内存空间，我们叫⻚（Page）
2. 页表
   虚拟地址与物理地址之间通过⻚表来映射
3. 缺⻚异常
   当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个缺⻚异常，进⼊系统内核空间分配物理内存、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏
4. 解决内存碎片和内存交换空间太大的问题
   - 页之间可以不连续，采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存
   - 内存空间不够，系统通过换出（Swap Out），释放其他正在运⾏的进程中的「最近没被使⽤」的内存⻚⾯，需要的时候，再换⼊（Swap In）。⼀次性写⼊磁盘的也只有少数⼏个⻚，不会花太多时间， 内存交换的效率就相对⽐较⾼
   - 分⻚的⽅式使得我们在加载程序的时候，不再需要⼀次性都把程序加载到物理内存中。映射之后，只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再加载到物理内存⾥⾯去
5. 如何映射
  - 虚拟地址:页号，页内偏移
  - 页表：包含物理页每页所在物理内存基地址
  - 步骤
    - 把虚拟内存地址，切分成⻚号和偏移量
    - 根据⻚号，从⻚表⾥⾯，查询对应的物理⻚号
    - 物理⻚号，加上前⾯的偏移量，就得到了物理内存地址
6. 简单分页缺陷
   有空间上的缺陷：
   32位，虚拟内存地址有4GB(2^32)，页大小为4KB(2^12)，需要100万(2^20)个页，每个页表项需要4byte，则需要4MB内存存储一个线程的页表。100个线程则需要400MB内存，开销非常大
7. 多级页表
   - ⻚表（⼀级⻚表）分为 1024 个⻚表（⼆级⻚表），每个表（⼆级⻚表）中包含 1024 个「⻚表项」，形成⼆级分⻚
   - 映射 4GB 地址空间就需要 4KB（⼀级⻚表） + 4MB（⼆级⻚表）的内存，占用空间更大？
     - 往往不会为⼀个进程分配那么多内存
     - 局部性原理
         如果使⽤了⼆级分⻚，⼀级⻚表（4kb）就可以覆盖整个 4GB 虚拟地址空间，但如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即可以在需要时才创建⼆级⻚表。若只有20%一级页表项被使用，则消耗内存空间为:4KB（⼀级⻚表） + 20% * 4MB（⼆级⻚表） = 0.804MB <<4MB
   - 单极页表无法节约内存
      ⻚表⼀定要覆盖全部虚拟地址空间，虚拟地址在⻚表中找不到对应的⻚表项，计算机系统无法工作。不分级的⻚表就需要有 100 多万个⻚表项来映射，⽽⼆级分⻚则只需要 1024 个⻚表项（此时⼀级⻚表覆盖到了全部虚拟地址空间，⼆级⻚表在需要时创建）
   - 64位系统：四级目录
      - 全局⻚⽬录项 PGD（Page Global Directory）
      - 上层⻚⽬录项 PUD（Page Upper Directory）
      - 中间⻚⽬录项 PMD（Page Middle Directory）
      - ⻚表项 PTE（Page Table Entry）
   - ⻚表缓存TLB（Translation Lookaside Buffer）
     - 多级页表节约空间但由于多层的地址转换降低了虚拟地址到物理地址转换的效率，增加了时间开销
     - 程序具有局部性，⼀段时间内，整个程序的执⾏仅限于程序中的某⼀部分。相应地，执⾏所访问的存储空间也局限于某个内存区域
     - 最常访问的⼏个⻚表项存储到访问速度更快的硬件Cache，即页表缓存
     - CPU内内存管理单元（Memory Management Unit）芯⽚，它⽤来完成地址转换和 TLB的访问与交互。CPU寻址时先查TLB再查常规页表
     - TLB命中率很高，程序最常访问的⻚并不多
8. 段⻚式内存管理
   - 实现方式
     - 先将程序划分为多个有逻辑意义的段
     - 接着再把每个段划分为多个⻚，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚，页在段内可以不连续
   - 地址结构：段号、段内⻚号和⻚内位移
   - 三次内存访问
     - 第⼀次访问段表，通过段号得到⻚表起始地址
     - 第⼆次访问⻚表，通过页号得到物理⻚号
     - 第三次将物理⻚号与⻚内位移组合，得到物理地址
   - 增加了硬件成本和系统开销，但提⾼了内存的利⽤率
9. Linux内存管理
   - 各种地址
     - 逻辑地址，程序所使⽤的地址，通常是没被段式内存管理映射的地址
     - 线性地址(虚拟地址)通过段式内存管理映射的地址
   - Linux 内存主要采⽤的是⻚式内存管理,但由于Intel处理器发展历史，先段后页
   - 使段式映射不起作用
    把所有段的基地址设为 0 ，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被⽤于访问控制和内存保护
   - 内核空间和用户空间
     - 32位：1G，3G；64位：128T，128T，其余未定义
     - 进程在⽤户态时，只能访问⽤户空间内存
     - 进程在内核态后，才可以访问内核空间的内存
     - 每个进程都各⾃有独⽴的虚拟内存，但每个虚拟内存中的内核地址，其实关联的都是相同的物理内存，即共有同一内核空间
   - 用户空间内存，由低到高7种不同内存段
     - 程序⽂件段，包括⼆进制可执⾏代码
     - 已初始化数据段，包括静态常量
     - 未初始化数据段，包括未初始化的静态变量
     - 堆段，包括动态分配的内存，malloc()
     - ⽂件映射段，包括动态库、共享内存等mmap()
     - 栈段，包括局部变量和函数调⽤的上下⽂等。栈的⼤⼩是固定的，⼀般是 8 MB,也可自定义
  
### 4. 进程与线程

#### 4.1 基础知识
1. 进程
   - 进程
      静态文件编译后形成二进制可执行文件，运行后被装载至内存，CPU执行其命令，这个运行中的程序被称为进程
   - 并发和并行
      - 例:有⼀个会读取硬盘⽂件数据的程序被执⾏，读取⽂件时，由于硬盘的读写速度⾮常慢，CPU 不需要阻塞等待数据的返回，⽽是去执⾏另外的进程。当硬盘数据返回时， CPU 会收到个中断，于是 CPU 再继续运⾏这个进程
      - 多个程序、交替执⾏
   - 进程的状态
     - 创建状态（new）：进程正在被创建时的状态
     - 运⾏状态（Runing）：该时刻进程占⽤ CPU
     - 就绪状态（Ready）：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏
     - 阻塞状态（Blocked）：该进程正在等待某⼀事件发⽣（如等待输⼊/输出操作的完成）⽽暂时停⽌运⾏，这时，即使给它CPU控制权，它也⽆法运⾏
     - 结束状态（Exit）：进程正在从系统中消失时的状态
     - 挂起状态：描述进程没有占⽤实际的物理内存空间的情况
       - 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现
       - 就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏
       - 若有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运⾏的时候，再从硬盘换⼊到物理内存
       - 导致进程挂起的原因
         - 进程所使⽤的内存空间不在物理内存
         - 通过 sleep 让进程间歇性挂起
         - ⽤户希望挂起⼀个程序的执⾏，如Ctrl + Z
   - 进程的控制结构
     - 进程控制块PCB
       - PCB 是进程存在的唯⼀标识
       - 进程描述信息
         - 进程标识符：标识各个进程，每个进程都有⼀个并且唯⼀的标识符
         - ⽤户标识符：进程归属的⽤户，⽤户标识符主要为共享和保护服务
       - 进程控制和管理信息
         - 进程当前状态，如 new、 ready、 running、 waiting 或 blocked
         - 进程优先级：进程抢占 CPU 时的优先级
       - 资源分配清单
         - 有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使⽤的 I/O 设备信息
       - CPU 相关信息
         - CPU 中各个寄存器的值，当进程被切换时， CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执⾏时，能从断点处继续执⾏
     - PCB组织方式
       - 通过链表的⽅式进⾏组织，把具有相同状态的进程链在⼀起，组成各种队列
         - 就绪队列
         - 阻塞队列
         - 单核CPU只有一个运行指针
       - 索引方式
         - 索引表：同⼀状态的进程组织在⼀个索引表，索引表项指向相应的 PCB，不同状态对应不同的索引表
         - 因为进程增删操作多，所以一般采用链表
   - 进程的控制
     - 创建进程
       - 子进程继承父进程资源，终止时交还资源。终止父进程会同时终止所有子进程。但在具体操作系统中，有各自的实现方式。如Linux会把子进程交给1号进程
       - 分配PCB,PCB有限，无则创建失败
       - 分配资源，没有则进入等待状态
       - 初始化PCB
       - PCB插入就绪队列
     - 终止进程
       - 查找PCB
       - 终止执行，将CPU资源分配给其他进程
       - 终止子进程，交还资源给父进程
       - 从PCB队列中删除
     - 阻塞进程
       - 只能由另⼀个进程唤醒,有阻塞语句必有对应的唤醒语句
       - 查找PCB
       - 保护其线程，转为阻塞状态
       - PCB插入阻塞队列
     - 唤醒进程
       - 从阻塞队列中查找PCB
       - 移出并转为就绪状态
       - 插入就绪队列等待调度
   - 进程的上下文切换
     - CPU 上下⽂
         CPU 寄存器和程序计数器是 CPU 在运⾏任何任务前，所必须依赖的环境，称为CPU上下文
     - 上下文切换
         先把前⼀个任务的 CPU 上下⽂（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下⽂到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运⾏新任务
     - 切换内容
         进程是由内核管理和调度的，所以进程的切换只能发⽣在内核态。进程的上下⽂切换不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。这些信息都保存在PCB中
     - 切换场景
       - 公平调度时，一个进程时间片耗尽切换下一个进程
       - 系统资源不⾜（⽐如内存不⾜）时，要等到资源满⾜后才可以运⾏，这个时候进程也会被挂起，并由系统调度其他进程运⾏
       - sleep主动挂起
       - 调用高优先级进程
       - 硬件中断，中断挂起

2. 线程
   - 单进程和多进程的缺点
     - 单进程:函数之间不是并发执⾏，影响资源的使⽤效率
     - 多进程:进程之间如何通信，共享数据；维护进程的系统开销较⼤；
   - 线程
     - 线程是进程当中的⼀条执⾏流程
     - 线程之间可以并发运⾏且共享相同的地址空间，但每个线程各⾃都有⼀套独⽴的寄存器和栈，这样可以确保线程的控制流是相对独⽴的
     - 优点
       - ⼀个进程中可以同时存在多个线程
       - 各个线程之间可以并发执⾏
       - 各个线程之间可以共享地址空间和⽂件等资源
     - 缺点
       - 当进程中的⼀个线程崩溃时，会导致其所属进程的所有线程崩溃
       - 例：游戏的用户设计不应该使用多线程
   - 线程与进程的比较
     - 线程的创建时间⽐进程快，因为线程创建时不涉及资源管理信息而是共享它们，但进程需要
     - 线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多
     - 同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同⼀个进程的线程都具有同⼀个⻚表，切换时不需要切换⻚表。⽽对于进程，切换的时候要切换⻚表，⽽⻚表的切换过程开销是⽐较⼤的
     - 由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼
     - 最大区别:线程是调度的基本单位，⽽进程则是资源拥有的基本单0位
   - 线程的上下文切换
     - 线程和进程
       - 当进程只有⼀个线程时，可以认为进程就等于线程
       - 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下⽂切换时是不需要修改的
       - 线程也有⾃⼰的私有数据，⽐如栈和寄存器等，这些在上下⽂切换时也是需要保存的
     - 线程上下⽂切换的内容
       - 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样
       - 当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据
   - 线程的实现
     - 用户线程（User Thread） 
       - 在⽤户空间实现的线程，不是由内核管理的线程，是由⽤户态的线程库来完成线程的管理；
       - 多对⼀的关系，也就是多个⽤户线程对应同⼀个内核线程
       - 线程控制块（Thread Control Block, TCB） 也是在库⾥实现，操作系统看不到TCB只能看到整个进程的PCB
       - ⽤户线程的整个线程管理和调度，操作系统是不直接参与的，⽽是由⽤户级线程库函数来完成线程的管理，包括线程的创建、终⽌、同步和调度等
       - 优点
         - TCB 由⽤户级线程库函数来维护，可⽤于不⽀持线程技术的操作系统
         - ⽤户线程的切换也是由线程库函数来完成的，⽆需⽤户态与内核态的切换，时间开销小
       - 缺点
         - 操作系统无法管理用户线程，所以线程因发起系统调用而阻塞，进程其他用户线程都无法执行。并且当线程开始运行后，除非其主动交出CPU使用权，否则其他线程无法运行
         - 分配给每个进程的时间片一样，所以多线程执⾏时，每个线程得到的时间⽚较少，执⾏会⽐较慢
     - 内核线程（Kernel Thread）
       - 在内核中实现的线程，是由内核管理的线程
       - ⼀对⼀的关系，即⼀个⽤户线程对应⼀个内核线程
       - 优点
         - 在⼀个进程当中，如果某个内核线程发起系统调⽤⽽被阻塞，并不会影响其他内核线程的运⾏
         - 分配给线程，多线程的进程获得更多的 CPU 运⾏时间
       - 缺点
         - 需要支持线程技术的操作系统，由内核来维护进程和线程的上下⽂信息，如PCB和TCB
         - 线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，系统开销⽐较⼤
     - 轻量级进程（Light-weight process， LWP）
       - 是内核⽀持的⽤户线程，⼀个进程可有⼀个或多个 LWP，每个 LWP 是跟内核线程⼀对⼀映射的，也就是 LWP 都是由⼀个内核线程⽀持
       - LWP与普通进程的区别也在于它只有⼀个最⼩的执⾏上下⽂和调度程序所需的统计信息。LWP代表程序的执行线程，不需要那么多状态信息
       - 1 : 1 模式，即⼀个 LWP 对应 ⼀个⽤户线程
         - 优点：实现并⾏，当⼀个 LWP 阻塞，不会影响其他 LWP
         - 缺点：每⼀个⽤户线程，就产⽣⼀个内核线程，创建线程的开销较⼤
       - N : 1 ，即⼀个 LWP 对应多个⽤户线程
         - 优点：⽤户线程要开⼏个都没问题，且上下⽂切换发⽣⽤户空间，切换的效率较⾼
         - 缺点：⼀个⽤户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，**无法充分利⽤CPU**
       - M : N ，即多个 LMP 对应多个⽤户线程
         - 优点：综合了前两种优点，⼤部分的线程上下⽂发⽣在⽤户空间，且多个线程⼜可以充分利⽤多核CPU的资源
         - 线程是可以在多个不同CPU内并行执行，LWP为执行线程，当然LWP内的线程就必须在同一CPU内
       - 组合模式：结合以上模型，针对不同的应⽤特点调节内核线程的数⽬来达到物理并⾏性（并行）和逻辑并⾏性（并发）的最佳⽅案

3. 调度
   - 选择⼀个进程运⾏这⼀功能是在操作系统中完成的，通常称为调度程序（scheduler）
   - 调度时机
     - 根据状态的变化
       - 从就绪态 -> 运⾏态：当进程被创建时，会进⼊到就绪队列，操作系统会从就绪队列选择⼀个进程运⾏；
       - 从运⾏态 -> 阻塞态：当进程发⽣ I/O 事件⽽阻塞时，操作系统必须另外⼀个进程运⾏；
       - 从运⾏态 -> 结束态：当进程退出结束后，操作系统得从就绪队列选择另外⼀个进程运⾏；
     - 根据如何处理时钟中断
       - ⾮抢占式调度算法挑选⼀个进程，然后让该进程运⾏直到被阻塞，或者直到该进程退出，才会调⽤另外⼀个进程，不理会时钟中断
       - 抢占式调度算法挑选⼀个进程，然后让该进程只运⾏某段时间，如果在该时段结束时，该进程仍然在运⾏时，则会把它挂起，接着调度程序从就绪队列挑选另外⼀个进程。这种抢占式调度处理，需要在时间间隔的末端发⽣时钟中断，以便把 CPU 控制返回给调度程序进⾏调度，也就是常说的时间⽚机制
   - 调度原则
     - CPU 利⽤率：调度程序应确保 CPU 是始终匆忙的状态，这可提⾼ CPU 的利⽤率
     - 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，⻓作业的进程会占⽤较⻓的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量
     - 周转时间：周转时间是进程运⾏和阻塞时间总和，⼀个进程的周转时间越⼩越好
     - 等待时间：这个等待时间不是阻塞状态的时间，⽽是进程处于就绪队列的时间，等待的时间越⻓，⽤户越不满意
     - 响应时间：⽤户提交请求到系统第⼀次产⽣响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准
   - 调度算法
     - 在单核 CPU 系统中常⻅的调度算法
     - 先来先服务调度算法（First Come First Seved, FCFS）
       - 每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个进程接着运⾏
       - FCFS 对⻓作业有利，适⽤于 CPU 繁忙型作业的系统，⽽不适⽤于 I/O 繁忙型作业的系统。i/o型作业执行时，要经常i/o,它一i/o，就要放弃cpu，到队尾重新排队。而计算型作业一旦得到cpu，就能一直执行。
     - 最短作业优先调度算法（Shortest Job First, SJF）
       - 优先选择运⾏时间最短的进程来运⾏
       - 对于长作业不利
     - ⾼响应⽐优先调度算法（Highest Response Ratio Next, HRRN）
       - 每次把响应⽐优先级」最⾼的进程投⼊运⾏
       - 优先权 = (等待时间 + 要求服务时间)/要求服务时间
       - 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应⽐」就越⾼，这样短作业的进程容易被选中运⾏
       - 如果两个进程「要求的服务时间」相同时，「等待时间」越⻓，「响应⽐」就越⾼，这就兼顾到了⻓作业进程，因为进程的响应⽐可以随时间等待的增加⽽提⾼，当其等待时间⾜够⻓时，其响应⽐便可以升到很⾼，从⽽获得运⾏的机会
     - 时间⽚轮转调度算法（Round Robin, RR）
       - 每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏，平权
       - 如果时间⽚⽤完，进程还在运⾏，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外⼀个进程
       - 如果该进程在时间⽚结束前阻塞或结束，则 CPU ⽴即进⾏切换
       - 如果时间⽚设得太短会导致过多的进程上下⽂切换，降低了 CPU 效率
       - 如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓
       - ⼀般来说，时间⽚设为 20ms~50ms
     - 最⾼优先级调度算法（Highest Priority First， HPF）
       - 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运⾏时间优先级都不会变化；
       - 动态优先级：随着时间的推移增加等待进程的优先级
       - ⾮抢占式：当就绪队列中出现优先级⾼的进程，运⾏完当前进程，再选择优先级⾼的进程
       - 抢占式：当就绪队列中出现优先级⾼的进程，当前进程挂起，调度优先级⾼的进程运⾏
       - 缺点:导致低优先级的进程永远不会运⾏
     - 多级反馈队列调度算法（Multilevel Feedback Queue,MFQ）
       - 「多级」表示有多个队列，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短
       - 「反馈」表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列
       - 如何工作
         - 「反馈」表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列
         - 新的进程会被放⼊到第⼀级队列的末尾，按先来先服务的原则排队等待被调度，如果在第⼀级队列规定的时间⽚没运⾏完成，则将其转⼊到第⼆级队列的末尾，以此类推，直⾄完成
         - 当较⾼优先级的队列为空，才调度较低优先级的队列中的进程运⾏。如果进程运⾏时，有新进程进⼊较⾼优先级的队列，则停⽌当前运⾏的进程并将其移⼊到原队列末尾，接着让较⾼优先级的进程运⾏
       - 优点
         对于短作业可能可以在第⼀级队列很快被处理完。对于⻓作业，如果在第⼀级队列处理不完，可以移⼊下次队列等待被执⾏，虽然等待的时间变⻓了，但是运⾏时间也变更⻓了，所以该算法很好的兼顾了⻓短作业，同时有较好的响应时间
      