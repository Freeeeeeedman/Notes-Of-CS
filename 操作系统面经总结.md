#### 操作系统面经总结

#### 1. 硬件结构
1. 说一说冯诺依曼模型
   - 中央处理器（CPU）
        CPU用于计算，32位宽：4字节，64位宽：8字节。
        寄存器：通⽤寄存器：⽤来存放需要进⾏运算的数据
                程序计数器：⽤来存储 CPU 要执⾏下⼀条指令「所在的内存地址」
                指令寄存器：⽤来存放程序计数器指向的指令
        控制单元
        逻辑运算单元
   - 内存
        程序和数据都是存储在内存
   - 输⼊设备
   - 输出设备
   - 总线
        ⽤于 CPU 和内存以及其他设备之间的通信
        地址总线，数据总线，控制总线
2. 说一说CPU 执⾏程序的过程
    ⼀个程序执⾏的时候， CPU 会根据程序计数器⾥的内存地址，从内存⾥⾯把需要执⾏的指令读取到指令寄存器⾥⾯执⾏，然后根据指令⻓度⾃增，开始顺序读取下⼀条指令
3. 如何让程序跑的更快？
    程序的CPU执行时间 = CPU 时钟周期数 X 时钟周期时间 = 指令数 X 每天指令的平均时钟周期数 X 时钟周期时间
    编译器优化减少指令数
    减少 每天指令的平均时钟周期数、
    提高CPU主频，减少时钟周期时间
4. 64 位相⽐ 32 位 CPU 的优势在哪吗？ 64 位 CPU 的计算性能⼀定⽐ 32 位 CPU ⾼很多吗
    - 64 位 CPU 可以⼀次计算超过 32 位的数字，⽽ 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进⾏计算，效率就没那么⾼，但是⼤部分应⽤程序很少会计算那么⼤的数字，所以只有运算⼤数字的时候， 64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不⼤。
    - 64 位 CPU 可以寻址更⼤的内存空间
5. 你知道软件的 32 位和 64 位之间的区别吗？再来 32 位的操作系统可以运⾏在 64 位的电脑上吗？ 64 位的操作系统可以运⾏在 32 位的电脑上吗？如果不⾏，原因是什么？
    - 64 位和 32 位软件，实际上代表指令是 64 位还是 32 位的
    - 如果 32 位指令在 64 位机器上执⾏，需要⼀套兼容机制，就可以做到兼容运⾏了。但是如果 64 位指令在 32 位机器上执⾏，就⽐较困难了，因为 32 位的寄存器存不下 64 位的指令；
    - 硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽
6. 说一说计算机存储器的层次结构（CPU如何读取数据）
   每⼀种存储器设备只和它相邻的存储器设备打交道
   -  CPU 中的寄存器
   -  CPU ⾼速缓存，CPU Cache
   -  内存
   -  硬盘
7. 如何写出让 CPU 跑得更快的代码？（如何写出 CPU 缓存命中率⾼的代码？）
   - 提高数据缓存的命中率
        CPU Cache每次会顺序存放多个额外数据。所以遇到这种遍历数组的情况时，按照内存布局顺序访问，就可以提高数据缓存的命中率
   - 提高指令缓存的命中率
        CPU有分支预测器，对于if语句可以预测，提前把可能的指令放到CPU缓存中。所以如果数组中的元素随机的，就不太管用。C++编译器中有宏可以使用。一般CPU ⾃身的动态分⽀预测已经是⽐较准了。
   - 提高多核 CPU 的缓存命中率
        进程可能在不同 CPU 核⼼来回切换执⾏，这对 CPU Cache 不是有利的，如果⼀个进程在不同核⼼来回切换，各个核⼼的缓存命中率就会受到影响。把线程绑定在某⼀个 CPU 核⼼上，提高缓存命中率，意味着 CPU 可以减少访问 内存的频率，提升性能。
8. 中断是什么？
    中断是系统⽤来响应硬件设备请求的⼀种机制，操作系统收到硬件的，中断请求，会打断正在执⾏的进程，然后调⽤内核中的中断处理程序来响应请求，是⼀种异步的事件处理机制，可以提⾼系统的并发处理能⼒。又有外中断，内中断，软中断，硬中断之分。
    一般中断处理程序分为两部分，上半部直接处理硬件请求，硬中断，耗时短快速执⾏，可能会屏蔽其他中断；下半部是由内核触发，软中断，负责上半部未完成的⼯作，耗时⽐较⻓，延迟执⾏。这样来避免中断处理程序执⾏过⻓和中断丢失的问题。
9. 说一说中断处理程序的处理流程
   1.  在 I/O 时，设备控制器如果已经准备好数据，则会通过中断控制器向 CPU 发送中断请求；
   2.  保护被中断进程的 CPU 上下⽂；
   3.  转⼊相应的设备中断处理函数；
   4.  进⾏中断处理；
   5.  恢复被中断进程的上下⽂；
10. 举例说明中断
    举例如网卡接受到网络包，会通过硬件中断通知内核有新的数据到了，于是内核就会调⽤对应的中断处理程序来响应该事件。先是硬中断快速处理，所以只要把⽹卡的数据读到内存中等。再是软中断延迟处理，把内存中的网络数据交给网络协议栈处理。
11. 外中断和异常（内中断）有什么区别？
   - 外中断是指由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。
   - 异常(内中断)是由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等
11. 软中断和硬中断有什么区别？
   - 软中断是可被调用执行的程序产生的中断。比如外部设备管理中断服务程序（键盘管理中断、显示器管理中断、打印机管理 中断等）
   - 硬件中断是由与系统相连的外设(比如网卡 硬盘 键盘等)自动产生的. 
12. 如何查看中断相关信息？
    软中断：/proc/softirqs
    硬中断：/proc/interrupts 
13. 如何定位软中断 CPU 使⽤率过⾼的问题？（如何定位网络IO过高的问题？）
    top，si，就是 CPU 在软中断上的使⽤率， CPU 使⽤率最⾼的进程也是软中断 ksoftirqd
    要知道是哪种软中断类型导致的，我们可以使⽤ watch -d cat /proc/softirqs 命令查看每个软中断类型的中断次数的变化速率。
    ⼀般对于⽹络 I/O ⽐较⾼的 Web 服务器， NET_RX ⽹络接收中断的变化速率相⽐其他中断类型快很多。如果发现 NET_RX ⽹络接收中断次数的变化速率过快，接下⾥就可以使⽤ sar -n DEV 查看⽹卡的⽹络包接收速率情况，然后分析是哪个⽹卡有⼤量的⽹络包进来。接着，在通过 tcpdump 抓包，分析这些包的来源，如果是⾮法的地址，可以考虑加防⽕墙，如果是正常流量，则要考虑硬件升级等。
14. 说一说计算机如何表示整数
    二进制表示，最⾼位是作为「符号标志位」，其余为表示二进制数据
15. 说一说计算机如何表示负数
    采用补码方式表示。把对应正数的⼆进制全部取反再加1。⽤了补码的表示⽅式，对于负数的二进制加减法操作，实际上是和正数的二进制加减法操作⼀样的。否则还要判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转成加法。
16. 说一说计算机如何表示小数
    乘2取整法表示，但对于有些小数是无法⼆进制精确的表示 0.1，只能⽤「近似值」来表示。在计算机中使用浮点数表示，将二进制数用科学记数法分为符号位，指数位，和尾数位。指数位表示范围，尾数位决定精度。比如float 32位单精度浮点数，指数位8位，尾数位23位，精度是log10（2^24）为7位。（IEEE标准规定首位必须位1，所以尾数位可以再加上1位隐藏位）
17. 为什么计算机中0.1 + 0.2 != 0.3?
    因为有的⼩数⽆法可以⽤「完整」的⼆进制来表示，所以计算机⾥只能采⽤近似数的⽅式来保存，那两个近似数相加，得到的必然也是⼀个近似数。
18. 什么是内核？
    内核是作为应⽤连接硬件设备的桥梁，应⽤程序只需关⼼与内核交互，不⽤关⼼硬件的细节
19. 内核具体有什么功能？
    进程调度，内存管理，硬件管理，系统调用
20. 内核是怎么工作的？
    ⽤户空间的代码只能访问⼀个局部的内存空间，⽽内核空间的代码可以访问所有内存空间。
    内核程序执⾏在内核态，⽤户程序执⾏在⽤户态。当应⽤程序使⽤系统调⽤时，会产⽣⼀个中断。发⽣中断后， CPU 会中断当前在执⾏的⽤户程序，转⽽跳转到中断处理程序，也就是开始执⾏内核程序。内核处理完后，主动触发中断，把 CPU 执⾏权限交回给⽤户程序，回到⽤户态继续⼯作。
#### 2. 进程管理
1. 程序是什么？
    程序是包含一系列信息的文件，这些信息描述了如何在运行时创建一个进程。
    包括：机器语言指令，数据（变量初始值），共享库和动态链接信息等等
2. 进程是什么？
    进程是正在运行的程序的实例，也是系统进行资源分配和调度的基本单位
3. 进程和程序的区别
   - 进程占用内存，CPU等资源，而程序只占用磁盘 
   - 进程是正在运行的程序的实例。 进程既是基本的分配单元，也是基本的执行单元。
   - 可以用一个程序来创建多个进程
4. 说一说进程的状态
   - 三态模型
        运⾏状态（Runing）：该时刻进程占⽤ CPU；
        就绪状态（Ready）：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏；
        阻塞状态（Blocked）：该进程正在等待某⼀事件发⽣（如等待输⼊/输出操作的完成）⽽暂时停⽌运⾏，这时，即使给它CPU控制权，它也⽆法运⾏；
   - 五态模型
        创建状态（new）：进程正在被创建时的状态；
        结束状态（Exit）：进程正在从系统中消失时的状态；
   - 七态模型
        挂起状态：描述进程没有占⽤实际的物理内存空间的情况
        阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
        就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏；
5. 说一说进程的状态变迁
        进程先是创建状态，然后进入就绪队列即就绪状态，被调用后进入运行状态，如果等待事件则进入阻塞状态。如果结束则进入结束状态。如果时间片用完或者等待的事件完成则进入就绪状态。如果进程运行中被挂起就进入就绪挂起状态，如果在阻塞状态被挂起就进入阻塞挂起状态。被激活后在进入就绪或阻塞状态
6. 为什么要把进程挂起？
    如果有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，应当把这些进程换出到硬盘
7. 导致进程挂起的原因是什么？
   - 进程所使⽤的内存空间不在物理内存
   - 通过 sleep 让进程间歇性挂起，其⼯作原理是设置⼀个定时器，到期后唤醒进程
   - ⽤户希望挂起⼀个程序的执⾏，⽐如在 Linux 中⽤ Ctrl+Z 挂起进程
8. 操作系统中用什么来描述进程？
    进程控制块（PCB），PCB 是进程存在的唯⼀标识
9.  PCB 具体包含什么信息呢？
   - 进程标识符
   - 进程状态
   - 优先级
   - 有关内存地址空间的信息与CPU 中各个寄存器的值以便进程上下文切换
11. 每个 PCB 是如何组织的呢？
   - 通常是通过链表的⽅式进⾏组织
   - 就绪队列：将所有处于就绪状态的进程链在⼀起
     阻塞队列：把所有因等待某事件⽽处于等待状态的进程链在⼀起
11. 说一说CPU的上下⽂切换
    - CPU上下⽂是CPU 在运⾏任何任务前，所必须依赖的环境，即CPU 寄存器和程序计数器。CPU 上下⽂切换就是先把前⼀个任务的 CPU 上下⽂保存起来，然后加载新任务的上下⽂，最后再跳转到程序计数器所指的新位置，运⾏新任务。
    - CPU 上下⽂切换分成： 进程上下⽂切换、线程上下⽂切换和中断上下⽂切换
12. 说一说进程的上下⽂切换
    - 各个进程之间是共享 CPU ，CPU从⼀个进程切换到另⼀个进程运⾏，称为进程的上下⽂切换
    - 进程的上下⽂切换不仅包含了虚拟地址空间、堆、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。通常，会把交换的信息保存在进程的 PCB，当要运⾏另外⼀个进程的时候，我们需要从这个进程的 PCB取出上下⽂，然后恢复到 CPU 中，这使得这个进程可以继续执⾏
13. 进程间共享什么？
    - 没有亲缘关系的进程
      - CPU
      - 共享内存
    - 父子进程fork()
      - 子进程内核空间拷贝父进程，但各自的PID不同
      - 子进程用户空间拷贝父进程，但读时共享，写时拷贝。需要写入时才复制地址空间，从而使各个进程拥有各自的地址空间
14. 发⽣进程上下⽂切换有哪些场景？
    - 进程的时间片用完
    - 系统资源不足时，进程会被挂起
    - sleep主动挂起
    - 高优先级进程先运行时被挂起
    - 硬件中断时被挂起，CPU来执行内核中的中断服务程序
15. 孤儿进程
        父进程运行结束，但子进程还在运行（未运行结束），这样的子进程就称为孤儿进程（Orphan Process）。孤儿资源没有危害，因为其资源最后会由init进程来进行回收
16. 僵尸进程
        子进程结束之后, 都会释放自己地址空间中的用户区数据，通过父进程释放掉内核区的 PCB数据。如果进程终止时，父进程尚未回收，子进程残留资源（PCB）存放于内核中，变成僵尸（Zombie）进程。会一直占用进程号，导致系统不能产生新的进程。一般通过让父进程调用wait()或waitpid()回收，或者直接结束父进程，让子进程变成孤儿进程。
17. 线程是什么？
    线程是进程当中的⼀条执⾏流程，是CPU执行的最基本单元。线程之间可以共享代码段、数据段等资源，但各自有⼀套独⽴的寄存器和栈
18. 为什么需要线程？
    - 进程间通信开销大
    - 维护进程的系统开销大，比如进程切换时，需要保存进程的上下文
19. 线程的优缺点？
    - 优点
        ⼀个进程中可以同时存在多个线程；
        各个线程之间可以并发执⾏；
        各个线程之间可以共享地址空间和⽂件等资源
    - 缺点
        当进程中的⼀个线程崩溃时，可能会导致其所属进程的所有线程崩溃。比如操作系统检测到异常，会kill掉进程，其他线程就一起被干掉了。
20. 线程相⽐进程能减少开销体现在哪里？
    - 线程的创建时间⽐进程快，因为进程在用fork（）创建的过程中，，即便利用写时复制技术，仍然需要复制诸如内存页表和文件描述符表之类的多种进程属性
    - 线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多；
    - 同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的；
    - 由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼了
21. 线程上下⽂切换的是什么？
    - 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样；
    - 当两个线程是属于同⼀个进程，内核空间，共享库，堆空间，bss段，data段，text段，但是栈空间，寄存器，程序计数器不共享
22. 协程是什么？
    协程是一种用户态的轻量级线程，协程的调度完全由用户控制。
23. 为什么需要协程？
    - 节省CPU，内核级别的线程切换开销大，浪费CPU资源。而协程是用户态的线程，用户可以自行控制协程的创建于销毁，避免了系统级线程上下文切换造成的资源浪费。
    - 节约内存：线程占用内存多，协程占用内存少可以实现高并发
    - 更稳定，一个线程崩溃可能会导致进程中的所有线程都会跟着一起崩溃。
    - 开发效率更高，适用于异步IO
24. 协程上下文切换的是什么？
    寄存器和栈
25. 进程、线程和协程的区别和联系
    - 定义
        进程：资源分配基本单位，线程：程序执行的基本单位，协程用户态的轻量级线程，线程内部调度的基本单位
    - 上下文切换内容不同
        进程：虚拟地址空间、堆、栈、全局变量等⽤户空间的资源，还包括了内核堆 、栈、寄存器等内核空间的资源
        线程：程序计数器，寄存器，线程栈
        协程：寄存器，协程栈
    - 状态转变
        进程、线程：用户态，内核态，用户态
        协程:用户态
    - 并发性
        不同进程之间切换实现并发
        一个进程内部的多个线程并发执行
        同一时间只能执行一个协程，而其他协程处于休眠状态
    - 系统开销不同
        进程：创建销毁切换开销很大，切换时还需要切换页表
        线程：创建销毁需要的资源都很少，切换不需要切换页表，只需要切换线程栈，寄存器与程序计数器
        协程：相较线程只在用户态，没有内核切换的开销
    - 通信方式不同
        进程：进程间通信，比如管道，共享内存，socket
        线程：共享内存，通过全局变量通信
        协程：共享内存
26. 一个进程可以创建多少线程，和什么有关？
    一个进程可以创建的线程数由可用虚拟空间和线程的栈的大小共同决定。理论上，一个进程可用虚拟空间是2G，默认情况下，线程的栈的大小是1MB，所以理论上最多只能创建2048个线程
27. 进程线程模型你知道多少？
    - 多进程
        - 进程是资源分配的基本单位。通过fork()创建子进程。子进程用户空间拷贝父进程，但读时共享，写时拷贝。需要写入时才复制地址空间，从而使各个进程拥有各自的地址空间。在命令行中执行文件创建的进程都是shell进程的子进程
        - 进程的上下文切换：...
        - 一些接口
            创建进程：pid_t fork(void);
            结束进程：void exit(int status);
    - 多线程
       -  线程是调度的基本单位。对于用户态的多线程模型，同一个进程内部有多个线程，所有的线程共享同一个进程的内存空间，进程中定义的全局变量会被所有的线程共享。
       -  多线程的优点是首先减少了多进程创建销毁以及进程上下文切换的大量开销。并且
        原先顺序执行的程序可以被拆分成几个独立的逻辑流，这些逻辑流可以独立完成一些任务。
       -  多线程的缺点是会带来多线程共享资源导致的互斥和同步问题，并且当进程中的⼀个线程崩溃时，可能会导致其所属进程的所有线程崩溃。
       -  多线程的接口有：
            创建线程：pthread_create
            终止线程：pthread_exit
            分离线程（自动回收线程资源）：pthread_detach
            连接已终止的线程（手动回收已终止的线程的资源）：int pthread_join

28. 说一说CPU调度的时机
    - 从就绪态 -> 运⾏态：当进程被创建时，会进⼊到就绪队列，操作系统会从就绪队列选择⼀个进程运⾏；
    - 从运⾏态 -> 阻塞态：当进程发⽣ I/O 事件⽽阻塞时，操作系统必须另外⼀个进程运⾏；
    - 从运⾏态 -> 结束态：当进程退出结束后，操作系统得从就绪队列选择另外⼀个进程运⾏
29. 说一说CPU调度算法（进程调度算法）
    - 先来先服务（First Come First Seved, FCFS）算法
        每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个进程接着运⾏。
        FCFS 对⻓作业有利，适⽤于 CPU 繁忙型作业的系统，⽽不适⽤于 I/O 繁忙型作业的系统
    - 最短作业优先（Shortest Job First, SJF）调度算法
        优先选择运⾏时间最短的进程来运⾏
        对⻓作业不利
    - ⾼响应⽐优先（Highest Response Ratio Next, HRRN）调度算法
        兼顾短作业和长作业，高响应比优先，响应比 = （等待时间 + 要求服务时间）/要求服务时间
    - 时间⽚轮转（Round Robin, RR）调度算法
        每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏。
        如果时间⽚设得太短会导致过多的进程上下⽂切换
        如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓
    - 最⾼优先级（Highest Priority First， HPF）调度算法
        静态优先级
        动态优先级：随着时间的推移增加等待进程的优先级
        ⾮抢占式和抢占式
    - 多级反馈队列（Multilevel Feedback Queue）调度算法
        多级表示有多个队列，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短。
        反馈表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列；
        这样对于短作业很快就能运行完，对于长作业，如果在第一个队列时间片内没运行完会转入到第二队列的末尾等待运行。兼顾了⻓短作业，同时有较好的响应时间
30. 说一说进程间通信的方式
    - 管道
    - 消息队列
    - 共享内存
    - 信号量
    - 信号
    - socket
31. 说一说线程间通信的方式
    - 共享内存（全局变量）
    - 信号
    - 信号量
    - 锁
    - 条件变量
32. 说一说管道
     int pipe(int pipefd[2]);
     int mkfifo(const char *pathname, mode_t mode);
     管道其实是一个在内核内存中维护的缓冲器。一段输入，一段读取。管道传输的数据是⽆格式的流且⼤⼩受限。匿名管道用于父子进程间通信，有名管道用于没有亲缘关系的进程间的通信。
33. 如何利用管道通信？
    对于匿名管道fork()后的父子进程共享同一文件描述符表，父子进程都拥有了管道的读端和写段。如果需要双向通信，则应该创建两个管道。而命名管道就需要通过管道文件作为媒介通信。
34. shell里管道命令实际是怎么工作的？
    shell ⾥⾯执⾏ A | B 命令的时候， A 进程和 B 进程都是 shell 创建出来的⼦进程， A 和 B 之间不存在⽗⼦关系，它俩的⽗进程都是 shell。在 shell ⾥通过「 | 」匿名管道将多个命令连接在⼀起，实际上也就是创建了多个⼦进程。在我们编写 shell 脚本时，能使⽤⼀个管道搞定的事情，就不要多⽤⼀个管道，这样可以减少创建⼦进程的系统开销。
35. 说一说消息队列
    管道的通信⽅式是效率低的，因此管道不适合进程间频繁地交换数据，消息队列解决了这个问题。消息队列是保存在内核中的消息链表，以消息体的格式发生数据。每个消息体都是固定⼤⼩的存储块，不像管道是⽆格式的字节流数据。
36. 说一说消息队列和管道的区别
    - 传输的格式不同
    - 通信效率不同
    - 生命周期不同，消息队列⽣命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会⼀直存在，⽽匿名管道是随进程的创建⽽建⽴，随进程的结束⽽销毁
37. 说一说消息队列的缺点
    - 消息队列不适合⽐较⼤数据的传输，消息体有长度限制
    - 消息队列通信过程中，存在⽤户态与内核态之间的数据拷⻉开销，因为进程写⼊数据到内核中的消息队列时，会发⽣从⽤户态拷⻉数据到内核态的过程，同理另⼀进程读取内核中的消息数据时，会发⽣从内核态拷⻉数据到⽤户态的过程。
38. 说一说共享内存
    int shmget(key_t key, size_t size, int shmflg);
    共享内存是效率最高的一种进程间通信方式，共享内存的机制，就是不同的进程拿出⼀块虚拟地址空间来，映射到相同的物理内存中。
39. 共享内存效率高在哪里？
    不需要像管道或者消息队列一样，存在⽤户态与内核态之间的数据拷⻉开销，也不需要频繁切换用户态和内核态
40. 说一说条件变量
    pthread_cond_t，使用通知的方式解锁，与互斥锁配合使用。条件变量不是锁，当满足某个条件时，条件变量可以阻塞线程或者解除阻塞。解决不了线程同步问题。
41. 说一说信号量
    使用共享内存通信会导致多进程竞争共享资源造成数据错乱。信号量其实就是⼀个整型的计数器，就可以实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。通常信号量表示资源的数量，对应的变量是⼀个整型（ sem ）变量。两个原⼦操作的系统调⽤函数来控制信号量的。P操作信号量-1，如果sem<0, 阻塞。V操作信号量+1，如果sem>=0,唤醒。
42. 信号量是如何实现进程/线程间的互斥与同步的？
    进程：共享内存，线程:全局变量
    信号量：sem_t
    互斥：初始化信号量为 1，A进程通过P操作减1，访问到共享内存。B进程经过P操作后发现信号量<0,阻塞。A处理完后V操作，信号量为0，B被唤醒 
    同步：初始化信号量为 0，线程B先通过P操作建1阻塞，此时线程A如果完成动作后执行V操作，则B被唤醒
43. 说一说信号
    raise()
    信号是进程间通信机制中唯⼀的异步通信机制。因为可以在任何时候发送信号给某⼀进程，⼀旦有信号产生，就有3种处理方式
    - 常见信号：SIGKILL, SIGSTOP, SIGALARM
    - 执行默认操作
    - 捕捉信号，执行相应的信号处理函数（signal，sigaction）
    - 忽略信号，但是SIGKILL和SIGSTOP无法忽视或者捕捉
44. 说一说socket
     int socket(int domain, int type, int protocal)
     Socket 通信不仅可以跨⽹络与不同主机的进程间通信，还可以在同主机上进程间通信。还可以指定通信的方式，如TCP,UDP还是本地进程间字节流通信
45. 针对 TCP 协议通信的 socket 编程模型
    服务端和客户端初始化 socket ，得到⽂件描述符；
    服务端调⽤ bind ，将绑定在 IP 地址和端⼝;
    服务端调⽤ listen ，进⾏监听；
    服务端调⽤ accept ，等待客户端连接；
    客户端调⽤ connect ，向服务器端的地址和端⼝发起连接请求；
    服务端 accept 返回⽤于传输的 socket 的⽂件描述符；
    客户端调⽤ write 写⼊数据；服务端调⽤ read 读取数据；
    客户端断开连接时，会调⽤ close ，那么服务端 read 读取数据的时候，就会读取到了 EOF ，待处理完数据后，服务端调⽤ close ，表示连接关闭。
    监听 socket，已完成连接 socket
46. 针对 UDP 协议通信的 socket 编程模型
    UDP 是没有连接的，不需要三次握⼿，只需要IP地址和端口号
    客户端/服务端：socket()初始化，bind()绑定IP和端口，再通过sendto()和recvfrom()传输数据
47. 针对本地进程间通信的 socket 编程模型
    本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端⼝，⽽是绑定⼀个本地⽂件
48. 为什么会发生多进程（线程）竞争共享资源造成数据错乱？
    因为实际进程（线程）运行过程种调度不可控不可知，比如对共享内存中的一个数字进行修改大概分为三个步骤，从内存中取值并放入寄存器，寄存器修改值，值放回内存。可能进程（线程）只执行了1，2步切换到另一个（进程）线程，而这个（进程）线程重复的完整执行了三个步骤，这时候又切换到第一个（进程）线程,则又会执行第三部，相当于第二个（进程）线程未做修改。
49. 说一说互斥
    保证⼀个线程在临界区执⾏时，其他线程应该被阻⽌进⼊临界区。互斥也并不是只针对多线程。在多进程竞争共享资源的时候，也同样是可以使⽤互斥的⽅式来避免资源竞争造成的资源混乱。
50. 说一说同步
    同步，就是并发进程/线程在⼀些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。
52. 一般如何实现多线程的互斥与同步？
    - 锁，使⽤加锁操作和解锁操作可以解决并发线程/进程的互斥问题
        「忙等待锁」，⾃旋锁（spin lock），⼀直while⾃旋，利⽤ CPU 周期，直到锁可⽤
        「⽆等待锁」，就把当前线程放⼊到锁的等待队列，然后执⾏调度程序，把 CPU让给其他线程执⾏。
    - 信号量
       信号量其实就是⼀个整型的计数器，就可以实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。通常信号量表示资源的数量，对应的变量是⼀个整型（ sem ）变量。两个原⼦操作的系统调⽤函数来控制信号量的。P操作信号量-1，如果sem<0, 阻塞。V操作信号量+1，如果sem>=0,唤醒。



#### 3. 内存管理
1. 什么是内存？作用是什么？
    内存是用于存放数据的硬件，程序执行前需要先存放到内存中才能被CPU处理。
2. 什么时虚拟内存地址？
    操作系统为每个进程分配独⽴的⼀套「虚拟地址」，将不同进程的虚拟地址和不同内存的物理地址映射起来
3. 虚拟内存的目的是什么？
    - 隔离进程间的内存地址。因为如果进程使用绝对物理地址，会导致互相会产生冲突。而且进程能够直接访问物理地址是一种不安全的方式。
    - 可以让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。进⾏虚拟内存和物理内存的⻚之间的映射之后，并不真的把⻚加载到物理内存⾥，⽽是只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再从磁盘加载到物理内存⾥⾯去。
4. 操作系统是如何管理虚拟地址与物理地址之间的关系？
   内存分段和内存分⻚
5. 说一说内存分段
   程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。 不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来。
6. 分段机制下，虚拟地址和物理地址是如何映射的？
    分段机制下的虚拟地址由两部分组成， 段选择⼦和段内偏移量。通过段选择子得到段表保存的段基地址，段基地址加上段内偏移量得到物理内存地址
7. 分段机制会导致什么问题？
    - 内存碎⽚
        外部内存碎⽚，也就是产⽣了多个不连续的⼩物理内存，导致新的程序⽆法被装载；
        内部内存碎⽚，程序所有的内存都被装载到了物理内存，部分内存并不常⽤，导致浪费；
    - 内存交换的效率低
        解决外部内存碎片采用内存交换的方式，即把这下不连续的内存碎片先写到硬盘再读回内存
        多进程的系统来说，⽤分段的⽅式，很容易产⽣内存碎⽚，但硬盘速度很慢，如果内存交换的时候，交换的是⼀个占内存空间很⼤的程序，开销很大
8.  说一说分页机制
    分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩称为页，在 Linux 下，每⼀⻚的⼤⼩为 4KB，虚拟地址与物理地址之间通过⻚表来映射.分页可以解决分段的内存碎⽚、内存交换效率低的问题
    ⻚表是存储在内存⾥的， 内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的⼯作
9.  分⻚是怎么解决分段的内存碎⽚、内存交换效率低的问题？
   - 内存空间都是预先划分好的，也就不会像分段会产⽣间隙⾮常⼩的内存,采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存
   - 如果内存空间不够，操作系统会把其他正在运⾏的进程中的「最近没被使⽤」的内存⻚⾯给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。⼀旦需要的时候，再加载进来，称为换⼊（Swap In）。所以，⼀次性写⼊磁盘的也只有少数的⼀个⻚或者⼏个⻚，不会花太多时间， 内存交换的效率就相对⽐较⾼。
   - 分⻚的⽅式使得我们在加载程序的时候，不再需要⼀次性都把程序加载到物理内存中。我们完全可以在进⾏虚拟内存和物理内存的⻚之间的映射之后，并不真的把⻚加载到物理内存⾥，⽽是只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再加载到物理内存⾥⾯去。
12. 分⻚机制下，虚拟地址和物理地址是如何映射的？
    - 简单页表
        对于简单的页表,虚拟地址分为两部分， ⻚号和⻚内偏移.通过页号找到页表中的对应的物理内存的基地址,加上页内偏移就得到了物理内存地址
        但简单页表会有空间上的缺陷.对于32位,虚拟地址4GB,需要100万个页来存储,一个页表项4个字节,那么一个进程就需要4MB的内存来存页表
    - 多级页表
        如果采用二级分页,一级页表内存二级页表,二级页表再存页表项.这样一级⻚表就可以覆盖整个 4GB 虚拟地址空间，但如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即可以在需要时才创建⼆级⻚表。64位系统里是四级页表。但多级页表降低了地址转换的效率
13. 说一说系统如何提高访问页表的效率？
    局部性原理，通过TLB页表缓存（快表），将最常访问的⼏个⻚表项存储到缓存中。这样CPU 在寻址时，会先查 TLB里是否由匹配的页号，如果有，就会将对应得物理内存得基地址加上页内偏移得到虚拟地址。如果没找到，才会继续查常规的⻚表。
14. 说一说缺页异常（缺页中断）
    - 当进程访问的虚拟地址在⻚表中无效时，系统会产⽣⼀个缺⻚异常（同时保存CPU上下文）
    - 操作系统收到缺页中断会执行缺⻚中断处理函数，先会查找该⻚⾯在磁盘中的⻚⾯的位置
    - 找到磁盘中页面后，再在物理内存中寻找空闲页，如果有，就把该页面换入到物理内存中
    - 更新页表项
    - CPU重新执行导致缺页异常的指令
    - 找不到空闲⻚的话，就说明此时内存已满了，这时候，就需要「⻚⾯置换算法」选择⼀个物理⻚，如果该物理⻚有被修改过（脏⻚），则把它换出到磁盘，然后把该被置换出去的⻚表项的状态改成「⽆效的」，最后把正在访问的⻚⾯装⼊到这个物理⻚中
15. 缺页异常与一般中断的区别
    - 缺⻚中断在指令执⾏「期间」产⽣和处理中断信号，⽽⼀般中断在⼀条指令执⾏「完成」后检查和处理中断信号。
    - 缺⻚中断返回到该指令的开始重新执⾏「该指令」，⽽⼀般中断返回回到该指令的「下⼀个指令」执⾏
16. 说一说内存⻚⾯置换算法
    当出现缺⻚异常，需调⼊新⻚⾯⽽内存已满时，选择被置换的物理⻚⾯，也就是说选择⼀个物理⻚⾯换出到磁盘，然后把需要访问的⻚⾯换⼊到物理⻚
    - 最佳⻚⾯置换算法
        置换在「未来」最⻓时间不访问的⻚⾯
        实际系统中⽆法实现，因为程序访问⻚⾯时是动态的，我们是⽆法预知每个⻚⾯在「下⼀次」访问前的等待时间，用处是衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是⾼效的
    - 先进先出置换算法（FIFO）
        选择在内存驻留时间最⻓的⻚⾯进⾏中置换
    - 最近最久未使⽤的置换算法（LRU）
        选择最⻓时间没有被访问的⻚⾯进⾏置换
        开销大，需要维护所以页面的链表，并且每次访问内存时都要更新整个链表
    - 时钟⻚⾯置换算法
        把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⼀个表针指向最⽼的⻚⾯。发生缺⻚中断时，找到访问位为0的页面，插入该位置，将表针前移。否则清除访问位并前移。
    - 最不常⽤算法（LFU）
        当发⽣缺⻚中断时，选择「访问次数」最少的那个⻚⾯，并将其淘汰。
        开销大，并且没有考虑时间问题。但是现在已经没有访问了，⽽当前频繁访问的⻚⾯由于没有这些⻚⾯访问的次数⾼，在发⽣缺⻚中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不⾼的⻚⾯。
17. 说一说段页式内存管理（寻址过程）
    内存分段和内存分⻚相组合。先将程序划分为多个段，接着再把每个段划分为多个⻚。虚拟地址分为三部分，段号，段内页号，页内位移。由段号从段表中得到页表起始地址，再从页表中得到物理页号，再加上页内位移得到物理地址。
    通常会在系统中设置一个页表寄存器(PTR)，存放页表在内存中的起始地址F和页表长度M。进程未执行时，页表的始址和页表长度放在进程控制块(PCB) 中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。
18. 说一说Linux 采⽤了什么⽅式管理内存
    Linux 内存主要采⽤的是⻚式内存管理，也涉及到段机制。因为Intel的CPU硬件结构决定了只能线进行段式映射，再进行页式映射。Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是⼀样的。
19. 说一说Linux的虚拟地址空间
    - 分为内核空间和用户空间。32位系统内核空间占⽤ 1G ，位于最⾼处，剩下的 3G 是⽤户空间；64 位系统的内核空间和⽤户空间都是 128T ，分别占据整个内存空间的最⾼和最低处，剩下的中间部分是未定义的。
    - 每个进程都各⾃有独⽴的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。
    - ⽤户空间内存，从低到⾼分别是：
        程序文件段，.text
        已初始化数据段，.data, 比如已初始化的全局变量
        未初始化数据段，.bass, 比如未初始化的全局变量
        堆段，动态分配的内存，从低地址向高地址增长(malloc())
        文件映射段，包括动态库，共享内存(mmap()，动态分配)
        栈段，包括局部变量，从高地址向低地址增长
20. 内存交换和覆盖有什么区别？
       交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一程序或进程中。 
21. 动态分区分配算法有哪几种？可以分别说说吗？（动态分区是如何分配内存的？）
    - 首次适应算法
        每次都从低地址开始查找，找到第一个能满足大小的空闲分区。具体是通过按地址递增的空闲分区链来查找
    - 最佳适应算法
        优先使用更小的空闲区，来留下大的空闲区给大进程。具体是通过按容量递增排序的空闲分区链来查找
    - 最坏适应算法（最大适应算法）
        优先使用最大的空闲区，防止留下很大很小的空间碎片。具体是通过按容量递减排序的空闲分区链来查找
    - 邻近适应算法
        首次适应算法每次都从链头开始查找, 而这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能减小开销。具体是通过按地址递增的空闲分区的循环链表来实现
    - 区别
        首次适应算法最简单以及最好最快，但会增加查找开销。邻近算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间分裂成小的碎片，它通常比首次适应算法结果要差。最佳导致大量碎片，最坏导致没有大的空间。
22. 虚拟技术你了解吗？
    虚拟技术把一个物理实体转换为多个逻辑实体。主要有两种虚拟技术：时分复用技术和空分复用技术。
    多进程与多线程：多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。
    虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。
23. 操作系统在对内存进行管理的时候需要做些什么?
    操作系统负责内存空间的分配与回收。
    操作系统需要提供某种技术从逻辑上对内存空间进行扩充。
    操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。
    操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰

#### 4. 调度算法
1. CPU调度算法（进程调度算法）
2. 内存页面置换算法
3. 磁盘调度算法
   - 目的：提⾼磁盘的访问性能，⼀般是通过优化磁盘的访问请求顺序来做到的，其中寻道时间最长
   - 先来先服务（FCFS）
        先到来的请求，先被服务.
        如果⼤量进程竞争使⽤磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过⻓
   - 最短寻道时间优先(SSF)
        优先选择从当前磁头位置所需寻道时间最短的请求
        动态请求下，可能会导致磁头在一小块区域来回移动，有些区域无法被访问
   - 扫描算法
        磁头在⼀个⽅向上移动，访问所有未完成的请求，直到磁头到达该⽅向上的最后的磁道，才调换⽅向，这就是扫描（Scan）算法
        不会产生饥饿现象，但会导致每个磁道的响应频率存在差异，中间部分相⽐其他部分响应的频率会⽐较多
   - 循环扫描算法
        总是按相同的⽅向进⾏扫描，到达最边缘后快速复位，返回中途不处理任何请求
        使得每个磁道的响应频率基本⼀致。
   - LOOK 与 C-LOOK算法
        LOOK：针对扫描算法的优化，磁头在移动到「最远的请求」位置，然后⽴即反向移动，反向移动的途中会响应请求
        C-LOOK：针对循环扫描算法的优化， ，磁头在移动到「最远的请求」位置，然后⽴即反向移动，反向移动的途中不会响应请求
4. IO调度算法

#### 5. 文件系统/IO相关
1. 说一说Linux的文件系统
    Linux一切皆文件，有7大文件：普通文件，目录，套接字，管道，软链接，存储设备，端口设备。Linux采用索引节点和目录项来记录文件的信息和目录层次结构。
    索引节点是⽂件的唯⼀标识，而目录项维护了目录的层次结构
2. 说一说文件的存储方式
   - 连续空间存放
        ⽂件存放在磁盘「连续的」物理空间中，读写效率很⾼，有「磁盘空间碎⽚」和「⽂件⻓度不易扩展」的缺陷
   - ⾮连续空间存放
     - 链表方式
        通过链表存放文件，可以消除磁盘碎⽚且易于扩展。
        隐式链表：通过指针顺序访问，稳定性差，指针丢失会导致文件数据丢失
        显式链表：将各数据库的指针存在在表中即文件分配表，在内存中查找，速度快，减少了访问磁盘的次数，但不适用于大磁盘
     - 索引方式
        为每个⽂件创建⼀个「索引数据块」，存放指向数据块的指针。没有磁盘碎片，易于扩展，支持顺序读取和随机读取。缺点是增加空间开销
3. Unix采用什么方式存储文件？
    多级索引块的方式。通过⼀个索引块来存放多个索引数据块，⼀层套⼀层索引。
4. 如何管理空闲空间？
    - 空闲表法
        有少量的空闲区时才有较好的效果。因为，如果存储空间中有着⼤量的⼩的空闲区，则空闲表变得很⼤，这样查询效率会很低。另外，这种分配技术适⽤于建⽴连续⽂件
    - 空闲链表法
        不能随机访问，增删开销大，不适用于大型文件系统
    - 位图法
        二进制位表示磁盘中盘块情况
5. Linux如何管理空闲空间？
    位图法
6. 说一说文件IO的方式
   - 缓冲与⾮缓冲 I/O
   - 直接与⾮直接 I/O
   - 阻塞与⾮阻塞 I/O 
   - 同步与异步 I/O
7. 说一说缓冲与非缓冲IO
    根据「是否利⽤标准库缓冲」，，可以把⽂件 I/O 分为缓冲I/O 和⾮缓冲 I/O
    缓冲 I/O，利⽤的是标准库的缓存实现⽂件的加速访问，⽽标准库再通过系统调⽤访问⽂件。
    ⾮缓冲 I/O，直接通过系统调⽤访问⽂件，不经过标准库缓存
    目的是减少系统调⽤的次数，毕竟系统调⽤是有 CPU 上下⽂切换的开销的
8. 说一说直接与非直接IO
    根据是「否利⽤操作系统/内核的缓存」即页缓存，可以把⽂件 I/O 分为直接 I/O 与⾮直接 I/O
    直接 I/O，不会发⽣内核缓存和⽤户程序之间数据复制，⽽是直接经过⽂件系统访问磁盘。
    ⾮直接 I/O，读操作时，数据从内核缓存中拷⻉给⽤户程序，写操作时，数据从⽤户程序拷⻉给内核缓存，再由内核决定什么时候写⼊数据到磁盘。
    目的是减少磁盘IO次数
9. 如果⽤了⾮直接 I/O 进⾏写数据操作，内核什么情况下才会把缓存数据写⼊到磁盘？
    在调⽤ write 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上；
    ⽤户主动调⽤ sync ，内核缓存会刷到磁盘上；
    当内存⼗分紧张，⽆法再分配⻚⾯时，也会把内核缓存的数据刷到磁盘上；
    内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上；
10. 说一说阻塞与非阻塞IO
    - 阻塞IO：
        当⽤户程序执⾏ read ，线程会被阻塞，⼀直等到内核数据准备好，并把数据从内核缓冲区拷⻉到应⽤程序的缓冲区中，当拷⻉过程完成， read 才  会返回
        阻塞等待的是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程
    - 非阻塞IO:
        ⾮阻塞的 read 请求在数据未准备好的情况下⽴即返回，可以继续往下执⾏，此时应⽤程序不断轮询内核，直到数据准备好，内核将数据拷⻉到应⽤程序缓冲区， read 调⽤ 才可以获取到结果
        非阻塞等待的是「数据从内核态拷⻉到⽤户态」这个过程
    - 基于非阻塞IO多路复用
        当内核数据准备好时，再以事件通知应⽤程序进⾏操作而不是需要程序不断轮询来向内核询问。数据准备好，内核将数据拷⻉到应⽤程序缓冲区， read 调⽤ 才可以获取到结果。
        但还需要等待内核将数据从内核空间拷⻉到应⽤程序空间
11. 说一说同步IO与异步IO
    IO是分为两个过程：数据准备的过程，数据从内核空间拷⻉到⽤户进程缓冲区的过程
    - 同步IO
        包括阻塞 I/O、⾮阻塞 I/O，基于⾮阻塞 I/O 的多路复⽤。因为它们在 read调⽤时，内核将数据从内核空间拷⻉到应⽤程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷⻉效率不⾼， read 调⽤就会在这个同步过程中等待⽐较⻓的时间。
    - 异步IO
        异步 I/O 是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程都不⽤等待
        发起 aio_read 之后，就⽴即返回，内核准备数据，并且⾃动将数据从内核空间拷⻉到应⽤程序空间，这个拷⻉过程同样是异步的，内核⾃动完成的，和前⾯的同步操作不⼀样，应⽤程序并不需要主动发起拷⻉动作。
12. 说一说最一般的IO
    - read()调用，进程阻塞，CPU向磁盘发出IO请求
    - 磁盘控制器准备数据到内部缓冲区中，向CPU发出中断
    - CPU收到中断信号，切换上下文，将数据从磁盘控制器的缓冲区中拷贝到内核缓冲区，再从内核缓冲区（缓存页）拷贝到用户缓冲区中
    - read()返回
    全程需要CPU参与，不适合大量数据的搬运
13. 说一说直接内存访问（DMA）技术
    - read()调用，进程阻塞，CPU向DMA发出IO请求后执行其他任务
    - DMA向IO法术请求
    - 磁盘控制器准备数据到内部缓冲区中，向DMA发出中断
    - DMA将数据从磁盘缓冲区拷贝到内核缓冲区，向CPU发出中断
    - CPU收到信号，将数据从内核缓冲区（缓存页）拷贝到用户缓冲区中
    - read()返回
14. 说一说传统的文件传输
    需要调用一次read()和一次write()，涉及4次⽤户态与内核态的上下⽂切换，以及4次数据拷贝即两次DMA拷贝（磁盘到内核，socket缓冲区到网卡），两次CPU拷贝（内核缓存区/socket缓冲区到用户缓冲区）
15. 优化⽂件传输的性能？（不涉及TCP）
    - 减少系统调⽤的次数
    - 传输文件时不修改数据所以不需要用户缓冲区
    - 使用mmap()替换read()，把内核缓冲区⾥的数据「映射」到⽤户空间，4次上下文切换，1次CPU，2次DMA拷贝
    - 使用sendfile()替换read()和write()，减少⼀次系统调⽤，也就减少了 2 次上下⽂切换的开销，并且是直接将内核缓冲区⾥的数据拷⻉到 socket 缓冲区⾥，又减少了一次CPU数据拷贝，即2次上下文切换，1次CPU，2次DMA
    - 真正的零拷贝：⽹卡⽀持 SG-DMA，DMA将内核缓冲区的数据直接拷贝到网卡，不使用CPU拷贝，也不经过用户缓冲区。只有2次DMA拷贝，2次上下文切换
16. 说一说零拷贝技术
    ⽹卡⽀持 SG-DMA，DMA将内核缓冲区的数据直接拷贝到网卡，不使用CPU拷贝，也不经过用户缓冲区。只有2次DMA拷贝，2次上下文切换。零拷⻉技术可以把⽂件传输的性能提⾼⾄少⼀倍以上
17. 说一说页缓存
    页缓存（PageCache），就是磁盘高速缓存，也是所谓的内核缓冲区。根据程序的局部性原理，刚被访问的数据在短时间内再次被访问的概率很⾼，于是我们可以⽤ PageCache 来缓存最近被访问的数据，当空间不⾜时淘汰最久未被访问的缓存。同时页缓存也有预读功能。
18. 大文件传输会对页缓存造成什么问题？
    - 大文件传输无法利用到页缓存即内核缓冲区，会浪费一次DMA拷贝，造成零拷贝的性能降低
    - 大文件会占据页缓存导致其他小文件无法利用到页缓存
19. ⼤⽂件传输⽤什么⽅式实现？
    - 在⾼并发的场景下，针对⼤⽂件的传输的⽅式，应该使⽤「异步 I/O + 直接 I/O」来替代零拷⻉技术
    - 采用异步IO，进程调用read()后直接返回，内核将磁盘中的数据直接拷贝到进程缓冲区不经过页缓存，进程收到内核的通知后再去处理数据
    - 异步 I/O 并没有涉及到 PageCache，所以使⽤异步 I/O 就意味着要绕开PageCache，即直接IO
    - 缺点是没有内核的两点优化：
        - 内核的 I/O 调度算法会缓存尽可能多的 I/O 请求在 PageCache 中，最后「合并」成⼀个更⼤的 I/O请求再发给磁盘
        - 内核也会「预读」后续的 I/O 请求放在 PageCache 中

#### 6. 网络模型/IO多路复用
1. 多进程模型
    - 基于最原始的阻塞⽹络 I/O，为每个客户端分配⼀个进程来处理请求。
    - 服务器的主进程负责监听客户的连接，accept() 函数就会返回⼀个「已连接Socket」，通过 fork() 函数创建⼀个⼦进程来针对「已连接Socket」通信。然后通过wait() 和 waitpid()回收子进程。
    - 缺点是无法应对大规模并发通信，进程上下文切换开销太大
2. 多线程模型
    - 当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的⽂件描述符传递给线程函数，接着在线程⾥和客户端进⾏通信，从⽽达到并发处理的⽬的
    - 缺点是也还是有线程切换的上下文开销以及频繁创建和销毁线程的开销。用线程池的⽅式可以避免线程的频繁创建和销毁，但也无法应对大规模并发通信（10K）。
3. I/O 多路复⽤
   - 每个请求分配⼀个进程/线程的⽅式不合适，I/O 多路复⽤可以使⽤⼀个进程来维护多个 Socket。I/O 多路复⽤属于时分多路复⽤，⼀个进程虽然任⼀时刻只能处理⼀个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1秒内就可以处理上千个请求。
   - 通过select/poll/epoll 内核提供给⽤户态的多路复⽤系统调⽤，进程可以通过⼀个系统调⽤函数从内核中获取多个事件。在获取事件时，先把所有连接（⽂件描述符）传给内核，再由内核返回产⽣了事件的连接，然后在⽤户态中再处理这些连接对应的请求即可
4. 说一说select如何实现多路复用
   - select 实现多路复⽤的⽅式是，将已连接的 Socket 都放到⼀个⽂件描述符集合，然后调⽤ select 将⽂件描述符集合拷⻉到内核⾥，让内核通过遍历⽂件描述符集合的⽅式来检查是否有网络事件。当检查到有事件产⽣后，将此 Socket 标记为可读或可写， 接着再把整个⽂件描述符集合拷⻉回⽤户态⾥，然后⽤户态还需要再通过遍历的⽅法找到可读或可写的 Socket，然后再对其处理。
   - 需要遍历2次⽂件描述符集合，拷贝2次文件描述符集合
   - 使⽤固定⻓度的 BitsMap，表示⽂件描述符集合，限制大小为1024
5. 说一说poll如何实现多路复用
   - 和select类似。但采用链表来表示文件描述符集合，没有了select的个数限制，但还是会受到系统⽂件描述符限制。
   - poll 和 select 并没有太⼤的本质区别， 都是使⽤「线性结构」存储进程关注的 Socket 集合，因此都需要遍历⽂件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，⽽且也需要在⽤户态与内核态之间拷⻉⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。
6. 说一说epoll如何实现多路复用
   - epoll解决了select和poll的问题
   - epoll 在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字，把需要监控的 socket 通过epoll_ctl() 函数加⼊内核中的红⿊树⾥，红⿊树增删查⼀般时间复杂度是O(logn) ，就不需要每次都拷贝一整个socket集合，减少了拷贝开销和内存占用
   - epoll 使⽤事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件，当某个 socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件列表中，当⽤户调⽤ epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，以及通过传出参数传出哪些文件描述符有事件，不需要轮询扫描整个 socket 集合，⼤⼤提⾼了检测的效率
7. 说一说epoll的边缘触发模式和水平触发模式
   - 边缘触发模式
       - 当被监控的 Socket 描述符上有可读事件发⽣时，无论发生了几次事件，服务端都只调用一次epoll_wait(),同时要确保一次性将内核缓冲区的数据读取完
       - 由于IO事件只会通知一次，所以要用循环从文件描述符中读取数据。如果是阻塞IO当没数据可以读写时就会阻塞，导致程序无法正常执行。所以 边缘触发模式⼀般和⾮阻塞 I/O 搭配使⽤，程序会⼀直执⾏ I/O 操作，直到系统调⽤（如 read 和write ）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK 
   - 水平触发模式
        当被监控的 Socket 描述符上每发生一次可读事件，就通知服务端调用一次epoll_wait()读取，直到read读取完内核缓冲区的数据
   - ⼀般来说，边缘触发的效率⽐⽔平触发的效率要⾼，因为边缘触发可以减少 epoll_wait 的系统调⽤次数，系统调⽤也是有⼀定的开销的的，毕竟也存在上下⽂的切换
   - select/poll 只有⽔平触发模式， epoll 默认的触发模式是⽔平触发
8. 说一说⾼性能⽹络模式（设计模式）
   - Reactor 模式
     - 单reactor单线程
     - 单reactor多线程
     - 多reactor多线程（主从reactor多线程）
   - Proactor模式
9. 说一说Reactor模式
   - Reactor是⾮阻塞同步⽹络模式，即I/O 多路复⽤监听事件，收到事件后，根据事件类型分配（Dispatch）给某个线程
   - 基于面向对象的思想，其余有两个关键组成
        reactor：在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对IO事件做出反应
        Handlers：处理程序执行IO事件要完成的实际事件，一般就是回调函数
   - 单reator单进程/线程（C：单进程，Java：单线程）
     - 过程
        - Reactor对象通过Select监控客户端请求事件，收到事件后通过Dispatch进行分发；
        - 如果是建立连接请求事件，则由Acceptor通过Accept处理连接请求，然后创建一个Handler对象处理连接完成后的后续业务处理；如果不是建立连接事件，则Reactor会分发调用连接对应的Handler来响应；
        - Handler会完成Read->业务处理->send的完整业务流程；
     - 优点
        简单，没有多线程通信与资源竞争的问题
     - 缺点
        只有一个线程，无法完全发挥多核CPU的性能。Handler在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈。
     - 应用场景
        不适⽤计算机密集型的场景，只适⽤于业务处理⾮常快速的场景。比如Redis，业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上
   - 单Reactor多线程
     - 过程
       - Reactor对象通过Select监控客户端请求事件，收到事件后通过Dispatch进行分发；
       - 如果是建立连接请求事件，则由Acceptor通过Accept处理连接请求，然后创建一个Handler对象处理连接完成后续的各种事件；如果不是建立连接事件，则Reactor会分发调用连接对应的Handler来响应；
       - Handler只负责响应事件，不做具体业务处理，通过Read读取数据后，会分发给后面的Worker线程池进行业务处理；
       - Worker线程池会分配独立的线程完成真正的业务处理，然后将响应结果发给Handler进行处理；
       - Handler收到响应结果后通过send将响应结果返回给Client；
     - 优点
        可以充分利用多核CPU的处理能力
     - 缺点
        Reactor承担所有事件的监听和响应；在单线程中运行，高并发场景下容易成为性能瓶颈；
   - 多Reactor多线程
     - 过程
       - Reactor主线程MainReactor对象通过Select监控建立连接事件，收到事件后通过Acceptor接收，处理建立连接事件；
       - Acceptor处理建立连接事件后，MainReactor将连接分配Reactor子线程给SubReactor进行处理；SubReactor将连接加入连接队列进行监听，并创建一个Handler用于处理各种连接事件；当有新的事件发生时，SubReactor会调用连接对应的Handler进行响应；
       - Handler通过Read读取数据后，会分发给后面的Worker线程池进行业务处理；
       - Worker线程池会分配独立的线程完成真正的业务处理，然后将响应结果发送给Handler进行处理；
       - Handler收到响应结果后通过Send将响应结果返回给Client;
     - 优点
        线程只需要接收新连接，子线程完成后续的业务处理且无需返回数据
     - 应用场景
        netty（Java网络应用程序框架）
10. 说一说Proactor模式
    - Proactor是⾮阻塞异步⽹络模式，即在发起异步读写请求后就直接返回，由系统内核来自动完成数据的读写工作，然后就通知应用程序直接处理数据
    - 过程
      - Proactor Initiator 负责创建 Proactor 和 Handler 对象然后通过异步操作管理器注册到内核
      - 异步操作管理器处理IO操作后通知Proactor
      - Proactor根据不同的事件类型回调不同的 Handler 进⾏业务处理；
      - Handler 完成业务处理；
    - 缺点
        Linux下异步读写函数时aio系统函数，但这些函数不是真正的操作系统级别⽀持的，⽽是在⽤户空间模拟出来的异步，并且仅仅⽀持基于本地⽂件的 aio 异步操作，⽹络编程中的 socket 是不⽀持的，这也使得基于 Linux 的⾼性能⽹络程序都是使⽤ Reactor ⽅案。
        Windows里由IOCP操作系统级别实现了异步IO，所以Windows里可以使用Proactor⽅案来实现⾼性能⽹络程序
11. 说一说Reactor模式和Proactor模式的区别
    - Reactor 模式是基于同步非阻塞 I/O 的，而Proactor 模式基于异步非阻塞 I/O
    - Reactor 是在事件发生时就通知事先注册的事件，用户进程通过调用read()来读取数据。Proactor 是基于异步 I/O完成读写操作，待I/O操作完成后才回调应用程序来进行业务处理；



#### 7. 设备管理
1. CPU如何读取设备数据？
    每种设备都有⼀个设备控制器，控制器相当于⼀个⼩ CPU。CPU使用设备控制器读取数据，读取完成后通知CPU。一般有三种通知方式
    - 轮询等待：比较傻瓜，会占用CPU所有时间
    - 中断：通过中断来通知CPU，中断需要切换CPU上下文，对于频繁读写数据的磁盘不友好,而且CPU一直都要参与数据的搬运
    - 通过DMA控制器：可以使得设备在CPU 不参与的情况下，能够⾃⾏把设备 I/O 数据放⼊到内存。CPU 当要读取磁盘数据的时候，只需给 DMA 控制器发送指令，然后返回去做其他事情，当磁盘数据拷⻉到内存后， DMA 控制机器通过中断的⽅式，告诉 CPU 数据已经准备好了，可以从内存读数据了。仅仅在传送开始和结束时需要 CPU ⼲预。
2.  IO调度算法
    Linux 通过⼀个统⼀的通⽤块层，来管理不同的块设备。提供统一的标准接口并且能够调度IO，提高读写效率。Linux 内存⽀持 5 种 I/O 调度算法。
    没有调度算法
    先⼊先出调度算法
    完全公平调度算法
    优先级调度：适⽤于运⾏⼤量进程的系统
    最终期限调度算法：分别为读、写请求创建了不同的 I/O 队列，这样可以提⾼机械磁盘的吞吐量，并确保达到最终期限的请求被优先处理，适⽤于在 I/O 压⼒⽐较⼤的场景，⽐如数据库
3. 键盘敲⼊字⺟时，期间发⽣了什么？
   - 当⽤户输⼊了键盘字符， 键盘控制器将数据存储在缓冲中，并通过总线向CPU发生中断请求
   - CPU 收到中断请求后，操作系统会保存被中断进程的 CPU 上下⽂，然后调⽤键盘的中断处理程序。
   - 中断处理程序会调用显示设备的驱动程序会将数据写入显示设备的缓冲区中，再将其显示到屏幕上
   - 恢复被中断进程的上下⽂
#### 8. 综合问题
1. 一个程序从开始运行到结束的完整过程，你能说出来多少？
    主要是四个过程：
       - 预编译
        主要处理源代码文件中的以“#”开头的预编译指令，比如将使用的库文件内容替换到文件中，替换所有的宏定义，删除注释等等
       - 编译
        把预编译之后生成的文件，进行一系列词法语法分析及优化后，生成相应的汇编代码文件
       - 汇编
        将汇编代码转变成机器可以执行的指令(机器码文件)。
       - 链接
        将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。包括静态链接和动态链接。
2. 说一说程序的局部性原理
    即在⼀段时间内，整个程序的执⾏仅限于程序中的某⼀部分。相应地，执⾏所访问的存储空间也局限于某个内存区域。