#### 操作系统面经总结
 
 
#### 1. 硬件结构
1. 说一说冯诺依曼模型
   - **中央处理器**（CPU）
        CPU用于计算，32位宽：4字节，64位宽：8字节。
        寄存器：通⽤寄存器：⽤来存放需要进⾏运算的数据
                程序计数器：⽤来存储 CPU 要执⾏下⼀条指令所在的内存地址
                指令寄存器：⽤来存放程序计数器指向的指令
        控制单元
        逻辑运算单元
   - **内存**
        程序和数据都是存储在内存
   - **输⼊设备**
   - **输出设备**
   - **总线**
        ⽤于 CPU 和内存以及其他设备之间的通信
        地址总线，数据总线，控制总线
2. 说一说CPU 执⾏程序的过程
    ⼀个程序执⾏的时候， CPU 会根据程序计数器⾥的内存地址，从内存⾥⾯把需要执⾏的指令读取到指令寄存器⾥⾯执⾏，然后根据指令⻓度⾃增，开始顺序读取下⼀条指令
3. 如何让程序跑的更快？
    程序的CPU执行时间 = CPU 时钟周期数 X 时钟周期时间 = **指令数 X 每天指令的平均时钟周期数 X 时钟周期时间**
    - 编译器优化减少指令数
    - 减少 每天指令的平均时钟周期数、
    - 提高CPU主频，减少时钟周期时间
4. 64 位相⽐ 32 位 CPU 的优势在哪吗？ 64 位 CPU 的计算性能⼀定⽐ 32 位 CPU ⾼很多吗
    - 64 位 CPU 可以⼀次计算超过 32 位的数字，⽽ 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进⾏计算，效率就没那么⾼，但是⼤部分应⽤程序很少会计算那么⼤的数字，所以**只有运算⼤数字的时候， 64 位 CPU 的优势才能体现出来**，否则和 32 位 CPU 的计算性能相差不⼤。
    - 64 位 CPU 可以寻址**更⼤的内存空间**
5. 你知道软件的 32 位和 64 位之间的区别吗？再来 32 位的操作系统可以运⾏在 64 位的电脑上吗？ 64 位的操作系统可以运⾏在 32 位的电脑上吗？如果不⾏，原因是什么？
    - 64 位和 32 位软件，实际上代表**指令是** 64 位还是 32 位的
    - 如果 32 位指令在 64 位机器上执⾏，需要⼀套兼容机制，就可以做到兼容运⾏了。但是如果 64 位指令在 32 位机器上执⾏，就⽐较困难了，因为 **32 位的寄存器存不下 64 位的指令**；
    - 硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽
6. 说一说计算机存储器的层次结构（CPU如何读取数据）
   每⼀种存储器设备只和它相邻的存储器设备打交道
   -  CPU 中的寄存器
   -  **CPU ⾼速缓存**，CPU Cache
   -  内存
   -  硬盘
7. 如何写出让 CPU 跑得更快的代码？（如何写出 CPU 缓存命中率⾼的代码？）
   - **提高数据缓存的命中率**
        CPU Cache每次会顺序存放多个额外数据。所以遇到这种遍历数组的情况时，**按照内存布局顺序访问**，就可以提高数据缓存的命中率
   - **提高指令缓存的命中率**
        CPU有分支预测器，对于**if语句**可以预测，提前把可能的指令放到CPU缓存中。所以如果数组中的元素随机的，就不太管用。C++编译器中有宏可以使用。一般CPU ⾃身的动态分⽀预测已经是⽐较准了。
   - **提高多核 CPU 的缓存命中率**
        进程可能在不同 CPU 核⼼来回切换执⾏，这对 CPU Cache 不是有利的，如果⼀个进程在不同核⼼来回切换，各个核⼼的缓存命中率就会受到影响。**把线程绑定在某⼀个 CPU 核⼼上**，提高缓存命中率，意味着 CPU 可以减少访问 内存的频率，提升性能。
8.  说一说计算机如何表示**整数**
    二进制表示，最⾼位是作为符号标志位，其余为表示二进制数据
9.  说一说计算机如何表示**负数**
    采用补码方式表示。把对应正数的⼆进制全部取反再加1。**⽤了补码的表示⽅式，对于负数的二进制加减法操作，实际上是和正数的二进制加减法操作⼀样的**。否则还要判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转成加法。
10. 说一说计算机如何表示**小数**
    - **乘2取整法表示**，但对于有些小数是无法⼆进制精确的表示 0.1，只能⽤近似值来表示。
    - 在计算机中使用浮点数表示，将二进制数用科学记数法分为**符号位，指数位，和尾数位**。指数位表示范围，尾数位决定精度。
    - 对于float 32位单精度浮点数，指数位8位，尾数位23位，精度是log10（2^24）为7位。（IEEE标准规定首位必须位1，所以**尾数位可以再加上1位隐藏位**）。比如float 10.625，二进制小数为1010.101，小数点右移3位，为1.010101。加上偏移量127，指数位就为130.尾数位就为01010100000000000000000。
    - **偏移量**就可以将指数部分转换为无符号整数，IEEE 标准规定单精度浮点的指数取值范围是 -126 ~ +127。
11. 为什么计算机中0.1 + 0.2 != 0.3?
    因为有的⼩数⽆法可以⽤完整的⼆进制来表示，所以计算机⾥只能采⽤近似数的⽅式来保存，那两个近似数相加，得到的必然也是⼀个近似数。
12. 什么是内核？
    内核是作为**应⽤连接硬件设备的桥梁**，应⽤程序只需关⼼与内核交互，不⽤关⼼硬件的细节
13. 内核具体有什么功能？
    进程调度，内存管理，硬件管理，系统调用
14. **内核是怎么工作的？**
    ⽤户空间的代码只能访问⼀个局部的内存空间，⽽内核空间的代码可以访问所有内存空间。
    内核程序执⾏在内核态，⽤户程序执⾏在⽤户态。当应⽤程序使⽤系统调⽤时，会产⽣⼀个中断。发⽣中断后， CPU 会中断当前在执⾏的⽤户程序，转⽽跳转到中断处理程序，也就是开始执⾏内核程序。内核处理完后，主动触发中断，把 CPU 执⾏权限交回给⽤户程序，回到⽤户态继续⼯作。
15. **中断**是什么？
    - 中断是系统⽤来**响应硬件设备请求的⼀种机制**，操作系统收到硬件的，中断请求，会打断正在执⾏的进程，然后调⽤内核中的中断处理程序来响应请求，是⼀种**异步**的事件处理机制，可以提⾼系统的并发处理能⼒。
    - 有外中断，内中断，软中断，硬中断之分。
    - 一般中断处理程序分为两部分，上半部直接处理硬件请求，硬中断，耗时短快速执⾏，可能会屏蔽其他中断；下半部是由内核触发，软中断，负责上半部未完成的⼯作，耗时⽐较⻓，延迟执⾏。这样来**避免中断处理程序执⾏过⻓和中断丢失**的问题。
16. 外中断和异常（内中断）有什么区别？
   - **外中断**是指由 CPU 执行指令以外的事件引起，如 I/O 完成中断，硬件中断等等
   - **异常**(内中断)是由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等
17. 硬中断和软中断有什么区别？
   - **硬件中断**是由与系统相连的外设(比如网卡 硬盘 键盘等)自动产生的. 
   - **软中断**是可被调用执行的程序产生的中断。比如外部设备管理中断服务程序（键盘管理中断、显示器管理中断、打印机管理 中断等）
18. 说一说中断处理程序的处理流程
   1.  在 I/O 时，设备控制器如果已经准备好数据，则会通过中断控制器向 CPU 发送中断请求；
   2.  保护被中断进程的 CPU 上下⽂；
   3.  转⼊相应的设备中断处理函数；
   4.  进⾏中断处理；
   5.  恢复被中断进程的上下⽂；
19. 举例说明中断
    举例如网卡接受到网络包，会通过硬件中断通知内核有新的数据到了，于是内核就会调⽤对应的中断处理程序来响应该事件。先是硬中断快速处理，所以只要把⽹卡的数据读到内存中等。再是软中断延迟处理，把内存中的网络数据交给网络协议栈处理。
20. 如何查看中断相关信息？
    软中断：/proc/softirqs
    硬中断：/proc/interrupts 
21. 如何定位软中断 CPU 使⽤率过⾼的问题？（如何定位网络IO过高的问题？）
    - top，si，就是 CPU 在软中断上的使⽤率， CPU 使⽤率最⾼的进程也是软中断 ksoftirqd
    - 要知道是哪种软中断类型导致的，我们可以使⽤ **watch -d cat /proc/softirqs** 命令查看每个软中断类型的中断次数的变化速率。
    - ⼀般对于⽹络 I/O ⽐较⾼的 Web 服务器， **NET_RX** ⽹络接收中断的变化速率相⽐其他中断类型快很多。如果发现 NET_RX ⽹络接收中断次数的变化速率过快，接下⾥就可以使⽤ **sar -n DEV** 查看⽹卡的⽹络包接收速率情况，然后分析是哪个⽹卡有⼤量的⽹络包进来。接着，在通过 tcpdump 抓包，分析这些包的来源，如果是⾮法的地址，可以考虑加防⽕墙，如果是正常流量，则要考虑硬件升级等。
22. 说一说并发和并行
    - 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。
    - 操作系统通过引入**进程和线程**，使得程序能够并发运行
    - 并行需要硬件支持，如多流水线、**多核处理器**或者分布式计算系统。

#### 2. 内存管理
1. 什么是内存？作用是什么？
    内存是用于存放数据的硬件，程序执行前需要**先存放到内存**中才能被CPU处理。
2. 常见内存分配方式有哪些？
    - **从静态存储区域分配**
        内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。
    - **在栈上创建**
        在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放 
    - **从堆上分配，亦称动态内存分配**
         程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多
3. 常见内存分配内存错误
    - **内存分配未成功，却使用了它**
        解决办法是，在使用内存之前检查指针是否为NULL
    - **内存分配虽然成功，但是尚未初始化就引用它**
        无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦
    - 内存分配成功并且已经初始化，但操作**越过了内存的边界**
    - 忘记了释放内存，造成**内存泄露**
        态内存的申请与释放必须配对，程序中malloc与free的使用次数一定要相同，否则肯定有错误（new/delete同理）
    - **释放了内存却继续使用它**
        例如使用free或delete释放了内存后，没有将指针设置为NULL。导致产生“野指针”
4. 一般情况下在Linux下栈空间的大小
    8MB，8192KB，通过ulimit命令查看以及修改
5. 堆和栈的区别
   - 申请方式不同
     - 堆：由程序员管理，需要⼿动 new malloc delete free 进⾏分配和回收，如果不进⾏回收的话，会造成内存泄漏的问题
     - 栈：由编译器进⾏管理，在需要时由编译器⾃动分配空间，在不需要时候⾃动回收空间，⼀般保存的是局部变量和函数参数等
   - 空间大小不同
     - 堆是不连续的内存区域，受限于计算机系统中有效的虚拟内存（32位 4G）
     - 栈是一块连续的内存区域，大小固定，过ulimit -a查看，由ulimit -s修改
   - **管理机制不同**（**底层原理**）
     - 堆由链表管理，当在堆中申请空间时，操作系统首先从空闲链表中找到第一个空间大于“申请空间”的节点，将其分配。多余的部分，系统自动放回空闲链表。在这块内存空间首地址处记录分配的大小，如此，之后的delete()才能正确释放内存空间。
     - 只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则报异常提示栈溢出
   - **碎片问题**
     - 对于堆，频繁的new/delete会造成大量碎片，使程序效率降低
     - 对于栈，它是有点类似于数据结构上的一个先进后出的栈，进出一一对应，不会产生碎片。
   - **生长方向不同**
     - 堆向上，向高地址方向增长。	
     - 栈向下，向低地址方向增长。
     - 堆从低向高扩展，方便内存管理。栈从高向低是为了最大程度利用地址空间，否则必须指定栈堆的分界线，会导致分配不均。同时高向低也确定了栈空间的起始位置，避免了动态扩展栈空间时需要移动整个栈的数据
   - **分配效率不同**
     - 堆由C/C++函数库提供在分配堆内存的时候需要一定的算法寻找合适大小的内存。并且获取堆的内容需要两次访问，第一次访问指针，第二次根据指针保存的地址访问内存，因此堆比较慢。
     - 而计算机在底层对栈提供支持，分配专门寄存器存放栈地址，栈操作有专门指令。
     - 另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去的
     所以堆的效率比栈低很多
6. malloc与free的实现原理？（虚拟内存如何从堆中动态分配和释放内存）
    - malloc 
      - 操作系统将可用的内存块连接为空闲链表，调用malloc函数时，它沿连接表寻找一个大到足以满足用户请求所需要的内存块。然后，将该内存块一分为二。接下来，将分配给用户的那块内存传给用户，并将剩下的那块返回到连接表上。如果空闲链上没有足够大的内存块，则将相邻的小空闲块合并成较大的内存块再使用。
      - 从操作系统层面上看，malloc是通过两个系统调用来实现的： **brk和mmap**。进程先通过这两个系统调用获取或者扩大进程的虚拟内存，获得相应的虚拟地址，在访问这些虚拟地址的时候，**通过缺页中断**，让内核分配相应的物理内存，这样内存分配才算完成
      - **brk是将进程数据段(.data)的最高地址指针向高处移动**，这一步可以扩大进程在运行时的堆大小（因为堆范围就是数据段顶部到栈空间最低位）。**mmap是在进程的虚拟地址空间中寻找一块空闲的虚拟内存**，这一步可以获得一块可以操作的堆内存。通常，分配的内存小于128k时，使用brk调用来获得虚拟内存，大于128k时就使用mmap来获得虚拟内存。
    - free
      - 调用free函数时，被free回收的内存会首先被ptmalloc使用双链表保存起来，当用户下一次申请内存的时候，会尝试从这些内存中寻找合适的返回。这样就避免了频繁的系统调用，占用过多的系统资源。同时ptmalloc也会尝试对小块内存进行合并，避免过多的内存碎片。它将用户释放的内存块连接到空闲链上。
7. 说一说内存泄漏和内存溢出
    - 内存泄漏是指由于疏忽导致程序未内释放已不再使用的内存。一般是发生在程序中已动态分配的堆内存，比如malloc或者new后忘记free或delete。
    - 内存溢出是指程序在申请内存时，没有足够的内存空间供其使用。比如用int存储long值
8. 什么是**虚拟内存地址**？
    操作系统为每个进程分配独⽴的⼀套虚拟地址，将不同进程的虚拟地址和不同内存的物理地址映射起来
9. 虚拟内存的目的（功能）是什么？
    - **简化内存管理**，虚拟内存为每个进程提供了一致的地址空间，用户不必关心底层的物理地址, 
    - **隔离进程间的内存地址**，保护了每个进程的地址空间不被其他进程破坏
    - 可以**让物理内存扩充成更大的逻辑内存**，从而让程序获得更多的可用内存。进⾏虚拟内存和物理内存的⻚之间的映射之后，并不真的把⻚加载到物理内存⾥，⽽是只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再从磁盘加载到物理内存⾥⾯去。
10. 操作系统是如何管理虚拟地址与物理地址之间的关系？
     内存分段和内存分⻚
11. 说一说**内存分段**
   - 程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。 不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来。
   - 分段机制下的虚拟地址由两部分组成， **段选择⼦和段内偏移量**。通过段选择子得到段表保存的段基地址，段基地址加上段内偏移量得到物理内存地址
12. 分段机制会导致什么问题？
    - **内存碎⽚**
      - 外部内存碎⽚，也就是产⽣了多个不连续的⼩物理内存，导致新的程序⽆法被装载；
      - 内部内存碎⽚，程序所有的内存都被装载到了物理内存，部分内存并不常⽤，导致浪费；
    - **内存交换的效率低**
      - 解决外部内存碎片采用**内存交换**的方式，即把这下不连续的内存碎片先写到硬盘再读回内存
      - 多进程的系统来说，⽤分段的⽅式，很容易产⽣内存碎⽚，但硬盘速度很慢，如果内存交换的时候，交换的是⼀个占内存空间很⼤的程序，开销很大
13. 说一说内部碎片与外部碎片
    - 内部碎片
        已经被分配出去，能明确指出属于哪个进程，却不能被利用的内存空间，直到进程释放或者结束才能被使用
        常发生于固定分区存储管理，页式虚拟存储系统存在内部碎片
    - 外部碎片
        外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。
        常发生于分段分页式存储管理， 段式虚拟存储系统
14. 如何解决外部碎片与内部碎片的问题？
    - linux是段页式的内存管理方式，内存划分为页，就不存在无法利用的小碎片。同时通过内存交换合并碎片的页。而且由于linux的的换入换出是以页为单位的所以小效率较高。
    - 内部碎片的话，linux会**将进程最近未使用的页面换出**，并且加载程序到内存时也不完全载入，只有**用到了才通过缺页中断载入**
15. 说一说分页机制
    - 分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩称为页，在 Linux 下，每⼀⻚的⼤⼩为 **4KB**，虚拟地址与物理地址之间通过**⻚表**来映射.分页可以解决分段的内存碎⽚、内存交换效率低的问题
    - ⻚表是存储在内存⾥的， **内存管理单元 （MMU）**就做将虚拟内存地址转换成物理地址的⼯作
16. 分⻚是怎么解决分段的内存碎⽚、内存交换效率低的问题？
   - 内存空间都是预先划分好的，也就不会像分段会产⽣间隙⾮常⼩的内存,采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存
   - 如果内存空间不够，操作系统会把其他正在运⾏的进程中的**最近没被使⽤**，也就是**LRU算法**的内存⻚⾯暂时写在硬盘上，称为换出。需要的时候，再换⼊。所以，⼀次性写⼊磁盘的也只有少数的⼀个⻚或者⼏个⻚，不会花太多时间， 内存交换的效率就相对⽐较⾼。
   - 分⻚的⽅式使得我们在加载程序的时候，不再需要⼀次性都把程序加载到物理内存中。只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再加载到物理内存⾥⾯去。
17. 分⻚机制下，虚拟地址和物理地址是如何映射的？
    - 简单页表
        对于简单的页表,虚拟地址分为两部分，**⻚号和⻚内偏移**.通过页号找到页表中的对应的物理内存的基地址,加上页内偏移就得到了物理内存地址
        但简单页表会有空间上的缺陷.对于32位,虚拟地址4GB,需要100万个页来存储,一个页表项4个字节,那么一个进程就需要4MB的内存来存页表
    - 多级页表
        如果采用**二级分页**,一级页表内存二级页表,二级页表再存页表项.这样**一级⻚表就可以覆盖整个 4GB 虚拟地址空间，但如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表**了，即可以在需要时才创建⼆级⻚表。64位系统里是四级页表。但多级页表降低了地址转换的效率
18. 说一说系统如何提高访问页表的效率？（说一说**快表**）
    局部性原理，通过**TLB页表缓存（快表）**，将最常访问的⼏个⻚表项存储到缓存中。这样CPU 在寻址时，会先查 TLB里是否由匹配的页号，如果有，就会将对应的物理内存的基地址加上页内偏移得到虚拟地址。如果没找到，才会继续查常规的⻚表。快表存储在CPU高速缓存中，这样就只需要访问一次内存
19. 地址变换中，有快表和没快表，有什么区别？
    没有快表的话，在内存中访问页表再访问页，需要访问两次内存。而有快表的话，就只需要访问一次内存。但是如果快表未命中就还需要访问两次内存。
20. 页表项都包括哪些字段?
    **页号，物理页号，状态位，修改位，硬盘地址**
21. 说一说MMU的工作流程（地址访问的流程）
    MMU内存管理单元完成虚拟内存地址转换成物理地址的工作。CPU 在寻址时，MMU会先查 TLB，如果命中了，就可以获得物理块号, 然后直接去物理内存中取出页面。如果没找到, 才会去物理内存中继续查常规的页表, 然后进行虚拟地址转换, 然后再访问物理内存, 读出页面。
22. 说一说缺页异常（缺页中断）
    - 当进程访问的虚拟地址在⻚表中无效时，系统会产⽣⼀个缺⻚异常（同时**保存CPU上下文**）
    - 操作系统收到缺页中断会执行缺⻚中断处理函数，先会查找该⻚⾯在磁盘中的⻚⾯的位置（因为程序就存储在磁盘中）
    - 找到磁盘中页面后，再在物理内存中寻找空闲页，如果有，就把该页面换入到物理内存中
    - 更新页表项
    - CPU重新执行导致缺页异常的指令
    - 找不到空闲⻚的话，就说明此时内存已满了，这时候，就需要⻚⾯置换算法选择⼀个物理⻚，如果该物理⻚有被修改过（脏⻚），则把它换出到磁盘，然后把该被置换出去的⻚表项的状态改成⽆效的，最后把正在访问的⻚⾯装⼊到这个物理⻚中
23. 缺页异常与一般中断的区别
    - 缺⻚中断在指令**执⾏期间**产⽣和处理中断信号，⽽⼀般中断在⼀条指令**执⾏完成后**检查和处理中断信号。
    - 缺⻚中断返回到该指令的开始**重新执⾏**该指令，⽽⼀般中断返回回到该指令的**下⼀个指令执⾏**
24. 说一说内存⻚⾯置换算法
    当出现缺⻚异常，需调⼊新⻚⾯⽽内存已满时，选择被置换的物理⻚⾯，也就是说选择⼀个物理⻚⾯换出到磁盘，然后把需要访问的⻚⾯换⼊到物理⻚
    - **最佳⻚⾯置换算法**
        置换在未来最⻓时间不访问的⻚⾯
        实际系统中⽆法实现，因为程序访问⻚⾯时是动态的，我们是⽆法预知每个⻚⾯在下⼀次访问前的等待时间，用处是衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是⾼效的
    - 先进先出置换算法（FIFO）
        选择在内存驻留时间最⻓的⻚⾯进⾏中置换
    - 最近最久未使⽤的置换算法（LRU）
        选择最⻓时间没有被访问的⻚⾯进⾏置换
        开销大，需要维护所以页面的链表，并且每次访问内存时都要更新整个链表
    - 时钟⻚⾯置换算法
        把所有的⻚⾯都保存在⼀个类似钟⾯的环形链表中，⼀个表针指向最⽼的⻚⾯。发生缺⻚中断时，找到访问位为0的页面，插入该位置，将表针前移。否则清除访问位并前移。
    - 最不常⽤算法（LFU）
        当发⽣缺⻚中断时，选择访问次数最少的那个⻚⾯，并将其淘汰。
        开销大，并且没有考虑时间问题。但是现在已经没有访问了，⽽当前频繁访问的⻚⾯由于没有这些⻚⾯访问的次数⾼，在发⽣缺⻚中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不⾼的⻚⾯。
25. 说一说段页式内存管理（寻址过程）
    内存分段和内存分⻚相组合。先将程序划分为多个段，接着再把每个段划分为多个⻚。虚拟地址分为三部分，段号，段内页号，页内位移。由段号从段表中得到页表起始地址，再从页表中得到物理页号，再加上页内位移得到物理地址。
    通常会在系统中设置一个页表寄存器(PTR)，存放页表在内存中的起始地址F和页表长度M。进程未执行时，页表的始址和页表长度放在进程控制块(PCB) 中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。
26. 说一说Linux 采⽤了什么⽅式管理内存
    Linux 内存主要采⽤的是⻚式内存管理，也涉及到段机制。因为Intel的CPU硬件结构决定了只能线进行段式映射，再进行页式映射。Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是⼀样的。
27. 说一说Linux的虚拟地址空间（和C++内存分区稍有不同）
    - 分为内核空间和用户空间。32位系统内核空间占⽤ 1G ，位于最⾼处，剩下的 3G 是⽤户空间；64 位系统的内核空间和⽤户空间都是 128T ，分别占据整个内存空间的最⾼和最低处，剩下的中间部分是未定义的。
    - 每个进程都各⾃有独⽴的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。
    - ⽤户空间内存，从低到⾼分别是：
        程序文件段，.text
        已初始化数据段，.data, 比如已初始化的全局变量
        未初始化数据段，.bass, 比如未初始化的全局变量
        堆区，动态分配的内存，从低地址向高地址增长(malloc())
        文件映射段，包括动态库，共享内存(mmap()，动态分配)
        栈段，包括局部变量，从高地址向低地址增长
    - 内核空间
28. 说一说内存交换
    内存空间紧张时，系统将内存中某些处于阻塞状态的进程暂时换出外存，把外存中某些就绪挂起的进程换入内存。内存交换一般在多进程运行且内存紧张的时候发生，比如发现运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程;如果缺页率明显下降，就可以暂停换出
29. 在发生内存交换时，有哪些进程是被优先考虑的？你可以说一说吗？
    可优先换出阻塞进程;
    可换出优先级低的进程;
    为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间… (注意: PCB 会常驻内存，不会被换出外存）
30. 内存交换有什么要注意的？
    - 交换需要备份存储到磁盘，磁盘的访问速度要快，并且容量够大
    - 有效使用CPU，需要每个进程的执行时间比交换时间长，交换时间与所交换的空间内存成正比
31. 说一说内存覆盖
       由于程序运行时并非任何时候都要访问程序及数据的各个部分， 因此可以把用户空间分成为一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按照调用关系分段，首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统将其调入覆盖区，替换覆盖区中原有的段。
       这样就使得一个进程不需要将全部信息都放入内存才能运行，节省了内存
32. 内存交换和覆盖有什么区别？
       内存交换和覆盖都是用于在多进程环境中扩展内存，但覆盖主要用于早期系统，内存交换现在还在使用。交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一程序或进程中。 
33. 抖动你知道是什么吗？它也叫颠簸现象
    刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够)
    为进程分配的物理块太少，会使进程发生抖动现象。为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率 为了研究为应该为每个进程分配多少个物理块，Denning 提出了进程工作集” 的概念
34. 动态分区分配算法有哪几种？可以分别说说吗？（动态分区是如何分配内存的？）
    - 首次适应算法
        每次都从低地址开始查找，找到第一个能满足大小的空闲分区。具体是通过按地址递增的空闲分区链来查找
    - 最佳适应算法
        优先使用更小的空闲区，来留下大的空闲区给大进程。具体是通过按容量递增排序的空闲分区链来查找
    - 最坏适应算法（最大适应算法）
        优先使用最大的空闲区，防止留下很大很小的空间碎片。具体是通过按容量递减排序的空闲分区链来查找
    - 邻近适应算法
        首次适应算法每次都从链头开始查找, 而这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能减小开销。具体是通过按地址递增的空闲分区的循环链表来实现
    - 区别
        首次适应算法最简单以及最好最快，但会增加查找开销。邻近算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间分裂成小的碎片，它通常比首次适应算法结果要差。最佳导致大量碎片，最坏导致没有大的空间。
35. 虚拟技术你了解吗？
    虚拟技术把一个物理实体转换为多个逻辑实体。主要有两种虚拟技术：时分复用技术和空分复用技术。
    多进程与多线程：多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。
    虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。
36. 操作系统在对内存进行管理的时候需要做些什么?
    操作系统负责内存空间的分配与回收。
    操作系统需要提供某种技术从逻辑上对内存空间进行扩充。
    操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。
    操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰
#### 3. 进程管理
1. 程序是什么？
    程序是包含一系列信息的文件，这些信息描述了如何在运行时创建一个进程。
    包括：机器语言指令，数据（变量初始值），共享库和动态链接信息等等
2. 进程是什么？
    进程是正在运行的程序的实例，也是系统进行资源分配和调度的基本单位
3. 进程和程序的区别
   - 进程占用内存，CPU等资源，而程序只占用磁盘 
   - 进程是正在运行的程序的实例。 进程既是基本的分配单元，也是基本的执行单元。
   - 可以用一个程序来创建多个进程
4. 说一说进程的状态
   - 三态模型
        运⾏状态（Runing）：该时刻进程占⽤ CPU；
        就绪状态（Ready）：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏；
        阻塞状态（Blocked）：该进程正在等待某⼀事件发⽣（如等待输⼊/输出操作的完成）⽽暂时停⽌运⾏，这时，即使给它CPU控制权，它也⽆法运⾏；
   - 五态模型
        创建状态（new）：进程正在被创建时的状态；
        结束状态（Exit）：进程正在从系统中消失时的状态；
   - 七态模型
        挂起（睡眠sleep）状态：描述进程没有占⽤实际的物理内存空间的情况
        阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
        就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏；
5. 说一说进程的状态变迁
        进程先是创建状态，然后进入就绪队列即就绪状态，被调用后进入运行状态，如果等待事件则进入阻塞状态。如果结束则进入结束状态。如果时间片用完或者等待的事件完成则进入就绪状态。如果进程运行中被挂起就进入就绪挂起状态，如果在阻塞状态被挂起就进入阻塞挂起状态。被激活后在进入就绪或阻塞状态
6. 为什么要把进程挂起？
    如果有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，应当把这些进程换出到硬盘
7. 导致进程挂起的原因是什么？
   - 进程所使⽤的内存空间不在物理内存
   - 通过 sleep 让进程间歇性挂起，其⼯作原理是设置⼀个定时器，到期后唤醒进程
   - ⽤户希望挂起⼀个程序的执⾏，⽐如在 Linux 中⽤ Ctrl+Z 挂起进程
8.  说一说CPU调度的时机
    - 从就绪态 -> 运⾏态：当进程被创建时，会进⼊到就绪队列，操作系统会从就绪队列选择⼀个进程运⾏；
    - 从运⾏态 -> 阻塞态：当进程发⽣ I/O 事件⽽阻塞时，操作系统必须另外⼀个进程运⾏；
    - 从运⾏态 -> 结束态：当进程退出结束后，操作系统得从就绪队列选择另外⼀个进程运⾏
9.  说一说CPU调度算法（进程调度算法）
    - 先来先服务（First Come First Seved, FCFS）算法
        每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个进程接着运⾏。
        FCFS 对⻓作业有利，适⽤于 CPU 繁忙型作业的系统，⽽不适⽤于 I/O 繁忙型作业的系统
    - 最短作业优先（Shortest Job First, SJF）调度算法
        优先选择运⾏时间最短的进程来运⾏
        对⻓作业不利
    - ⾼响应⽐优先（Highest Response Ratio Next, HRRN）调度算法
        兼顾短作业和长作业，高响应比优先，响应比 = （等待时间 + 要求服务时间）/要求服务时间
    - 时间⽚轮转（Round Robin, RR）调度算法
        每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏。
        如果时间⽚设得太短会导致过多的进程上下⽂切换
        如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓
    - 最⾼优先级（Highest Priority First， HPF）调度算法
        静态优先级
        动态优先级：随着时间的推移增加等待进程的优先级
        ⾮抢占式和抢占式
    - 多级反馈队列（Multilevel Feedback Queue）调度算法
        多级表示有多个队列，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短。
        反馈表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列；
        这样对于短作业很快就能运行完，对于长作业，如果在第一个队列时间片内没运行完会转入到第二队列的末尾等待运行。兼顾了⻓短作业，同时有较好的响应时间
10. 操作系统中用什么来描述进程？
    进程控制块（PCB），PCB 是进程存在的唯⼀标识
11. PCB 具体包含什么信息呢？
   - 进程标识符
   - 进程状态
   - 优先级
   - 有关内存地址空间的信息与CPU 中各个寄存器的值以便进程上下文切换
11. 每个 PCB 是如何组织的呢？
   - 通常是通过链表的⽅式进⾏组织
   - 就绪队列：将所有处于就绪状态的进程链在⼀起
     阻塞队列：把所有因等待某事件⽽处于等待状态的进程链在⼀起
12. 进程间共享什么？
    - 没有亲缘关系的进程
      - CPU
      - 共享内存
    - 父子进程fork()
      - 子进程内核空间拷贝父进程，但各自的PID不同
      - 子进程用户空间拷贝父进程，但读时共享，写时拷贝。需要写入时才复制地址空间，从而使各个进程拥有各自的地址空间
13. 说一说CPU的上下⽂切换
    - CPU上下⽂是CPU 在运⾏任何任务前，所必须依赖的环境，即CPU 寄存器和程序计数器。CPU 上下⽂切换就是先把前⼀个任务的 CPU 上下⽂保存起来，然后加载新任务的上下⽂，最后再跳转到程序计数器所指的新位置，运⾏新任务。
    - CPU 上下⽂切换分成： 进程上下⽂切换、线程上下⽂切换和中断上下⽂切换
14. 说一说进程的上下⽂切换
    - 进程的上下⽂切换包含虚拟地址空间、堆、栈、全局变量等⽤户空间的资源，还包括内核堆栈、寄存器等内核空间的资源。同时也会切换页表以使用新的的地址空间，同时缓存页作废
    - 切换步骤
        - 保存CPU上下文至当前进程的PCB中
        - 将PCB移入相应队列如就绪队列，阻塞队列
        - 选择另一个进程执行，使用其PCB恢复CPU上下文
        - 切换页表，刷新TLB快表
15. 发⽣进程上下⽂切换有哪些场景？ 
    - 进程的时间片用完
    - 系统资源不足时，进程会被挂起
    - sleep主动挂起
    - 高优先级进程先运行时被挂起
    - 硬件中断时被挂起，CPU来执行内核中的中断服务程序
16. 进程终止的几种方式
    - main函数的自然返回，return 
    - 调用exit函数，属于c的函数库 
    - 调用_exit函数，属于系统调用 
    - 调用abort函数，异常程序终止，同时发送SIGABRT信号给调用进程。 
    - 接受能导致进程终止的信号：ctrl+c (^C)、SIGINT(SIGINT中断进程)  
17. 孤儿进程
        父进程运行结束，但子进程还在运行（未运行结束），这样的子进程就称为孤儿进程（Orphan Process）。孤儿资源没有危害，因为其资源最后会由init进程来进行回收
18. 僵尸进程
       -  子进程结束之后, 都会释放自己地址空间中的用户区数据，再通过父进程释放掉内核区的 PCB数据。如果进程终止时，父进程尚未回收，子进程残留资源（PCB）存放于内核中，变成僵尸（Zombie）进程。会一直占用进程号，导致系统不能产生新的进程。一般通过让父进程调用wait()或waitpid()回收，或者直接结束父进程，让子进程变成孤儿进程由init进程回收。
       - 设置僵尸进程的目的是维护子进程的信息，以便父进程在以后通过wait()，waitpid()获取。
19. 如何避免僵尸进程？
    - 父进程设置signal忽略SIGCHID信号，子进程由init进程回收
    - 父进程设置信号捕捉函数sigaction捕捉SIGCHID，回调函数内用非阻塞的waitpid()循环回收子进程，一旦没有了就break
    - 通过两次调用fork。父进程首先调用fork创建一个子进程然后waitpid等待子进程退出，子进程再fork一个孙进程后退出。这样子进程退出后会被父进程等待回收，而对于孙子进程其父进程已经退出所以孙进程成为一个孤儿进程，孤儿进程由init进程接管，孙进程结束后，init会等待回收。
20. 说一说守护进程
    指在后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性地执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等
21. 如何创建守护进程
   - 调用fork（）产生一个子进程，然后使父进程退出，目的是防止进程组首进程产生会话产生冲突
   - 子进程调用 setsid() 开启一个新会话，创建的新会话没有控制终端，就可以防止键盘产生一些信号杀死这个终端
   - 清除进程的 umask 以确保当守护进程创建文件和目录时拥有所需的权限
   - 修改进程的当前工作目录，通常会改为根目录，防止运行时某些目录无效
   - 关闭守护进程从其父进程继承而来的所有打开着的文件描述符，节省系统资源
   - 处理SIGCHLD信号设为SIG_IGN,因为对于服务器进程往往会使用子进程处理请求，防止子进程结束时要等待父进程捕获状态而成为僵尸进程占用资源。如果忽略信号，子进程将由init进程进程回收 
22. 线程是什么？
    线程是进程当中的⼀条执⾏流程，是CPU执行的最基本单元。线程之间可以共享代码段、数据段等资源，但各自有⼀套独⽴的寄存器和栈
23. 线程的分类
    - 内核级线程：内核支持的线程，创建，销毁和切换都是内核实现，比如CPU是4核8线程，这里的线程就是内核级线程
    - 用户级线程：不依赖于操作系统核心，应用进程利用线程库来完成其创建和管理
24. 线程的优缺点？
    - 优点
        ⼀个进程中可以同时存在多个线程；
        各个线程之间可以并发执⾏；
        各个线程之间可以共享地址空间和⽂件等资源
    - 缺点
        当进程中的⼀个线程崩溃时，可能会导致其所属进程的所有线程崩溃。比如操作系统检测到异常，会kill掉进程，其他线程就一起被干掉了。
25. 为什么一个线程挂掉了其他线程也会挂掉
    进程（主线程）创建了多个线程，多个子线程均拥有自己独立的栈空间（存储函数参数、局部变量等），但是多个子线程和主线程共享堆、全局变量等非栈内存。如果子线程崩溃是由于对共享区域造成破坏那么大家都会一起崩溃。同时对于os来说，当线程崩溃时会直接插死进程。
26. 为什么需要线程？
    - 进程间通信开销大
    - 维护进程的系统开销大，比如进程切换时，需要保存进程的上下文
27. 线程上下⽂切换的是什么？
    - 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样；
    - 当两个线程是属于同⼀个进程，内核空间，共享库，堆空间，bss段，data段，text段，但是栈空间，寄存器，程序计数器不共享
28. 线程相⽐进程能减少开销体现在哪里？
    - 线程的创建时间⽐进程快
        因为进程在用fork（）创建的过程中，，即便利用写时复制技术，仍然需要复制诸如内存页表和文件描述符表之类的多种进程属性。而创建线程只需要将堆栈段要划分给一个新的线程, 以及一组寄存器
    - 线程的终⽌时间⽐进程快
        因为线程释放的资源相⽐进程少很多；
    - 同⼀个进程内的线程切换⽐进程切换快
        因为线程具有相同的地址空间（虚拟内存共享），这意味着同⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的；同时切换页表也会导致TLD页缓存失效，更慢了
    - 数据交流快
        由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼了
29. 什么时候该用多线程，什么时候该用多进程？
   -  频繁修改：需要频繁创建和销毁的优先使用多线程
   - 计算量：需要大量计算的优先使用多线程 因为需要消耗大量CPU资源且切换频繁，所以多线程好一点
   - 相关性：任务间相关性比较强的用多线程，相关性比较弱的用多进程。因为线程之间的数据共享和同步比较简单。
   - 多分布：可能要扩展到多机分布的用多进程，多核分布的用多线程
30. 一个进程可以创建多少线程，和什么有关？
    一个进程可以创建的线程数由可用虚拟空间和线程的栈的大小共同决定。理论上，一个进程可用虚拟空间是2G，默认情况下，线程的栈的大小是1MB，所以理论上最多只能创建2048个线程
31. 进程线程模型你知道多少？
    - 多进程
        - 进程是资源分配的基本单位。通过fork()创建子进程。子进程用户空间拷贝父进程，但读时共享，写时拷贝。需要写入时才复制地址空间，从而使各个进程拥有各自的地址空间。在命令行中执行文件创建的进程都是shell进程的子进程
        - 进程的上下文切换：...
        - 一些接口
            创建进程：pid_t fork(void);
            结束进程：void exit(int status);
            回收子进程：wait(), waitpid()
    - 多线程
       -  线程是调度的基本单位。对于用户态的多线程模型，同一个进程内部有多个线程，所有的线程共享同一个进程的内存空间，进程中定义的全局变量会被所有的线程共享。
       -  多线程的优点是首先减少了多进程创建销毁以及进程上下文切换的大量开销。并且
        原先顺序执行的程序可以被拆分成几个独立的逻辑流，这些逻辑流可以独立完成一些任务。
       -  多线程的缺点是会带来多线程共享资源导致的互斥和同步问题，并且当进程中的⼀个线程崩溃时，可能会导致其所属进程的所有线程崩溃。
       -  多线程的接口有：
            创建线程：pthread_create
            终止线程：pthread_exit
            分离线程（子线程自动回收线程资源）：pthread_detach
            连接已终止的线程（主线程调用回收已终止的线程的资源，类似于wait()会被阻塞）：pthread_join
32. 协程是什么？
    协程是一种用户态的轻量级线程，协程的调度完全由用户控制。
33. 为什么需要协程？
    - 节省CPU，内核级别的线程切换开销大，浪费CPU资源。而协程是用户态的线程，用户可以自行控制协程的创建于销毁，避免了系统级线程上下文切换造成的资源浪费。
    - 节约内存：线程占用内存多，协程占用内存少可以实现高并发
    - 更稳定，一个线程崩溃可能会导致进程中的所有线程都会跟着一起崩溃。
    - 开发效率更高，适用于异步IO
34. 协程上下文切换的是什么？
    寄存器和栈
35. 进程、线程和协程的区别和联系
    - 定义
        进程：资源分配基本单位，线程：程序执行的基本单位，协程用户态的轻量级线程，线程内部调度的基本单位
    - 上下文切换内容不同
        进程：虚拟地址空间、堆、栈、全局变量等⽤户空间的资源，还包括了内核堆 、栈、寄存器等内核空间的资源
        线程：程序计数器，寄存器，线程栈
        协程：寄存器，协程栈
    - 状态转变
        进程、线程：用户态，内核态，用户态
        协程:用户态
    - 并发性
        不同进程之间切换实现并发
        一个进程内部的多个线程并发执行
        同一时间只能执行一个协程，而其他协程处于休眠状态
    - 系统开销不同
        进程：创建销毁切换开销很大，切换时还需要切换页表
        线程：创建销毁需要的资源都很少，切换不需要切换页表，只需要切换线程栈，寄存器与程序计数器
        协程：相较线程只在用户态，没有内核切换的开销
    - 通信方式不同
        进程：进程间通信，比如管道，共享内存，socket
        线程：共享内存，通过全局变量通信
        协程：共享内存
36. 说一说进程间通信的方式
    - 管道：速度慢，容量有限
    - 消息队列：容量有限
    - 共享内存：速度最快，但需要同步互斥机制
    - 信号量：只能用于同步互斥机制中，不能传递复制消息
    - 信号：不能传递复制消息
    - socket：能够用于任何进程，但速度慢
37. 说一说线程间通信的方式
    - 共享内存（全局变量）
    - 信号
    - 信号量
    - 锁
    - 条件变量
38. 说一说管道
     int pipe(int pipefd[2]);
     int mkfifo(const char *pathname, mode_t mode);
     管道其实是一个在内核内存中维护的缓冲器。一段输入，一段读取。管道传输的数据是⽆格式的流且⼤⼩受限。匿名管道用于父子进程间通信，有名管道用于没有亲缘关系的进程间的通信。
39. 如何利用管道通信？
    对于匿名管道fork()后的父子进程共享同一文件描述符表，父子进程都拥有了管道的读端和写段。如果需要双向通信，则应该创建两个管道。而命名管道就需要通过管道文件作为媒介通信。
40. shell里管道命令实际是怎么工作的？
    shell ⾥⾯执⾏ A | B 命令的时候， A 进程和 B 进程都是 shell 创建出来的⼦进程， A 和 B 之间不存在⽗⼦关系，它俩的⽗进程都是 shell。在 shell ⾥通过 | 匿名管道将多个命令连接在⼀起，实际上也就是创建了多个⼦进程。在我们编写 shell 脚本时，能使⽤⼀个管道搞定的事情，就不要多⽤⼀个管道，这样可以减少创建⼦进程的系统开销。
41. 说一说消息队列
    管道的通信⽅式是效率低的，因此管道不适合进程间频繁地交换数据，消息队列解决了这个问题。消息队列是保存在内核中的消息链表，以消息体的格式发生数据。每个消息体都是固定⼤⼩的存储块，不像管道是⽆格式的字节流数据。
42. 说一说消息队列和管道的区别
    - 传输的格式不同
    - 通信效率不同
    - 生命周期不同，消息队列⽣命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会⼀直存在，⽽匿名管道是随进程的创建⽽建⽴，随进程的结束⽽销毁
43. 说一说消息队列的缺点
    - 消息队列不适合⽐较⼤数据的传输，消息体有长度限制
    - 消息队列通信过程中，存在⽤户态与内核态之间的数据拷⻉开销，因为进程写⼊数据到内核中的消息队列时，会发⽣从⽤户态拷⻉数据到内核态的过程，同理另⼀进程读取内核中的消息数据时，会发⽣从内核态拷⻉数据到⽤户态的过程。
44. 说一说共享内存
    int shmget(key_t key, size_t size, int shmflg);
    共享内存是效率最高的一种进程间通信方式，共享内存的机制，就是不同的进程拿出⼀块虚拟地址空间来，映射到相同的物理内存中。
45. 共享内存效率高在哪里？
    不需要像管道或者消息队列一样，存在⽤户态与内核态之间的数据拷⻉开销，也不需要频繁切换用户态和内核态
46. 说一说条件变量
    pthread_cond_t，使用通知的方式解锁，与互斥锁配合使用。这样在不满足竞态条件的时候，我们就可以主动解开互斥锁。条件变量不是锁，当满足某个条件时，条件变量可以阻塞线程或者解除阻塞。解决不了线程同步问题。
47. 说一说信号量
    使用共享内存通信会导致多进程竞争共享资源造成数据错乱。信号量其实就是⼀个整型的计数器，就可以实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。通常信号量表示资源的数量，对应的变量是⼀个整型（ sem ）变量。两个原⼦操作的系统调⽤函数来控制信号量的。P操作信号量-1，如果sem<0, 阻塞。V操作信号量+1，如果sem>=0,唤醒。
48. 信号量是如何实现进程/线程间的互斥与同步的？
    - 进程：共享内存，线程:全局变量
    - 信号量：sem_t
        互斥：初始化信号量为 1，A进程通过P操作减1，访问到共享内存。B进程经过P操作后发现信号量<0,阻塞。A处理完后V操作，信号量为0，B被唤醒 
        同步：初始化信号量为 0，线程B先通过P操作减1阻塞，此时线程A如果完成动作后执行V操作，则B被唤醒
49. 说一说信号
    - 信号是进程间通信机制中唯⼀的异步通信机制。因为可以在任何时候发送信号给某⼀进程，⼀旦有信号产生，就有3种处理方式
      - 执行默认操作
      - 捕捉信号，执行相应的信号处理/回调函数（signal()，sigaction()）
      - 忽略信号，但是SIGKILL和SIGSTOP无法忽视或者捕捉
    - 常见信号(raise())
      - SIGKILL(kill())
      - SIGABORT(abort())
      - SIGSTOP
      - SIGALARM(alarm(), setitimer())
      - SIGCHID
50. 说一说信号集
    - 许多信号相关的系统调用都需要能表示一组不同的信号，多个信号可使用一个称之为信号集的数据结构来表示，其系统数据类型为 sigset_t
    - 阻塞信号集与未决信号集
        - 阻塞信号集用于阻塞信号被处理留待以后发生，未决信号集就是当就是还没有被处理的信号集，用于和阻塞信号集做比较。
        - 如果没有阻塞，这个信号就被处理
        - 如果阻塞了，这个信号就继续处于未决状态，直到阻塞解除，这个信号就被处理
        - 只能修改阻塞信号集，未决信号集只能被获取
    - sigprocmask()将用户设置的阻塞信号集添加到内核中(在SIGCHID解决僵尸进程中有使用)
    - 常规信号不支持排队，未决信号集只能标记一次的状态，即只能记录一个信号是否是未决，当其中某个信号被阻塞时，后面如果又来了相同的信号，它们都会被丢弃（其他序号32后面的支持排队）
51. 说一说内核实现信号捕捉的过程
   1. 在执行主控制流程的某条指令时因为中断、异常或系统调用进入内核
   2. 内核处理完异常准备回用户模式之前先处理当前进程中可以递送的信号
   3. 如果信号的处理动作为自定义的信号处理函数，则回到用户模式执行信号处理函数（而不是回到主控制流程）
   4. 信号处理函数返回时执行特殊的系统调用sigreturn再次进入内核
   5. 返回用户模式从主控制流程中上次被中断的地方继续向下执行
52. 说一说SIGCHID
    - SIGCHLD信号产生的3个条件：
      1. 子进程结束
      2. 子进程暂停了
      3. 子进程继续运行
    - 以上三种情况内核都会给父进程发送该信号，父进程默认忽略该信号。
    - 作用：使用SIGCHLD信号解决僵尸进程的问题。
    - 改进方案是通过非阻塞的waitpid来回收进程，设置循环，循环内调用waitpid()一旦收到SIGCHLD信号，就把所有已经死亡的子进程的资源回收，如果还有未回收的子进程或者所有子进程已死亡，break，通过回调函数回到父进程执行位置（不需要关心有多少个SIGCHID的信号被忽略了，因为收到一个就会回收所有的已死亡的子进程）
    - 要提前在主函数中设置好对应的阻塞信号集，因为有可能子进程很快结束，而父进程还没有注册完信号捕捉。在创建子进程前设置好阻塞信号集，在父进程执行中解除阻塞信号集即可。
53. 说一说socket
     int socket(int domain, int type, int protocal)
     Socket 通信不仅可以跨⽹络与不同主机的进程间通信，还可以在同主机上进程间通信。还可以指定通信的方式，如TCP,UDP还是本地进程间字节流通信
54. 针对 TCP 协议通信的 socket 编程模型
    服务端和客户端初始化 socket ，得到⽂件描述符；
    服务端调⽤ bind ，将绑定在 IP 地址和端⼝;
    服务端调⽤ listen ，进⾏监听；
    服务端调⽤ accept ，等待客户端连接；
    客户端调⽤ connect ，向服务器端的地址和端⼝发起连接请求；
    服务端 accept 返回⽤于传输的 socket 的⽂件描述符；
    客户端调⽤ write 写⼊数据；服务端调⽤ read 读取数据；
    客户端断开连接时，会调⽤ close ，那么服务端 read 读取数据的时候，就会读取到了 EOF ，待处理完数据后，服务端调⽤ close ，表示连接关闭。
    监听 socket，已完成连接 socket
55. 针对 UDP 协议通信的 socket 编程模型
    UDP 是没有连接的，不需要三次握⼿，只需要IP地址和端口号
    客户端/服务端：socket()初始化，bind()绑定IP和端口，再通过sendto()和recvfrom()传输数据
56. 针对本地进程间通信的 socket 编程模型
    本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端⼝，⽽是绑定⼀个本地⽂件
57. 为什么会发生多进程（线程）竞争共享资源造成数据错乱？
    因为实际进程（线程）运行过程种调度不可控不可知，比如对共享内存中的一个数字进行修改大概分为三个步骤，从内存中取值并放入寄存器，寄存器修改值，值放回内存。可能进程（线程）只执行了1，2步切换到另一个（进程）线程，而这个（进程）线程重复的完整执行了三个步骤，这时候又切换到第一个（进程）线程,则又会执行第三部，相当于第二个（进程）线程未做修改。
58. 说一说共享
    共享是指系统中的资源可以被多个并发进程共同使用。
    有两种共享方式：互斥共享和同时共享。
    互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问
59. 说一说互斥
    保证⼀个线程在临界区执⾏时，其他线程应该被阻⽌进⼊临界区。互斥也并不是只针对多线程。在多进程竞争共享资源的时候，也同样是可以使⽤互斥的⽅式来避免资源竞争造成的资源混乱。
60. 说一说同步
    同步，就是并发进程/线程在⼀些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。
61. 一般如何实现多线程的互斥与同步？
    - 临界区
        当多个线程访问一个独占性共享资源时，可以使用临界区对象，只限制同一进程的线程之间，开销更小
        注意linux下没有临界区对象，只适用于windows
    - 锁和条件变量
        使⽤加锁操作和解锁操作可以解决并发线程/进程的互斥问题，允许多进程
    - 信号量（sem_t互斥信号量初始为1和互斥锁效果相同）
       信号量其实就是⼀个整型的计数器，就可以实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。通常信号量表示资源的数量，对应的变量是⼀个整型（ sem ）变量。两个原⼦操作的系统调⽤函数来控制信号量的。P操作信号量-1，如果sem<0, 阻塞。V操作信号量+1，如果sem>=0,唤醒。
       当初始信号量设置为1就可以实现临界区的互斥访问，设置为0就可以实现同步访问
62. 说一说经典的同步问题
    - 生产者与消费者问题
    - 哲学家就餐问题
    - 读者与写者问题
63. 说一说生产者与消费者问题
    - 问题描述
    ⽣产者在⽣成数据后，放在⼀个缓冲区中；消费者从缓冲区取出数据处理；任何时刻， 只能有⼀个⽣产者或消费者可以访问缓冲区，并且生产者与消费者之间需要同步
    - 实现
        需要三个信号量，一个是缓冲区的互斥锁mutex，一个是用于表示缓冲区是否有数据的信号量fullBuffers，初始化为0，最后是用于表示缓冲区是否有空闲存放数据的信号量emptyBuffers，初始化为n。这样消费者线程⼀开始执⾏ P(fullBuffers) ，此时 fullBuffers 的值从 0 变为 -1，说明缓冲区⾥没有数据，消费者只能等待。⽣产者执⾏ P(emptyBuffers) ，表示减少 1 个空槽，如果当前没有其他⽣产者线程在临界区执⾏代码，那么该⽣产者线程就可以把数据放到缓冲区，放完后，执⾏ V(fullBuffers) ，信号量 fullBuffers变成 0，于是阻塞等待的消费者线程会被唤醒
64. 说一说哲学家就餐问题
    - 问题描述
        5个人在圆桌上吃饭，每两个人之间有一个叉子，一共5个叉子，每个人需要2个叉子才能吃饭，吃完后放回叉子，如何保证所有人都能够有序吃饭？
    - 实现
      - 信号量
            用5个信号量代表5个叉子，初始化为1，每个线程先后拿左右的叉子，即对左右的叉子进行P操作，吃完后在进行V操作
            当5个线程同时对左边叉子进行P操作就会造成死锁
      - 信号量+互斥锁
            设置一个互斥锁，在拿起左右叉子前加锁，放下左右叉子后解锁，不会发生死锁，但通知只能保证一个线程就餐
      - 信号量 + 分支结构
            单用信号量出现死锁的原因在于可能所有线程都先拿起左边的叉子，那么只要让偶数号的线程先拿左边叉子后拿右边叉子，奇数号线程先拿右边叉子在拿左边叉子就即奇偶线程P操作顺序左右相反不会死锁，由于V操作不会阻塞先后就可以一样。这就可以保证两个线程同时就餐
      - 信号量 + 数组记录每⼀位哲学家在进餐、思考还是饥饿状态
            信号量初始化为1.如果一个哲学家左右都没有进餐，就可以进入就餐状态。之后拿起叉子并进行P操作。就餐后放回叉子，通过V操作通知其他哲学家可以就餐。
    - 应用场景
        对于互斥访问有限的竞争问题（如 I/O 设备）⼀类的建模过程
65. 说一说读者与写者模型
    - 问题描述
       读-读允许，读-写互斥，写-写互斥
    - 实现
      - 分为读者优先，写者优先，公平策略
      - 信号量解决
            互斥信号量wMutex控制写操作，读者计数rCount记录正在读的读者数目，信号量rCountMutex控制对rCount的互斥修改，初始化为1。读者优先下会阻塞写者。
            如果是写者优先的化就要增加一个互斥信号量rMutex来阻塞读者。
            公平策略的话，大概也是通过信号量和锁来进行互斥和同步的。具体细节记不清了。
#### 4. 锁
1. 说一说锁
    锁是用来解决多线程或者多进程竞争共享资源而导致数据错乱的方式，针对不同的应⽤场景有
    互斥锁、⾃旋锁、读写锁、乐观锁、悲观锁
2. 为什么要有这么多锁？
    因为锁本身有开销，在高并发的场景下，可能会降低系统的性能。要针对不同的应用场景使用不同的锁来避免性能的降低
3. 信号量和锁有什么区别
   - 信号量可以实现多线程之间的同步和互斥问题，通过PV原子操作进行同步和互斥
   - 锁一般是实现多线程中的互斥问题，通过加锁实现临界区。锁就相当于信号量设置为1的情况，但是锁更简单，所以一般互斥用锁实现
4. 说一说互斥锁（互斥量  pthread_mutex_t）与自旋锁
   - 互斥锁加锁失败后，线程会被内核挂起，释放CPU ，给其他线程
   - ⾃旋锁加锁失败后，线程会忙等待，占用CPU，直到它拿到锁
   - 应用场景
        互斥锁有线程上下文切换的开销，可能切换的时间比锁住代码时间还长。所以适用于被锁住的代码执⾏时间较长的情况
        自旋锁是在⽤户态完成加锁和解锁操作，没有上下文开销，但会⻓时间占⽤ CPU 资源，所以⾃旋的时间和被锁住的代码执⾏的时间是成正⽐的关系
   - 互斥锁与自旋锁是锁的最基本处理⽅式，更⾼级的锁都会选择其中⼀个来实现，⽐如读写锁既可以选择互斥锁实现，也可以基于⾃旋锁实现
5. 说一说读写锁（pthread_rwlock_t）
   - 只读取共享资源⽤读锁加锁，如果要修改共享资源则⽤写锁加锁
   - 读锁是共享锁，写锁是独占锁。读读不阻塞，写读和写写都阻塞
   - 读写锁适⽤于能明确区分读操作和写操作的场景，且最好读多写少才效果好
   - 读优先锁：对于读线程并发性更好，缺点是如果一直有读线程，写线程就一直获取不到锁
   - 写优先锁：对于写线程并发性更好，缺点是如果一直有写线程，读线程就一直获取不到锁
   - 公平读写锁：⽤队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁
6. 说一说乐观锁和悲观锁
   - 悲观锁
        多线程同时修改共享资源的概率⽐较⾼，于是很容易出现冲突，所以访问共享资源前，先要上锁
        互斥锁、⾃旋锁、读写锁，都是属于悲观锁
   - 乐观锁
        假定冲突的概率很低，先修改完共享资源，再验证这段时间内有没有发⽣冲突（通过版本号），如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。
        乐观锁全程并没有加锁，所以它也叫⽆锁编程
        缺点是：重试的成本非常高
7.  说一说加锁的注意事项
    - 不要造成死锁
    - 根据应用场景加不同的锁
    - 加锁的代码范围应该尽可能的⼩，也就是加锁的粒度要⼩，这样执⾏速度会⽐较快
8. 说一说死锁
    当两个线程为了保护两个不同的共享资源⽽使⽤了两个互斥锁，这可能会造成两个线程都在等待对⽅释放锁，在没有外⼒的作⽤下，这些线程会⼀直相互等待，就没办法继续运⾏，即产生了死锁
9.  说一说发生死锁的条件
   - 互斥条件：多个线程不能同时使⽤同⼀个资源
   - 持有并等待条件：线程持有一个资源，并等待另一个资源释放
   - 不可剥夺条件：线程的资源在⾃⼰使⽤完之前不能被其他线程获取
   - 环路等待条件：两个线程获取资源的顺序构成了环形链，比如A持有资源1申请资源2，B持有资源2申请资源1，就会形成环路等待
11. 如何利用工作排查死锁问题
    - 先利用pstack查看每个线程的栈信息，如果一直没有变化说明出现了死锁
    - 再通过gdb调试
      - info thread 打印所有线程信息
      - 通过thread 2切换到可能出现死锁的线程，通过bt打印线程的调用栈
      - 通过frame 3打印调用栈中的帧信息，发现获取哪个锁时阻塞
      - p mutex_A打印锁对象信息，找到拥有改锁的线程
12. 如何应对死锁情况？
   - 鸵鸟策略
        因为死锁发生的概率很低而且解决的代价很高，所以大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它
   - 死锁恢复
        不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。
        利用回滚恢复
        通过杀死进程恢复
   - 死锁预防
     一般来讲只要破坏死锁条件中的任意一个条件就行，最常⻅的并且可⾏的就是使⽤资源有序分配法，来破环环路等待条件。比如A先获取锁1再获取锁2，B先获取锁2再获取锁1，那么只要AB获取锁12的顺序一样就可以解决死锁问题。
     对于不可剥夺条件，可以在申请不到新资源时主动释放已有资源。对于持有等待条件，可以一次性申请所有资源。
   - 死锁避免
     在程序运行时避免发生死锁。大概是通过安全状态和银行家算法来分配资源。
11. 说一说活锁
    - 多线程中出现了相互谦让,都主动将资源释放给别的线程使用,这样资源在多个线程之间跳动而又得不到执行,形成活锁。活锁是加不上锁就放开已获得的资源重试。和死锁相反。
    - 解决办法
        解决活锁的一个简单办法就是在下一次尝试获取资源之前,随机休眠一小段时间。




#### 5. 调度算法
1. CPU调度算法（进程调度算法）
2. 内存页面置换算法
3. 磁盘调度算法
   - 目的：提⾼磁盘的访问性能，⼀般是通过优化磁盘的访问请求顺序来做到的，其中寻道时间最长
   - 先来先服务（FCFS）
        先到来的请求，先被服务.
        如果⼤量进程竞争使⽤磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过⻓
   - 最短寻道时间优先(SSF)
        优先选择从当前磁头位置所需寻道时间最短的请求
        动态请求下，可能会导致磁头在一小块区域来回移动，有些区域无法被访问
   - 扫描算法
        磁头在⼀个⽅向上移动，访问所有未完成的请求，直到磁头到达该⽅向上的最后的磁道，才调换⽅向，这就是扫描（Scan）算法
        不会产生饥饿现象，但会导致每个磁道的响应频率存在差异，中间部分相⽐其他部分响应的频率会⽐较多
   - 循环扫描算法
        总是按相同的⽅向进⾏扫描，到达最边缘后快速复位，返回中途不处理任何请求
        使得每个磁道的响应频率基本⼀致。
   - LOOK 与 C-LOOK算法
        LOOK：针对扫描算法的优化，磁头在移动到最远的请求位置，然后⽴即反向移动，反向移动的途中会响应请求
        C-LOOK：针对循环扫描算法的优化， ，磁头在移动到最远的请求位置，然后⽴即反向移动，反向移动的途中不会响应请求
4. IO调度算法

#### 6. 文件系统/IO相关
1. 说一说Linux的文件系统
    Linux一切皆文件，有7大文件：普通文件，目录，套接字，管道，软链接，存储设备，端口设备。Linux采用索引节点和目录项来记录文件的信息和目录层次结构。
    索引节点是⽂件的唯⼀标识，而目录项维护了目录的层次结构
2. 说一说文件的存储方式
   - 连续空间存放
        ⽂件存放在磁盘连续的物理空间中，读写效率很⾼，有磁盘空间碎⽚和⽂件⻓度不易扩展的缺陷
   - ⾮连续空间存放
     - 链表方式
        通过链表存放文件，可以消除磁盘碎⽚且易于扩展。
        隐式链表：通过指针顺序访问，稳定性差，指针丢失会导致文件数据丢失
        显式链表：将各数据库的指针存在在表中即文件分配表，在内存中查找，速度快，减少了访问磁盘的次数，但不适用于大磁盘
     - 索引方式
        为每个⽂件创建⼀个索引数据块，存放指向数据块的指针。没有磁盘碎片，易于扩展，支持顺序读取和随机读取。缺点是增加空间开销
3. Unix采用什么方式存储文件？
    多级索引块的方式。通过⼀个索引块来存放多个索引数据块，⼀层套⼀层索引。
4. 如何管理空闲空间？
    - 空闲表法
        有少量的空闲区时才有较好的效果。因为，如果存储空间中有着⼤量的⼩的空闲区，则空闲表变得很⼤，这样查询效率会很低。另外，这种分配技术适⽤于建⽴连续⽂件
    - 空闲链表法
        不能随机访问，增删开销大，不适用于大型文件系统
    - 位图法
        二进制位表示磁盘中盘块情况
5. Linux如何管理空闲空间？
    位图法
6. 说一说文件IO的方式
   - 缓冲与⾮缓冲 I/O
   - 直接与⾮直接 I/O
   - 阻塞与⾮阻塞 I/O 
   - 同步与异步 I/O
7. 说一说缓冲与非缓冲IO
    根据是否利⽤标准库缓冲，，可以把⽂件 I/O 分为缓冲I/O 和⾮缓冲 I/O
    缓冲 I/O，利⽤的是标准库的缓存实现⽂件的加速访问，⽽标准库再通过系统调⽤访问⽂件。
    ⾮缓冲 I/O，直接通过系统调⽤访问⽂件，不经过标准库缓存
    目的是减少系统调⽤的次数，毕竟系统调⽤是有 CPU 上下⽂切换的开销的
8. 说一说直接与非直接IO
    根据是否利⽤操作系统/内核的缓存即页缓存，可以把⽂件 I/O 分为直接 I/O 与⾮直接 I/O
    直接 I/O，不会发⽣内核缓存和⽤户程序之间数据复制，⽽是直接经过⽂件系统访问磁盘。
    ⾮直接 I/O，读操作时，数据从内核缓存中拷⻉给⽤户程序，写操作时，数据从⽤户程序拷⻉给内核缓存，再由内核决定什么时候写⼊数据到磁盘。
    目的是减少磁盘IO次数
9. 如果⽤了⾮直接 I/O 进⾏写数据操作，内核什么情况下才会把缓存数据写⼊到磁盘？
    在调⽤ write 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上；
    ⽤户主动调⽤ sync ，内核缓存会刷到磁盘上；
    当内存⼗分紧张，⽆法再分配⻚⾯时，也会把内核缓存的数据刷到磁盘上；
    内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上；
10. 说一说阻塞与非阻塞IO
    - 阻塞IO：
        当⽤户程序执⾏ read ，线程会被阻塞，⼀直等到内核数据准备好，并把数据从内核缓冲区拷⻉到应⽤程序的缓冲区中，当拷⻉过程完成， read 才  会返回
        阻塞等待的是内核数据准备好和数据从内核态拷⻉到⽤户态这两个过程
    - 非阻塞IO:
        ⾮阻塞的 read 请求在数据未准备好的情况下⽴即返回，可以继续往下执⾏，此时应⽤程序不断轮询内核，直到数据准备好，内核将数据拷⻉到应⽤程序缓冲区， read 调⽤ 才可以获取到结果
        非阻塞等待的是数据从内核态拷⻉到⽤户态这个过程
    - 基于非阻塞IO多路复用
        当内核数据准备好时，再以事件通知应⽤程序进⾏操作.通过内核而不是程序来循环遍历文件描述符。监控多个文件描述符的同时减少了系统调用的次数。
        但还需要等待内核将数据从内核空间拷⻉到应⽤程序空间
11. 说一说信号驱动IO
        通过信号处理函数，不阻塞，当进程收到SIGIO信号处理IO事件，但还需要等待内核将数据从内核空间拷⻉到应⽤程序空间
12. 说一说同步IO与异步IO
    IO是分为两个过程：数据准备的过程，数据从内核空间拷⻉到⽤户进程缓冲区的过程
    - 同步IO
        包括阻塞 I/O、⾮阻塞 I/O、信号驱动IO、基于⾮阻塞 I/O 的多路复⽤。因为它们在 read调⽤时，内核将数据从内核空间拷⻉到应⽤程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷⻉效率不⾼， read调⽤就会在这个同步过程中等待⽐较⻓的时间。
    - 异步IO
        异步I/O 是内核数据准备好和数据从内核态拷⻉到⽤户态这两个过程都不⽤等待
        发起 aio_read 之后，就⽴即返回，内核准备数据，并且⾃动将数据从内核空间拷⻉到应⽤程序空间，这个拷⻉过程同样是异步的，内核⾃动完成的，和前⾯的同步操作不⼀样，应⽤程序并不需要主动发起拷⻉动作。
13. 说一说最一般的IO（Linux 读写数据的整个流程）
    - read()调用，进程阻塞，CPU向磁盘发出IO请求
    - 磁盘控制器准备数据到内部缓冲区中，向CPU发出中断
    - CPU收到中断信号，切换上下文，将数据从磁盘控制器的缓冲区中拷贝到内核缓冲区，再从内核缓冲区（缓存页）拷贝到用户缓冲区中
    - read()返回，内核态切换未用户态
    全程需要CPU参与，不适合大量数据的搬运
14. 说一说直接内存访问（DMA）技术
    - read()调用，进程阻塞，CPU向DMA发出IO请求后执行其他任务
    - DMA向IO法术请求
    - 磁盘控制器准备数据到内部缓冲区中，向DMA发出中断
    - DMA将数据从磁盘缓冲区拷贝到内核缓冲区，向CPU发出中断
    - CPU收到信号，将数据从内核缓冲区（缓存页）拷贝到用户缓冲区中
    - read()返回
15. 说一说传统的文件传输（从磁盘到网卡）
    从磁盘到内核缓冲区，再到用户缓冲区，再到内核socket缓冲区，再到网卡。
    需要调用一次read()和一次write()，涉及4次⽤户态与内核态的上下⽂切换，以及4次数据拷贝即两次DMA拷贝（磁盘到内核，socket缓冲区到网卡），两次CPU拷贝（内核缓存区到用户缓冲区）
16. 优化⽂件传输的性能？（不涉及TCP）
    - 减少系统调⽤的次数
    - 传输文件时不修改数据所以不需要用户缓冲区
    - 使用mmap()替换read()，把内核缓冲区⾥的数据映射到⽤户空间，操作系统内核与⽤户空间就不需要再进⾏任何的数据拷⻉操作。但内核缓冲区到socket缓冲区还需要CPU拷贝，只减少了一次拷贝。
    - 使用sendfile()替换read()和write()，减少⼀次系统调⽤，也就减少了 2 次上下⽂切换的开销，并且是直接将内核缓冲区⾥的数据拷⻉到 socket 缓冲区⾥，又减少了一次CPU数据拷贝，即2次上下文切换，1次CPU，2次DMA
    - 真正的零拷贝：⽹卡⽀持 SG-DMA，DMA将内核缓冲区的数据直接拷贝到网卡，不使用CPU拷贝，也不经过用户缓冲区。只有2次DMA拷贝，2次上下文切换
17. 说一说零拷贝技术
    ⽹卡⽀持 SG-DMA，DMA将内核缓冲区的数据直接拷贝到网卡，不使用CPU拷贝，也不经过用户缓冲区。只有2次DMA拷贝，2次上下文切换。零拷⻉技术可以把⽂件传输的性能提⾼⾄少⼀倍以上
18. 说一说页缓存
    页缓存（PageCache），就是磁盘高速缓存，也是所谓的内核缓冲区。根据程序的局部性原理，刚被访问的数据在短时间内再次被访问的概率很⾼，于是我们可以⽤ PageCache 来缓存最近被访问的数据，当空间不⾜时淘汰最久未被访问的缓存。同时页缓存也有预读功能。
19. 大文件传输会对页缓存造成什么问题？
    - 大文件传输无法利用到页缓存即内核缓冲区，会浪费一次DMA拷贝，造成零拷贝的性能降低
    - 大文件会占据页缓存导致其他小文件无法利用到页缓存
20. ⼤⽂件传输⽤什么⽅式实现？
    - 在⾼并发的场景下，针对⼤⽂件的传输的⽅式，应该使⽤异步 I/O + 直接 I/O来替代零拷⻉技术
    - 采用异步IO，进程调用read()后直接返回，内核将磁盘中的数据直接拷贝到进程缓冲区不经过页缓存，进程收到内核的通知后再去处理数据
    - 异步 I/O 并没有涉及到 PageCache，所以使⽤异步 I/O 就意味着要绕开PageCache，即直接IO
    - 缺点是没有内核的两点优化：
        - 内核的 I/O 调度算法会缓存尽可能多的 I/O 请求在 PageCache 中，最后合并成⼀个更⼤的 I/O请求再发给磁盘
        - 内核也会预读后续的 I/O 请求放在 PageCache 中

#### 7. 网络模型/IO多路复用
1. 多进程模型
    - 基于最原始的阻塞⽹络 I/O，为每个客户端分配⼀个进程来处理请求。
    - 服务器的主进程负责监听客户的连接，accept() 函数就会返回⼀个已连接Socket，通过 fork() 函数创建⼀个⼦进程来针对已连接Socket通信。然后通过wait() 和 waitpid()回收子进程。
    - 缺点是无法应对大规模并发通信，进程上下文切换开销太大
2. 多线程模型
    - 当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将已连接 Socket的⽂件描述符传递给线程函数，接着在线程⾥和客户端进⾏通信，从⽽达到并发处理的⽬的
    - 缺点是也还是有线程切换的上下文开销以及频繁创建和销毁线程的开销。用线程池的⽅式可以避免线程的频繁创建和销毁，但也无法应对大规模并发通信（10K）。
3. I/O 多路复⽤
   - I/O 多路复⽤可以使⽤⼀个进程来维护多个 Socket，一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。
   - I/O 多路复⽤属于时分多路复⽤，⼀个进程虽然任⼀时刻只能处理⼀个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1秒内就可以处理上千个请求。
   - 通过select/poll/epoll 内核提供给⽤户态的多路复⽤系统调⽤，进程可以通过⼀个系统调⽤函数从内核中获取多个事件。在获取事件时，先把所有连接（⽂件描述符）传给内核，再由内核返回产⽣了事件的连接，然后在⽤户态中再处理这些连接对应的请求即可
   - 与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。
4. 说一说select如何实现多路复用
   - select 实现多路复⽤的⽅式是，将已连接的 Socket 都放到⼀个⽂件描述符集合，然后调⽤ select 将⽂件描述符集合拷⻉到内核⾥，让内核通过遍历⽂件描述符集合的⽅式来检查是否有网络事件。当检查到有事件产⽣后，将此 Socket 标记为可读或可写， 接着再把整个⽂件描述符集合拷⻉回⽤户态⾥，然后⽤户态还需要再通过遍历的⽅法找到可读或可写的 Socket，然后再对其处理。
   - 需要遍历2次⽂件描述符集合，拷贝2次文件描述符集合
   - 使⽤固定⻓度的 BitsMap，表示⽂件描述符集合，限制大小为1024
5. 说一说poll如何实现多路复用
   - 和select类似。但采用链表来表示文件描述符集合，没有了select的个数限制，但还是会受到系统⽂件描述符限制。
   - poll 和 select 并没有太⼤的本质区别， 都是使⽤线性结构存储进程关注的 Socket 集合，因此都需要遍历⽂件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，⽽且也需要在⽤户态与内核态之间拷⻉⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。
6. 说一说epoll如何实现多路复用
   - epoll解决了select和poll的问题
   - epoll不需要拷贝整个文件描述符表
        在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字，把需要监控的 socket 通过epoll_ctl() 函数加⼊内核中的红⿊树⾥，红⿊树增删查⼀般时间复杂度是O(logn) ，就不需要每次都拷贝一整个socket集合，减少了拷贝开销和内存占用
   - epoll不遍历所有的文件描述符，只遍历就绪链表中的文件描述符，时间复杂度为O(1)
        使⽤异步事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件，当某个 socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件链表中，当⽤户调⽤ epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，以及通过传出参数传出哪些文件描述符有事件，不需要轮询扫描整个 socket 集合，⼤⼤提⾼了检测的效率
6. 说一说select， poll， epoll的应用场景
   - 当所有的fd都是活跃连接，使用epoll，需要建立文件系统，红黑书和链表对于此来说，效率反而不高，不如selece和poll
   - 当监测的fd数目较小，且各个fd都比较活跃，建议使用select或者poll
   - 当监测的fd数目非常大，成千上万，且单位时间只有其中的一部分fd处于就绪状态，这个时候使用epoll能够明显提升性能
7. 说一说epoll的边缘触发模式和水平触发模式
   - 边缘触发模式ET
       - 当被监控的 Socket 描述符上有可读事件发⽣时，无论发生了几次事件，服务端都只调用一次epoll_wait(),同时要确保一次性将内核缓冲区的数据读取完
       - 由于IO事件只会通知一次，所以要用循环从文件描述符中读取数据。如果是阻塞IO当没数据可以读写时就会阻塞，导致程序无法正常执行。所以 边缘触发模式⼀般和⾮阻塞 I/O 搭配使⽤，程序会⼀直执⾏ I/O 操作，直到系统调⽤（如 read 和write ）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK 
   - 水平触发模式
        当被监控的 Socket 描述符上每发生一次可读事件，就通知服务端调用一次epoll_wait()读取，直到read读取完内核缓冲区的数据
   - ⼀般来说，边缘触发的效率⽐⽔平触发的效率要⾼，因为边缘触发可以减少 epoll_wait 的系统调⽤次数，系统调⽤也是有⼀定的开销的的，毕竟也存在上下⽂的切换
   - select/poll 只有⽔平触发模式， epoll 默认的触发模式是⽔平触发
8. 说一说⾼性能⽹络模式（设计模式）
   - Reactor 模式
     - 单reactor单线程
     - 单reactor多线程
     - 多reactor多线程（主从reactor多线程）
   - Proactor模式
9.  说一说Reactor模式
   - Reactor是⾮阻塞同步⽹络模式，即I/O 多路复⽤监听事件，收到事件后，根据事件类型分配（Dispatch）给某个线程
   - 基于面向对象的思想，其余有两个关键组成
        reactor：在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对IO事件做出反应
        Handlers：处理程序执行IO事件要完成的实际事件，一般就是回调函数
   - 单reator单进程/线程（C：单进程，Java：单线程）
     - 过程
        - Reactor对象通过Select监控客户端请求事件，收到事件后通过Dispatch进行分发；
        - 如果是建立连接请求事件，则由Acceptor通过Accept处理连接请求，然后创建一个Handler对象处理连接完成后的后续业务处理；如果不是建立连接事件，则Reactor会分发调用连接对应的Handler来响应；
        - Handler会完成Read->业务处理->send的完整业务流程；
     - 优点
        简单，没有多线程通信与资源竞争的问题
     - 缺点
        只有一个线程，无法完全发挥多核CPU的性能。Handler在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈。
     - 应用场景
        不适⽤计算机密集型的场景，只适⽤于业务处理⾮常快速的场景。比如Redis，业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上
   - 单Reactor多线程
     - 过程
       - Reactor对象通过Select监控客户端请求事件，收到事件后通过Dispatch进行分发；
       - 如果是建立连接请求事件，则由Acceptor通过Accept处理连接请求，然后创建一个Handler对象处理连接完成后续的各种事件；如果不是建立连接事件，则Reactor会分发调用连接对应的Handler来响应；
       - Handler只负责响应事件，不做具体业务处理，通过Read读取数据后，会分发给后面的Worker线程池进行业务处理；
       - Worker线程池会分配独立的线程完成真正的业务处理，然后将响应结果发给Handler进行处理；
       - Handler收到响应结果后通过send将响应结果返回给Client；
     - 优点
        可以充分利用多核CPU的处理能力
     - 缺点
        Reactor承担所有事件的监听和响应；在单线程中运行，高并发场景下容易成为性能瓶颈；
   - 多Reactor多线程
     - 过程
       - Reactor主线程MainReactor对象通过Select监控建立连接事件，收到事件后通过Acceptor接收，处理建立连接事件；
       - Acceptor处理建立连接事件后，MainReactor将连接分配Reactor子线程给SubReactor进行处理；SubReactor将连接加入连接队列进行监听，并创建一个Handler用于处理各种连接事件；当有新的事件发生时，SubReactor会调用连接对应的Handler进行响应；
       - Handler通过Read读取数据后，会分发给后面的Worker线程池进行业务处理；
       - Worker线程池会分配独立的线程完成真正的业务处理，然后将响应结果发送给Handler进行处理；
       - Handler收到响应结果后通过Send将响应结果返回给Client;
     - 优点
        线程只需要接收新连接，子线程完成后续的业务处理且无需返回数据
     - 应用场景
        netty（Java网络应用程序框架）
11. 说一说Proactor模式
      - 主线程和内核负责处理读写数据、接受新连接等I/O操作，工作线程仅负责业务逻辑，如处理客户请求。通常由异步I/O实现。
      - 区别在于socket上的读写事件是通过aio_read/aio_write向内核注册的，内核来负责整个IO。并且内核将通过信号来向应用程序报告连接socket上的读写事件。主线程中的epoll_wait调用仅能用来监听socket上的连接请求事件，而不能用来检测连接socket上的读写事件。
    - 缺点
        Linux下异步读写函数时aio系统函数，但这些函数不是真正的操作系统级别⽀持的，⽽是在⽤户空间模拟出来的异步，并且仅仅⽀持基于本地⽂件的 aio 异步操作，⽹络编程中的 socket 是不⽀持的，这也使得基于 Linux 的⾼性能⽹络程序都是使⽤ Reactor ⽅案。
        Windows里由IOCP操作系统级别实现了异步IO，所以Windows里可以使用Proactor⽅案来实现⾼性能⽹络程序
12. 说一说Reactor模式和Proactor模式的区别
    - Reactor 模式是基于同步非阻塞 I/O 的，而Proactor 模式基于异步非阻塞 I/O
    - Reactor 是在事件发生时就通知事先注册的事件，用户进程通过调用read()来读取数据。Proactor 是基于异步 I/O完成读写操作，待I/O操作完成后才回调应用程序来进行业务处理；

#### 8. 设备管理
1. CPU如何读取设备数据？
    每种设备都有⼀个设备控制器，控制器相当于⼀个⼩ CPU。CPU使用设备控制器读取数据，读取完成后通知CPU。一般有三种通知方式
    - 轮询等待：比较傻瓜，会占用CPU所有时间
    - 中断：通过中断来通知CPU，中断需要切换CPU上下文，对于频繁读写数据的磁盘不友好,而且CPU一直都要参与数据的搬运
    - 通过DMA控制器：可以使得设备在CPU 不参与的情况下，能够⾃⾏把设备 I/O 数据放⼊到内存。CPU 当要读取磁盘数据的时候，只需给 DMA 控制器发送指令，然后返回去做其他事情，当磁盘数据拷⻉到内存后， DMA 控制机器通过中断的⽅式，告诉 CPU 数据已经准备好了，可以从内存读数据了。仅仅在传送开始和结束时需要 CPU ⼲预。
2.  IO调度算法
    Linux 通过⼀个统⼀的通⽤块层，来管理不同的块设备。提供统一的标准接口并且能够调度IO，提高读写效率。Linux 内存⽀持 5 种 I/O 调度算法。
    没有调度算法
    先⼊先出调度算法
    完全公平调度算法
    优先级调度：适⽤于运⾏⼤量进程的系统
    最终期限调度算法：分别为读、写请求创建了不同的 I/O 队列，这样可以提⾼机械磁盘的吞吐量，并确保达到最终期限的请求被优先处理，适⽤于在 I/O 压⼒⽐较⼤的场景，⽐如数据库
3. 键盘敲⼊字⺟时，期间发⽣了什么？
   - 当⽤户输⼊了键盘字符， 键盘控制器将数据存储在缓冲中，并通过总线向CPU发生中断请求
   - CPU 收到中断请求后，操作系统会保存被中断进程的 CPU 上下⽂，然后调⽤键盘的中断处理程序。
   - 中断处理程序会调用显示设备的驱动程序会将数据写入显示设备的缓冲区中，再将其显示到屏幕上
   - 恢复被中断进程的上下⽂
#### 9. 综合问题
1. 操作系统你看了哪些书？
    现代操作系统，深入理解计算机系统，还有一些网课，博客之类的
2. 一个程序从开始运行到结束的完整过程，你能说出来多少？
    主要是四个过程：
       - 预编译
        主要处理源代码文件中的以“#”开头的预编译指令，比如将使用的库文件内容替换到文件中，替换所有的宏定义，删除注释等等
       - 编译
        把预编译之后生成的文件，进行一系列词法语法分析及优化后，生成相应的汇编代码文件
       - 汇编
        将汇编代码转变成机器可以执行的指令(机器码文件)。
       - 链接
        将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。包括静态链接和动态链接。
3. 说一说程序的局部性原理
    分为时间局部性和空间局部性。即在⼀段时间内，整个程序的执⾏仅限于程序中的某⼀部分，可能会再次执行。相应地，执⾏所访问的存储空间也局限于某个内存区域，可能会再次被访问。
4. 说一说buffer和cache的区别
    - buffer就是写入到磁盘，为了提高内存和硬盘（或其他I/O设备）之间的数据交换的速度而设计的
    - cache就是从磁盘读取数据然后存起来方便以后使用。cache实现数据的重复使用，避免额外的开销
    - 区别
        A.buffer是要写入数据；cache是已读取数据。
        B.buffer数据丢失会影响数据完整性，源数据不受影响；cache数据丢失不会影响数据完整性，但会影响性能。
        C.一般来说cache越大，性能越好，超过一定程度，导致命中率太低之后才会越大性能越低。buffer来说，空间越大性能影响不大，够用就行。cache过小，或者没有cache，不影响程序逻辑（高并发cache过小或者丢失导致系统忙死除外）。buffer过小有时候会影响程序逻辑，如导致网络丢包。
5. 说一说进程组，作业，会话，shell，终端之间的关系
   - 进程组
        进程组是多个进程组成的集合，每个进程都有自己的进程组ID。作用是为了方便管理一系列进程。又分为前台进程组和后台进程组。
   - 作业
        作业是一个或者多个进程组成的集合，这些进程组是为了完成某一任务的，这项任务就称为作业。shell分前后台控制的是一项作业或一个进程组而不是一个进程。
        如果我们在作业中的某个进程又创建了一个子进程，则子进程不属于作业。但是进程组中子进程创建一个进程，则这个进程属于这个进程组。
   - 会话
        会话是一个或者多个进程组的集合，一旦当我们登陆一次操作系统，就形成了一次会话，一个会话可能包含多个进程组，但是只能有一个前台进程组以及多个后台进程组。
        一个会话可以有一个控制终端，建立与控制终端连接的会话首进程被称为控制进程，一般就是shell进程。
   - shell
        shell是指“提供使用者使用界面”的软件，是用户和操作系统之间的中介，linux下默认是dash，常用的是bash。创建会话时shell进程一般就是会话首进程，即控制进程。
   - 终端
        就是一种输入输出的设备。
6. 为什么只能运行一个前台作业？
    当我们在前台新起了一个作业，shell就被提到了后台，因此shell就没有办法再继续接受我们的指令并且解析运行了。 但是如果前台进程退出了，shell就会有被提到前台来，就可以继续接受我们的命令并且解析运行。
7. 终端退出，终端运行的进程会怎样
        终端在退出时会发送SIGHUP挂起信号给对应的shell（bash）进程，shell（bash）进程收到这个信号后首先将它发给会话下面的进程，如果程序没有对SIGHUP信号做特殊处理，那么进程就会随着终端关闭而退出
8. 如何让进程后台运行
   - 命令后面加上&，实际上，这样是将命令放入到一个作业队列中了
   - ctrl + z 挂起进程，使用jobs查看序号，在使用bg %序号后台运行进程
   - nohup + &，将标准输出和标准错误缺省会被重定向到 nohup.out 文件中，忽略所有挂断（SIGHUP）信号
   - 运行指令前面 + setsid，使其父进程编程init进程，不受HUP信号的影响
9.  一个由C/C++编译的程序占用的内存分为哪几个部分？
    - 栈区
    - 堆区
    - 全局区：包括初始化的和非初始化的
    - 代码区
10. 什么是缓冲区溢出？有什么危害？
    - 缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。
    - 危害有以下两点：
      - 程序崩溃
      - 缓冲溢出攻击，跳转并且执行一段恶意代码
            因为缓冲区溢出的可能在堆段，栈段，数据段，可能会使得用户程序执行这段恶意的溢出的代码
11. ASCII、Unicode和UTF-8编码的区别？
    - ASCII 
        只有127个字符，表示英文字母的大小写、数字和一些符号
    - Unicode
        将各国语言统一到一套编码格式中，通常两个字节表示一个字符，而ASCII是一个字节表示一个字符
    - UTF-8
        Unicode常两个字节表示一个字符浪费空间，UTF-8把Unicode编码转化为“可变长编码”，文字母被编码成一个字节，常用汉字被编码成三个字节
12. 说一说计算机系统通用的字符编码工作方式
    - 在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码
    - 用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件
    - 浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器
13. 原子操作的是如何实现的?
    - 首先处理器会自动保证基本的内存操作的原子性.同一字节的内存地址不能被多CPU同时访问
    - 处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作
        - 总线加锁
            比如多个处理器同时对共享变量进行读改写操作，两个CPU同时i++，可能会导致结果只加了1次。此时就要通告总线锁来使得一个处理器在总线上输出此LOCK信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存
        - 缓存加锁
            总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。
            缓存锁定是利用CPU的缓存一致性原则，当某个CPU对缓存数据进行更改时，会通知缓存了该数据的该数据的CPU抛弃缓存的数据或者从内存重新读取。
14. 说一说网络模型
    - 多进程模型
    - 多线程模型
    - IO多路复用
15. 说一说⾼性能⽹络模式（设计模式）
    - Reactor 模式
     - 单reactor单线程
     - 单reactor多线程
     - 多reactor多线程（主从reactor多线程）
    - Proactor模式
17. 服务器高并发的解决方案你知道多少？
    - 应用数据与静态资源分离
        将静态资源（图片，视频，js，css等）单独保存到专门的静态资源服务器中，在客户端访问的时候从静态资源服务器中返回静态资源，从主服务器中返回应用数据。
    - 客户端缓存
         因为效率最高，消耗资源最小的就是纯静态的html页面，所以可以把网站上的页面尽可能用静态的来实现，在页面过期或者有数据更新之后再将页面重新缓存。或者先生成静态页面，然后用ajax异步请求获取动态数据。
    - 集群和分布式 
        集群是所有的服务器都有相同的功能，请求哪台都可以，主要起分流作用
        分布式是将不同的业务放到不同的服务器中，处理一个请求可能需要使用到多台服务器，起到加快请求处理的速度
    - 反向代理 
        在访问服务器的时候，服务器通过别的服务器获取资源或结果返回给客户端
18. 用户态和内核态是如何切换的?
    当用户进程调用了系统调用就会产生用户态和内核态的切换
    - 首先用户程序会调用 `glibc` 标准库，来准备系统调用
    - 然后glibc 库调用`软件中断指令(SWI)`切换为超级用户模式
    - 只会执行内核代码跳转系统调用函数
    - 执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行
19. 用户态切换到内核态方式
    - 系统调用
    - 异常（内中断）
    - 中断（外中断）
20. 为什么用线程池?
    池化技术在开发中比较常见,比如线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗,提高对资源的利用率。线程池就是池化思想的一个很好利用,它的好处我认为有三点:
    - 降低资源消耗。通过重复利用已创建的线程降低线程动态创建和销毁造成的消耗。
    - 提高响应速度。当任务到达时,任务可以不需要等到线程创建就能立即执行, 减少了创建线程这段时间的开销。
    - 提高线程的可管理性。线程是稀缺资源,如果无限制的创建,不仅会消耗系统资源,还会降低系统的稳定性,使用线程池可以
21. 说一说线程安全, 怎么保证线程安全
    线程安全可以简单理解为一个方法或者一个实例可以在多线程环境中使用而不会出现问题
    在拥有共享数据的多条线程并行执行的程序中，线程安全的代码会通过同步机制保证各个线程都可以正常且正确的执行，不会出现数据污染等意外情况。
    一般来说,对于某个资源如果只有读操作,则这个资源无需同步就是线程安全的,若有多个线程进行读写操作,则需要线程同步来保证线程安全。
22. 讲讲fork的整个过程实现
    - 分配新的内存块和内核数据结构给子进程
    - 将父进程部分数据结构内容(数据空间, 堆栈等)拷贝至子进程，但这里是读时共享，写时拷贝
    - 添加子进程到系统进程列表当中
    - fork返回, 开始调度器调度
