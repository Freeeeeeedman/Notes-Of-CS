### 如何看项目源码
1. 看github上的项目，首先要学会用，要把这个项目用起来，跑起来，然后再去看代码
2. 看开源项目可以分这么几步：
   1. 运行，跑起来，用起来，知道这个项目有什么功能，满足什么需求
   2. 找到项目入口 main函数
   3. 拆解项目模块，都有哪些功能，哪些模块
   4. 一个模块一个模块去看代码，而不是 囫囵吞枣
   5. 修改部分代码，重新跑项目，看看有哪些变动
   6. 完成这个项目代码的阅读
3. 开发原则：先调用，再具体设计使用

### 项目细节
1. 补充man手册
   sudo apt-get install manpages-posix-dev
2. 在别的服务器上测试才有完整的性能
3. IP地址
   124.221.163.97
   10.0.16.15


### 面试思路
1. 关于项目，主要想清楚这几个问题：
   你的项目的技术难点是什么？
   你是如何克服这个技术难点的？
   你做这个项目的收获是什么？
   为什么使用这个技术/组件？
2. 关键词包装
   高并发，半同步半反应堆，同步IO模拟Proactor模式，支持ET，线程池，主从状态机，数据库连接池，同步异步日志，小根堆定时器
3. 使用一门技术，想好对应的说辞：
   为啥你要用
   在你项目中咋体现的
   不用可不可以
   第四点（设计模式）
4. 关于设计模式
   针对某某场景，编写了一个XXX模块，难点在于XXX
   扩展说说这种设计的优缺点。项目为什么用到这种设计？不用会怎么样？（体现你对工业常用设计方式的理解）

### 项目问题

#### 综合问题
1. 对后端开发的看法？
   前端主要是负责与用户直接打交道，更多的是做一些交互，用户的请求一般是提交到后端进行处理，后端主要负责逻辑处理。C++后端要求熟悉C++语言，网络编程，高并发处理等等知识，同时也要会linux操作系统的基本知识和一门脚本语言。我在学校和导师做科研项目的时候就在linux服务器上开发，同时也发现了自己对于计算机技术方面的兴趣。
2. 为什么要做这样的项目？
   在学校的科研项目偏向于科研算法，涉及后台开发的知识不多，同时觉得需要通过一个项目来实践计算机学习过程中的知识，比如网络编程的方法，TCP/IP协议，HTTP协议，多线程以及linux各种命令与工具的使用。而选择了webserver的项目。
3. 介绍下你的项目
   Linux下C++的轻量级Web服务器。并发模式采用半同步半反应堆，IO模型采用同步IO模拟Proactor模式,支持epoll的LT水平触发和LT边缘触发。
   采用线程池管理工作线程。
   使用主从状态机解析HTTP请求报文，支持解析GET和POST请求，支持长/短连接。
   访问服务器数据库实现web端用户注册、登录功能，可以请求服务器图片和视频文件。
   可以使用同步或者异步的日志来记录服务器运行状态。
   使用基于小根堆的定时器关闭超时请求，解决超时，连接系统资源占用问题。
   经Webbench压力测试可以实现上万的并发连接数据交换
4. 这个项目你是自己写的吗？
   这个项目我是看书学习的，在书本的基础上把reactor模式改为了用同步IO模拟proactor模式，并且将升序链表实现的定时器改为了小根堆实现的定时器。这样做的好处是升序链表的添加时间复杂度为O(n)删除复杂度是O(1)而小根堆的添加和删除复杂度是log(n)。最后使用单例模式实现日志模块（和数据库连接池）。
5. 项目基本框架
   主要由I/O单元，逻辑单元和网络存储单元组成，其中每个单元之间通过请求队列进行通信。其中I/O单元用于处理客户端连接，读写网络数据；逻辑单元用于处理业务逻辑的线程；网络存储单元指本地数据库和文件等。
6. 项目大概流程
   并发模式采用半同步半反应堆，IO模型采用同步IO模拟Proactor模式。所以主线程充当异步线程，使用epoll监听所有socket上的事件。同时对连接进行读写也由主线程完成。     
     1. 主线程往epoll内核事件表中注册socket上的读就绪事件,调用epoll_wait等待socket上有数据可读。
     2. 当socket上有数据可读时，epoll_wait通知主线程读取数据。然后将读取到的数据封装成一个请求对象并插入请求队列。
     3. 线程池中的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。
     4. 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。
7. 说一下前端发送请求后，服务器处理的过程，中间涉及哪些协议？
   HTTP协议、TCP、IP协议等，计算机网络的知识。
8. 怎样应对服务器的大流量、高并发
   - 客户端：
      尽量减少请求数量：依靠客户端自身的缓存或处理能力
      尽量减少对服务端资源的不必要耗费：重复使用某些资源，如连接池
   - 服务端：
      增加资源供给：更大的网络带宽，使用更高配置的服务器
      请求分流：使用集群,分布式的系统架构
      应用优化：使用更高效的编程语言,优化处理业务逻辑的算法
9.  如何进行大文件传输？
   socket本身缓冲区有限，在传输大数据时客户端就需要进行分包，在目的地重新组包。一般使用一些通信用的中间件来完成，比如ActiveMQ，ZeroMQ等。（不过TCP本身不就分包了？）
11. 使用linux系统有什么好处？
   - linux跨平台，内核采用C语言编写，支持多种硬件平台
   - linux开源，开发者可以自由查看和修改源码
   - 有丰富的软件支持，几乎可以找到任何想要的编程开发工具，比如一些性能分析工具
   - 支持多用户多任务
   - linux稳定性好
12. 服务器突然崩溃退出，怎么处理？
   在Linux系统下使用CoreDump调试，如果程序有段错误会在当前目录下生成core文件（ulimit -c unlimited），然后使用gdb调试core文件（gdb a.out core），找到Segmentation fault这些信息。
11. 服务器突然运行很慢怎么处理？
   先查看后台服务器的运行状态，包括磁盘，CPU，内存的使用情况等（top，free）。如果是磁盘满了，做好备份，清理下磁盘；如果是CPU的问题，查找下占用率较高的进程，kill掉与系统应用无关的进程。还有一种情况可能是close_wait或者time_wait状态过多了，消耗了服务器的资源，使用netstat命令查看下网络连接的状态。


#### 项目遇到的问题（测试时有没有产生什么问题？）
1. 测试高并发的时候发现有一些连接丢失
   原因：socketfd使用ET触发模式，但是没有用while来循环accept()导致有些连接丢失（通过netstat查看全连接队列发现没有被取出）
2. LT模式下一直触发写事件
   原因：忘记了在发送完数据后移除写事件
3. ET模式下传输的数据有时候会丢失
   原因：ET模式下写事件只会触发一次，如果一次写不完就还要再注册一次


#### 项目改进
1. 采用相对高效的半同步/半异步模式来替代半同步半异步反应堆
      主线程只管理监听socket，工作线程监听连接socket。主线程将新连接的socket派发给工作线程，所有的IO操作都由工作线程完成，节省了线程切换的开销，同时每个工作线程都能同时处理多个客户连接。
2. 动态创建线程池线程数目，定义活跃度，即活跃的线程/总线程，如果活跃度一直接近于1就动态增加线程，如果活跃度一直较低就可以动态减小线程


#### 性能参数
1. 最大文件描述符为 65536个，最大事件数为10000， 最小超时单位为5s，超时时间为 3 * 5s = 15s
1. 线程池中线程数量为8， 请求队列中最多允许的、等待处理的请求的数量为10000


#### 线程池问题
1. 如何实现线程池？
   线程池本质上就是生产者和消费者模型加上一个请求队列（采用链表实现）。首先线程池设计为一个类，通过RALL机制在构造函数中就批量动态创建线程资源，同时设置线程分离，离开作用域时自动销毁。在析构函数中释放动态申请的资源。线程池中的线程相当于消费者，而请求队列相当于生产者。同时通过锁来对临界区即请求队列进行加锁。当有新请求产生时，通过信号量来唤醒工作线程进行处理。也就是说工作线程通过竞争申请互斥锁来获得任务的接管权。
2.  怎么决定线程池的线程数量？
    - 最直接的限制因素是CPU处理器的个数
      - 对于CPU密集的任务，线程池的线程数量应和CPU内核数目一直
      - 对于IO密集的任务，线程池的线程数量一般要多于CPU的核数，因为IO操作不占用 CPU，线程间竞争的不是CPU资源而是IO，IO的处理一般比较慢，多于核数的线程将为CPU争取更多的任务，不至于在线程处理IO的时候造成CPU空闲导致资源浪费
      - 混合型的任务，可以拆分为 IO 密集型和 CPU 密集型分别处理
    - 任务执行时间也影响线程数量
      如果任务执行时间长，在工作线程数量有限的情况下，工作线程很快就很被任务占完，导致后续任务不能及时被处理，此时应适当增加工作线程数量；反过来，如果任务执行时间短，那么工作线程数量不用太多，太多的工作线程会导致过多的时间浪费在线程上下文切换上。
3. 线程的同步机制有哪些？
   信号量、条件变量、互斥量等
4. 线程池中的工作线程是一直等待吗？
   是的，通过信号量sem_wait来阻塞，等待新任务的唤醒；
6. 你的线程池工作线程处理完一个任务后的状态是什么
    如果请求队列为空，则该线程进入线程池中等待；若不为空，则该线程跟其他线程一起进行任务的竞争；
7. 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？(线程池中只有几个线程能响应1万+的用户吗？)
   由于采用了基于非阻塞IO多路复用，通过时分复用的方式就可以解决这样的问题。当客户连接有事件需要处理的时，epoll会进行事件提醒，而后讲对应的任务加入请求队列，等待工作线程竞争执行。如果速度还是慢，那就只能够增大线程池容量，或者考虑集群分布式的做法
8. 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?
   会，因为线程的数量是固定的，如果一个客户请求长时间占用着线程资源，势必会影响到服务器对外的整体响应速度。解决的策略可以是给每一个线程处理任务设定一个时间阈值，当某一个客户请求时间过长，则将其置于任务请求最后，或断开连接
9. 怎样正确关闭线程池
   本项目中在析构函数中设置了一个控制线程池结束的bool值，当delete线程池对象时会直接关闭线程池，无论是否在处理请求。如果要安全地关闭线程池，应当在执行完正在执行的任务和队列中等待的任务后才彻底关闭，并直接拒绝后续地新的提交
10. 为什么要用多线程
   多线程可以发挥多核CPU的优势（并行执行），达到充分利用CPU的目的。因为多线程如果在单cpu中其实也是顺序执行的，只不过是系统帮我们切换执行顺序而已，其实并没有快。
11. 多线程编程的特点
    - 当前线程随时有可能被切换出去，或者说被抢占了，当我们使用公共资源的时候尤其要注意线程安全性，一般可以锁来保证线程安全。
    - 多线程程序中事件的发生没有一个固定的顺序
12. 线程池的简略实现
    ```
    template <typename T>
    class threadpool {
      
      public:
         threadpool(int thread_number);
         ~threadpool();
         bool append(T *request);
      
      private:
         static void *worker(void *arg); //创建线程时的执行函数，需要设置为静态函数
         void run();//worker()内实际运行的线程池的执行函数

         int m_thread_number;//线程池内线程数目
         pthread_t *m_threads;
         bool m_stop; //是否结束线程
         std::list<T *> m_workqueue;//请求队列
         locker m_queuelocker;//保护请求队列的互斥锁
         sem m_queuestat;//信号量，同步线程，是否有任务处理
    };

      template <typename T>
      threadpool<T>::threadpool(int thread_number):m_thead_number(thread_number), m_stop(false) {
         m_threads = new pthread_t[m_thread_number];
         for(int i = 0; i < thread_number; i++) {
           if(pthread_create(m_threads + i, NULL, worker, this) != 0) {
               delete[] m_threads;
               throw std::exception();
           } //简略写，只有这里判断返回值
            pthread_detach(m_threads[i]);//设置线程脱离
         }
      }

      template <typename T> 
      threadpool<T>::~threadpool() {
         delete[] m_threads;
         m_stop = true;
      }

      template <typename T>
      bool threadpool<T>::append(T *request) {
         m_queuelocker.locker();
         m_workqueue.push_back(request);
         m_queuelocker.unlock();
         m_queuestat.post();
         return true;
      }

      template <typename T>
      void *threadpool<T>::worker(void *arg) {
         threadpool *pool = (threadpool *)arg;
         pool->run();
         return pool;
      }

      template <typename T>
      void threadpool<T>::run() {
         while(!m_stop) {
            m_queuestat.wait();
            m_queuelocker.lock();
            T *request = m_workqueue.front();
            m_workerqueue.pop_front();
            m_queuelocker.unlock();
            request->process(); //处理HTTP请求的入口函数，request实际上是http连接类的指针，其指向客户端连接对象所有的信息，用于解析请求
         }
      }
    ```


#### 并发模型问题
1. 简单说一下服务器使用的并发模型？
      并发模式采用半同步半反应堆，IO模型采用同步IO模拟Proactor模式。所以主线程充当异步线程，使用epoll监听所有socket上的事件。同时对连接进行读写也由主线程完成。     
     1. 主线程往epoll内核事件表中注册socket上的读就绪事件,调用epoll_wait等待socket上有数据可读。
     2. 当socket上有数据可读时，epoll_wait通知主线程读取数据。然后将读取到的数据封装成一个请求对象并插入请求队列。
     3. 线程池中的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。
     4. 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。
2. reactor、proactor、主从reactor模型的区别？
   - Reactor模式：
      Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件。主线程(I/O处理单元)通过epoll监听文件描述符上是否有事件发生，有的话立即通知工作线程(逻辑单元)。而读写数据、接受新连接及处理客户请求均在工作线程中完成。这个过程是非阻塞同步的，需要工作线程主动调用 read 将 socket 接收缓存中的数据读到应用进程内存、
   - Proactor模式
      Proactor 是异步网络模式， 感知的是已完成的读写事件，将所有 IO 操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑，如处理客户请求。这个过程是异步的，读写工作全程由操作系统完成，操作系统完成读写工作后，就会通知工作系统直接处理数据
      无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 Reactor 模式是基于「待完成」的 I/O 事件，而 Proactor 模式则是基于「已完成」的 I/O 事件。
   - 同步I/O模拟proactor模式
      proactor模式中，工作线程仅负责业务逻辑不处理IO。那么使用同步I/O模拟proactor，就需要在主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一“完成事件”即可。
3. 你用了epoll，说一下为什么用epoll，还有其他复用方式吗？区别是什么？
   复用方式，比较常用的有三种：select/poll/epoll
   为什么使用epoll也就是区别在于
   - 首先底层数据结构不同
      select使用线性表描述文件描述符集合，文件描述符有上限；poll使用链表来描述，文件描述符没有上限，epoll底层通过红黑树来描述
   - 其次epoll不需要拷贝整个文件描述符表
      epoll在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字，把需要监控的 socket 加⼊内核中的红⿊树⾥，红⿊树增删查⼀般时间复杂度是O(logn) ，就不需要每次都拷贝一整个socket集合，减少了拷贝开销和内存占用。而select和poll都需要从⽤户态与内核态之间拷⻉整个⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。
   - 最后epoll不遍历所有的文件描述符
      由于底层数据结构的不同，select和poll都需要遍历文件描述符集合，时间复杂度为O(n), 而epoll使⽤异步事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件，当某个 socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件链表中。epoll所以遍历的时间复杂度为O(1)
   - 当监测的fd数量较小，且各个fd都很活跃的情况下，建议使用select和poll；当监听的fd数量较多，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。
4. 为什么epoll需要将socket设为非阻塞？
   主要是看对应socket是LT模式还是ET模式。对于LT模式阻塞和非阻塞都可以实现，因为一旦缓冲区未读尽epoll_wait会一直返回，不会遗漏数据。但对于ET模式，由于epoll_wait只会返回一次，所以我们要用循环一次性将缓冲区中数据读完，如果设置阻塞，就会阻塞在最后一次循环，导致任务进行不下去。
5. 客户端断开连接，服务端epoll监听到的事件是什么
   对端连接断开触发的 epoll 事件会包含 EPOLLIN | EPOLLRDHUP
6. epoll的线程安全
   epoll是通过锁来保证线程安全的, epoll中粒度最小的自旋锁ep->lock(spinlock)用来保护就绪的队列, 互斥锁ep->mtx用来保护epoll的重要数据结构红黑树


#### HTTP报文解析相关问题
1. 为什么要用状态机？
   有限状态机是逻辑单元内部一种编程方法，通过if-else,switch-case和函数指针来实现，这样服务器就可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂
2. 如何解析HTTP请求？
   主要使用主从状态机来解析请求。主线程监听到可读事件后，读取数据传递给工作线程。工作线程使用主状态机判断是在分析请求行、分析请求头或是请求体。而每次在主状态机判断之前通过从中状态机判断是读取了完整的一行，是没有读到完整的一行，还是读取行错误。判断依据是根据请求报文的结构，即行结束和空行的\r\n。
3. 画一下状态机的转移图
   ![状态机](https://pic4.zhimg.com/v2-053512c11e9e80de7c1bd1e68153f93b_r.jpg)
4. https协议为什么安全？
5. https的ssl连接过程？
6. HTTP报文的格式
7. 一次HTTP请求响应的流程
   - 域名解析
   - 发起TCP的3次握手
   - 建立TCP连接后发起http请求
   - 服务器响应http请求，浏览器得到html代码
   - 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）
   - 浏览器对页面进行渲染呈现给用户
8.  GET、POST区别
   - GET重点在从服务器上获取资源,post重点在向服务器发送数据
   - GET数据通过URL传递，而POST是放在请求体中，所以GET不能传递大量数据
   - GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息
   - GET产生一个TCP数据包，POST产生两个TCP数据包。POST会先发送请求头部，服务器会响应100continue，再发送请求体，服务器响应200.在网络好的情况下效率差别不大，但在网络比较差的情况下，两次包在验证数据包完整性上，有非常大的优点
11. HTTP请求如何判断get提交还是post提交？
   本项目中对于密码和用户名的传输是采用post提交的，因为get提交会直接暴露早url中。客户端要判断是get还是post就直接看url就可以了，服务器端判断是通过解析状态行，查看请求方法来判断的。
10. http报文怎么检测头部和包体的间隔
      通过\r\n
11. 怎么检测包体的结束
   在头部有一个content-length,然后你收内容为这个长度即可
11. HTTP请求怎么拆包
   HTTP请求内容：请求行，请求头，请求体。通过\r\n检测头部和包体的间隔。而在头部有一个content-length来检测包体的结束
12. HTTP怎么接收图片和视频流
   使用Content-Type字段，说明响应体中的媒体数据类型
13. 如何支持长连接？
   就是设置一个bool值判断，如果请求报文中keep-alive选项，就将其定时器延后。否则就关闭连接，移除其定时器


#### SQL连接相关问题
1. 客户端如何登录？
   首先是服务端会载入数据库表，将数据库中的数据载入到服务器中。然后对报文进行解析，提取用户名和密码，并对用户名和密码进行登录校验。最后是通过设置编号来对不同的资源进行访问。
2. 你这个保存状态了吗？如果要保存，你会怎么做？
   可以利用session或者cookie的方式进行状态的保存。
   cookie其实就是服务器给客户分配了一串“身份标识”，比如“123456789happy”这么一串字符串。每次客户发送数据时，都在HTTP报文附带上这个字符串，服务器就知道你是谁了；
   session是保存在服务器端的状态，每当一个客户发送HTTP报文过来的时候，服务器会在自己记录的用户数据中去找，类似于核对名单；
3. 如何实现SQL连接池？
   采用单例模式和链表来创建数据库连接池。和线程池类似，本质上也是生产者和消费者模型。首先将连接池设计为一个单例类。通过RALL机制在构造函数中批量创建连接并存放在链表中。同时在析构函数中销毁连接。这里线程相当于消费者，链表中的连接相当于生产者。同时通过锁来对链表来对链表进行加锁。当线程申请SQL连接时，信号量减1，如果连接池内没有连接则阻塞等待。
4. 登录中的用户名和密码你是load到本地，然后使用map匹配的，如果有10亿数据，即使load到本地后hash，也是很耗时的，你要怎么优化？
   对于大数据最遍历的方法就是进行hash，利用hash建立多级索引的方式来加快用户验证。比如将10亿的用户信息，利用大致缩小1000倍的hash算法进行hash，这时就获得了100万的hash数据，每一个hash数据代表着一个用户信息块（一级）；而后再分别对这100万的hash数据再进行hash，例如最终剩下1000个hash数据（二级）。在这种方式下，服务器只需要保存1000个二级hash数据，当用户请求登录的时候，先对用户信息进行一次hash，找到对应信息块（二级），在读取其对应的一级信息块，最终找到对应的用户数据。


#### 定时器相关问题
1. 为什么要用定时器？
   处理定时任务，或者非活跃连接，节省系统资源；
2. 说一下定时器的工作原理？
   - 首先是通过升序链表实现的定时器
   服务器为各事件分配一个定时器。该项目使用SIGALRM信号来实现定时器，首先每一个定时事件都处于一个升序链表上，通过alarm()函数周期性触发SIGALRM信号，而后信号回调函数利用管道通知主循环的epoll，主循环接收到信号之后对升序链表上的定时器进行处理（循环结束后处理，并不立即处理）：若一定时间内无数据交换则关闭连接（通过绝对事件+设定的超时事件与当前时间相比较）。这样的添加复杂度为O(n),删除为O(1)
   - 之后我又使用了了优先队列即最小堆来进行优化，插入和删除的时间复杂度都是O(logN)
   最小堆以每个定时器的过期时间进行排序，绝对时间+设定的超时时间最小的定时器位于堆顶，当SIGALRM信号触发回调函数时执行过期定时器清除，如果堆顶的定时器时间过期，则删除，并重新建堆，再判定是否过期，如此循环直到未过期为止
3. 堆的实现
   
   ```
   vector<int> heap;
   
   //获得最小值
   void top() {
      return heap[0];
   }

   //插入值，把新的数字放在最后一位，然后上浮
   void push(int k) {
      heap.push_back(k);
      swim(heap.size() - 1);
   }

   //删除值，删除根节点的最小值即数组第一个值，为了不破坏最小堆结构，
   //由于缺少了第一个元素，需要把最后一个数字挪到开头，然后下沉
   void pop() {
      heap[0] = heap.back();
      heap.pop_back();
      sink(0);
   }

   //上浮
   //如果父节点大于当前插入点，则交换，即上浮
   //如果父节点小于等于插入点，或者pos=0，即已经上浮到根节点最小值，停止循环
   void swim(int pos) {
      while(pos > 0 && heap[(pos - 1 / 2)] > heap[pos]) {
         swap(heap[(pos - 1) / 2], heap[pos]);
         pos = (pos - 1) / 2;
      }
   }

   //下沉
   //如果当前点大于子节点中较小的那一个，则交换，即下沉
   //如果当前点小于等于子节点中较小的那一个，或者当前点已经到达最底部，停止循环
   void link(int pos) {
      while(2 * pos + 1 < heap.size()) {
         int i = 2 * pos + 1;
         //如果存在右节点，且右节点小于左节点
         if(i + 1 < heap.size() && heap[i] > heap[i + 1]) ++i;
         if(heap[pos] <= heap[i]) break;
         swap(heap[pos], heap[i]);
         pos = i;
      }
   }
   ```


#### 日志相关问题
1. 如何实现日志系统？
   初始化服务器时，利用单例模式初始化日志系统，根据配置文件确认是同步还是异步写入的方式。如果是同步写入，则每次需要写日志的时候，就直接调用日志类中的公有函数对日志文件进行加锁写入。而如果是异步写入的方式，就需要创建一个线程以及阻塞队列。每次需要写日志的时候，将日志信息加入阻塞队列。再由新的线程通过生产者与消费者的模式写入日志文件。
2. 为什么要异步？和同步的区别是什么？
   同步方式写入日志时会产生比较多的系统调用比如fput()，若是某条日志信息过大，会阻塞日志系统和主线程，造成系统瓶颈。而异步方式采用生产者-消费者模型，具有较高的并发能力。
3. 这个阻塞队列如何实现？
   采用循环数组的方式。定义front和rear遍历，front指向队列的第一个元素，rear指向队列的最后一个元素，rear == front即队列为空，而(rear + 1) % maxSize == front则代表队列已满。
4. 现在你要监控一台服务器的状态，输出监控日志，请问如何将该日志分发到不同的机器上？
   可以使用消息队列进行消息的分发，例如mqtt、rabitmq等等
5. 说一说你的系统日志的分级
   分为debug测试用，info显示一般信息，warn显示警告，error显示错误信息
6. 针对高并发情况下，写线程数量不足，如何处理？
   采用线程池的方式写入。
7. 阻塞队列的实现
   ```
   template <typename T>
   class block_queue {
      public:
         block_queue(int max_size = 1000) {
            m_max_size = max_size;
            int m_size = 0;
            m_array = new T[max_size];
            m_front = -1;
            m_back = -1;            
         }

         ~block_queue() {
            m_mutex.lock();
            if(m_array != NULL)
               delete [] m_array;
            m_mutex.unlock();
         }

         bool empty() {
            m_mutex.lock();
            if(m_size == 0) {
               m_mutex.unlock();
               return true;
            }
            m_mutex.unlock();
            return false;
         }

         bool full() {
            m_mutex.lock();
            if(m_size >= m_max_size) {
               m_mutex.unlock();
               return true;
            }
            m_mutex.unlock();
            return false;
         }
         

         //往队列尾即back处添加元素，由于是循环数组实现的阻塞队列，需要取余
         bool push(const T &item) {
            m_mutex.lock();
            if(m_size >= m_max_size) { //如果队列已满，则通知线程进行处理，并返回false
               m_cond.broadcast();
               m_mutex.unlock();
               return false;
            }
            m_back = (m_back + 1) % m_max_size;
            m_array[m_back] = item;
            m_size++;
            m_cond.broadcast();
            m_mutex.unlock();
            return true;
         }

         //从队列头即front取出元素，注意是+1而不是-1，队列先进先出
         bool pop(T &item) {
            m_mutex.lock();
            while(m_size <= 0) {
               if(!m_cond.wait(&m_mutex)) { //队列中没有元素时，阻塞等待
                  m_mutex.unlock();
                  return false;
               }
            }
            m_front = (m_front + 1) % m_max_size();
            item = m_array[m_front]; //提取元素
            m_size--;
            m_mutex.unlock();
            return true;
         }
         //可以增加超时处理，思路是pop()时m_cond.wait()改为m_cond.timewait(),到期自动解除阻塞并返回false
      private:
         int m_max_size;
         int m_size;
         T *m_array;
         int m_front;
         int m_back;
         locker m_mutex;
         cond m_cond;

   };


#### 压测相关问题
1. 服务器并发量测试过吗？怎么测试的？
   测试过，利用webbench，至少满足万余的并发量
2. webbench是什么？介绍一下原理
   是一款轻量级的网址压力测试工具，可以实现高达3万的并发测试。
   其原理：Webbench实现的核心原理是：父进程fork若干个子进程，每个子进程在用户要求时间或默认的时间内对目标web循环发出实际访问请求，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在时间到后结束，父进程在所有子进程退出后统计并给用户显示最后的测试结果，然后退出。
3. 测试的时候有没有遇到问题？
   见上文
4. 压测的瓶颈会在哪里
   - io读取速度
   - CPU占用
   - 内存大小
5. 如何验证压测瓶颈
   - 一个是查看内核参数，通过watch命令结合/proc/cpuinfo查看
   - 还要就是利用一下性能分析命令，比如对于网络性能分析可以用netstat,ss,sar,对于IO性能的话通过iostat以及iotop查看吞吐量，对于CPU和内存的话htop,ps,vmstat等等
6. 如何进行多线程调试
   这里利用vscode编辑器+GDB进行调试，对程序中需要监测的位置打断点，利用-exec执行对应的 GDB 调试指令。在此基础上，让程序全速运行到指定的断点处，此时在调试控制台中采用info threads 可以显示当前可调试的所有线程，其中带*号的是正在调试的线程。此时如果需要在当前线程中单步运行的话，可以使用set scheduler-locking on命令进行上锁，执行单步调试。在最后使用set scheduler-locking off 解除锁定，返回原先的线程。


#### 单例模式相关问题
1. 说一说单例模式
      一个类只能创建一个对象，让类自身负责保存它的唯一实例，并提供一个访问它的全局访问接口，确保所有对象都访问唯一实例。
      又分为饿汉单例模式即程序启动时就实例化了该对象，懒汉单例模式即使用的时候再实例化
2. 单例模式的优缺点？项目为什么要用到这种设计，不用会怎么样？
      单例模式的优点是提供了对唯一实例的受控访问，同时由于只存在一个对象实例，可以节约系统资源。
      缺点是单例模式不是抽象的，扩展性差。并且单例类的职责过重，一定程度上违背了单一职责原则。同时单例模式需要注意使用锁来同步，以及要放在内存泄露
      日志模块使用单例模式，是因为对于所有的连接来说，都应该是共享同一个日志对象的，否则在高并发的情况下会占用较多内存，并且由于日志是输出到同一文件内，还需要进行线程内同步。而且在异步日志的情况下，日志对象会创建一个线程来进行异步输出日志。如果不是单例模式，则会导致创建多个线程，这在高并发的情况下很显然是无法接受的。
2. 如何实现单例模式
   - 构造函数私有化
      目的是禁止其他程序创建该类的对象
   - 指向本身实例的类属性为静态
      因为只有静态成员变量才能在没有创建对象时进行初始化，之后也不会再被初始化
   - 通过一个static静态成员方法返回唯一的对象实例
      因为指向本身实例的类属性为静态所以需要静态方法，同时也是公有的方法给外部提供访问
3. 单例模式实现
   - 饿汉式
      ```
      class Singleton {
         public:
            static Singleton* GetInstance() {
               return &instance; //取地址符返回指针
            }
         private:
            static Singleton instance;
            Singleton() {};
            ~Singleton() {};
            Singleton(const Singleton&) =delete; // 防止拷贝，禁止编译器默认生成的函数
            Singleton& operator=(const Singleton&) =delete; //防止赋值
      };
      Singleton Singleton::instance;
      ```
      没有线程安全问题，但由于函数外的static对象初始化顺序未定义，即GetInstance函数和instance初始化顺序不确定，如果在初始化完成之前调用 getInstance() 方法会返回一个未定义的实例。
   - 懒汉模式
      ```
      class Singleton {
         public:
            static Singleton* GetInstance() {
               static Singleton instance;//函数内的静态局部变量，第一次访问才初始化，程序结束，自动释放。
               return &instance;
            }
         private:
            Singleton() {};
            ~Singleton() {};
            Singleton(const Singleton&) =delete; // 防止拷贝，禁止编译器默认生成的函数
            Singleton& operator=(const Singleton&) =delete; //防止赋值           
      }
      双重检测模式和私有嵌套类Delete实现不方便，在c++11标准下，对于多线程单例模式的实现，可以使用函数内的local static 即静态局部变量的初始化，编译器会自动加锁和解锁，并且只有当第一次通过getinstance()方法访问时才对static静态局部变量初始化创建实例。
      

#### 其他细节问题
1. 端口复用
   - 防止服务器重启时之前绑定的端口还未释放，因为在服务端结束后，也就是第三次挥手的时候会有个time_wait,此时仍占用端口
   - 程序突然退出而系统没有释放端口
   ```
   int reuse = 1;
   setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &reuse, sizeof(reuse));
   ```
2. socket缓冲区
   就是在内核中的发送缓冲区和接受缓冲区，执行 send 之后，数据只是拷贝到了socket 缓冲区。至于什么时候会发数据，发多少数据，取决于滑动窗口和拥塞控制。
3. 静态成员变量
   通过pthread_create创建多个工作线程时，传入的函数必须是静态函数，因为非静态函数隐含this参数，不符合pthread_create要求。同时由于静态函数只能访问静态成员，为了访问非静态成员，就需要将this指针作为参数传递进去。
4. 大端序小端序
   0x12345678，从左往右数据字节序由高向低
   网络端是大端字节序，高位字节存低地址，地位字节存高地址
   主机端是小端字节序，低位字节存低地址，高位字节存高地址
   大端字节序方便人类阅读，小端字节序方便计算机内部处理，因为这样计算机读取数据时先独到的就是低位字节再是高位字节。
5. 屏蔽掉SIGPIPE信号
   在整个epoll监听循环开始之前，需要先屏蔽掉SIGPIPE信号。默认读写一个关闭的socket会触发sigpipe信号。该信号的默认操作是关闭进程，这明显是我们不想要的。
6. 返回引用与返回值
   - 函数返回值时会产生一个临时变量作为函数返回值的副本
         只能作为右值，而不能作为左值被赋值
   - 返回引用时不会产生值的副本
         可以作为左值
   - 注意
     - 不能返回局部对象的引用和指针，因为局部对象释放后引用就会指向不确定的内存，而指针就会变成野指针
     - C++ 不支持在函数外返回局部变量的地址，除非定义局部变量为 static变量
7. http连接类
   注意这里我们把每个客户端的http连接封装为一个类，包含客户端的信息如socketfd，读写缓冲区的地址，主从状态机等等。作为request任务添加到任务队列通知给子线程处理。
   



### 基础知识
#### Proactor模式
1. IO模型
    - 阻塞IO：
        当⽤户程序执⾏ read ，线程会被阻塞，⼀直等到内核数据准备好，并把数据从内核缓冲区拷⻉到应⽤程序的缓冲区中，当拷⻉过程完成， read 才  会返回
        阻塞等待的是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程
    - 非阻塞IO:
        ⾮阻塞的 read 请求在数据未准备好的情况下⽴即返回，可以继续往下执⾏，此时应⽤程序不断轮询内核，直到数据准备好，内核将数据拷⻉到应⽤程序缓冲区， read 调⽤ 才可以获取到结果
        非阻塞等待的是「数据从内核态拷⻉到⽤户态」这个过程
    - 基于非阻塞IO多路复用
        当内核数据准备好时，再以事件通知应⽤程序进⾏操作.通过内核而不是程序来循环遍历文件描述符。监控多个文件描述符的同时减少了系统调用的次数。
        但还需要等待内核将数据从内核空间拷⻉到应⽤程序空间
    - 信号驱动IO
         通过信号处理函数，不阻塞，当进程收到SIGIO信号处理IO事件，但还需要等待内核将数据从内核空间拷⻉到应⽤程序空间
    - 同步IO
        包括阻塞 I/O、⾮阻塞 I/O，信号驱动IO，基于⾮阻塞 I/O 的多路复⽤。因为它们在 read调⽤时，内核将数据从内核空间拷⻉到应⽤程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷⻉效率不⾼， read调⽤就会在这个同步过程中等待⽐较⻓的时间。
    - 异步IO
        在IO模型中异步IO和同步区分的是内核向应用程序通知的是就绪事件还是完成事件，以及是应用程序和内核谁来完成读写。
        异步I/O 是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程都不⽤等待
        发起 aio_read 之后，就⽴即返回，内核准备数据，并且⾃动将数据从内核空间拷⻉到应⽤程序空间，这个拷⻉过程同样是异步的，内核⾃动完成的，和前⾯的同步操作不⼀样，应⽤程序并不需要主动发起拷⻉动作。
2. reactor模式
   reactor模式中，主线程(I/O处理单元)只负责监听文件描述符上是否有事件发生，有的话立即通知工作线程(逻辑单元)，读写数据、接受新连接及处理客户请求均在工作线程中完成。通常由同步I/O实现。
   - 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件，程调用 epoll_wait 等待 socket 上有数据可读。
   - 当 socket 上有数据可读时，epoll_wait 通知主线程。主线程则将socket可读事件放入请求队列。
   - 睡眠在请求队列上的工作线程被唤醒，它从 socket 读取数据，并处理客户请求，然后往 epoll 内核事件表中注册该 socket 上的写就绪事件。
   - 当 socket 可写时，epoll_wait 通知主线程。主线程将 socket 可写事件放入请求队列。
   - 睡眠在请求队列上的某个工作线程被唤醒，它往 socket 上写入服务器处理客户请求的结果。
3. proactor模式
   - Proactor 模式将所有 IO 操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑，如处理客户请求。一般由异步I/O实现。
   - 连接 socket 上的读写事件是通过 aio_read/aio_write 向内核注册的，因此内核将通过信号向应用程序报告连接 socket 上的读写事件。所以主线程的 epoll_wait 仅能检测监听 socket 上的连接请求事件，不能用来检测连接 socket 上的读写事件
4. 同步I/O模拟proactor模式
   - proactor模式中，工作线程仅负责业务逻辑不处理IO。那么使用同步I/O模拟proactor，就需要在主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一“完成事件”即可。
     1. 主线程往epoll内核事件表中注册socket上的读就绪事件,调用epoll_wait等待socket上有数据可读。
     2. 当socket上有数据可读时，epoll_wait通知主线程读取数据。然后将读取到的数据封装成一个请求对象并插入请求队列。
     3. 线程池中的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。
     4. 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。
   - 注意在真正的proactor模式中，主线程仅监听新连接，而模拟的proactor模式中都监听


#### 半同步/半异步反应堆
1. 并发模式
   - 并发模式是指I/O处理单元（处理客户端连接，读写网络数据）和多个逻辑单元（业务进程或者线程）之间协调完成任务的方法。
   - 服务器主要有两种并发编程模式：半同步/半异步模式和领导者/追随者模式。
   - 同步指的是程序完成按照代码序列的顺序执行；按照同步方式运行的线程称为同步线程。同步线程虽然效率低，实时性差，但逻辑简单。
   - 异步指的是程序的执行需要操纵系统事件来驱动。常见的系统事件包括中断、信号等。按照异步方式运行的线程称为异步线程。异步线程的执行效率高，实时性强，但是编写异步方式执行的程序相对复杂，难于调试和扩展，而且不适合大量的并发。
   - 因此想服务器这种既要求较好的实时性，有要求同时处理过个客户端请求的应用程序，我们就应该同时使用同步线程和异步线程来实现，即采用半同步/半异步模式来实现
2. 半同步/半异步反应堆
   - 主线程充当异步线程，监听所有事件，有事件发生则将事件插入请求队列中。工作线程休眠在请求队列中，当任务到来时，通过竞争获取任务处理权。可以看作Reactor模式，也可以模拟为Proactor模式。即主线程完成数据的读写，将数据封装成任务对象插入请求队列，工作线程从请求队列取出任务对象处理。
   - 缺点
     - 主线程和工作线程共享请求队列，对请求队列的操作需求加锁，耗费CPU时间
     - 每一个工作线程在同一时间只能处理一个客户请求。客户数量多，工作线程少，请求队列任务堆积，响应满，如果添加试图通过增加线程则，由于线程切换导致的CPU时间消耗。。
3. 半同步/半异步模式
   主线程只管理监听socket，工作线程监听连接socket。主线程将新连接的socket派发给工作线程，所有的IO操作都由工作线程完成，节省了线程切换的开销，同时每个工作线程都能同时处理多个客户连接。


#### ET/LT/ONESHOT
1. epoll
   - int epoll_create(int size)
     创建一个指示epoll内核事件表的文件描述符，该描述符将用作其他epoll系统调用的第一个参数，size不起作用。
   - int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)
     该函数用于操作内核事件表监控的文件描述符上的事件：注册、修改、删除
   - int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout)
     该函数用于等待所监控文件描述符上有事件的产生，返回就绪的文件描述符个，传出参数events用来存内核得到事件的集合
2. LT水平触发模式
   - 被监控的文件描述符有可读事件，只要内核缓冲区内还有数据，比如读缓冲区太小不能一次读完，就会一直触发，epoll_wait()会一直通知程序进行操作，确保读完
   - 对于可写事件，LT模式下只要内核缓冲区可写就一直会触发，所以要在数据发送完成后移除检测可写事件(*本项目里会重新注册，顺便也重新注册了EPOLLONESHOT*)
   - 和阻塞或者非阻塞文件描述符相使用，epoll_wait()通知有读事件后，通过recv()数据返回
3. ET边缘触发模式
   - 被监控的文件描述符有可读事件，如果读缓冲区过小不能一次读完，都只会触发一次，即epoll_wait()只会通知一次程序来进行操作，直到下一次新的数据到达。所以要通过while来循环读取数据。
   - 对于可写事件，ET模式下如果内核缓冲区可写则只会通知一次，所以如果send()发送数据不能一次发送完成时，则必须再次注册可写事件(*本项目里使用writev如果一次写不完，会返回errno为EAGAIN，需要再注册一次可写事件*)
   - 和非阻塞文件描述符相使用，避免最后一次循环阻塞，当缓冲区为空后会导致EAGAIN错误，即读取完毕，此时就可以返回
4. 对于监听socket文件描述符和读写的socket文件描述符
   - 对于监听的socket文件描述符最好使用ET模式。如果使用LT模式，会导致高并发情况下，全连接队列有多个就绪连接，而epoll_wait()只通知accept一次，有些连接会连接不上。一定要使用的话必须使用while来循环accept，由于监听socket是非阻塞的，就绪连接处理完后，返回-1直接break退出循环。
   - 对于读写的socket文件描述符，LT,ET模式都可以，LT支持阻塞与非阻塞，而ET必须用阻塞
5. ET模式相较于LT模式的优势
   ⼀般来说，边缘触发的效率⽐⽔平触发的效率要⾼，因为边缘触发可以减少 epoll_wait 的系统调⽤次数，比如如果一次没有读完内核缓冲区数据，LT模式下就会再调用一次epoll_wait，再触发一次。而系统调⽤也是有⼀定的开销的的
6. EPOLLONESHOT
   EPOLLONESHOT主要是为了应对多线程的情况，比如对应某一个连接事件到来，工作线程进行处理，如果这时又有新的事件到达，如果又触发了其他线程来进行处理，则会导致混乱。而注册了EPOLLONESHOT后，就相当于触发事件后将对应socket从epoll的检测列表中清除，所以之后还需要重新注册。    


#### 线程池
   - 动态创建、销毁及切换线程都有开销，会导致客户响应慢
   - 池是一组资源的集合,这组资源在服务器启动之初就被完全创建好并初始化,这称为静态资源.当服务器进入正式运行阶段,开始处理客户请求的时候,如果它需要相关的资源,可以直接从池中获取,无需动态分配.当服务器处理完一个客户连接后,可以把相关的资源放回池中,无需执行系统调用释放资源


#### SQL连接池
   - 如果需要频繁访问数据库，不创建连接池就只能反复的创建数据库连接和断开连接，而这是很耗时的，而且容易造成据库安全隐患
   - 连接池中的资源为一组数据库连接，由程序动态地对池中的连接进行使用，释放。当系统开始处理客户请求的时候，如果它需要相关的资源，可以直接从池中获取，无需动态分配；当服务器处理完一个客户连接后,可以把相关的资源放回池中，无需执行系统调用释放资源。


#### 定时器
1. 队列
   先进先出
2. 优先队列
   - 最大优先队列：无论入队顺序如何，都是当前最大的元素优先出队
   - 最小优先队列：无论入队顺序如何，都是当前最小的元素优先出队
3. 堆
   - 又叫二叉堆，结构为完全二叉树（指序号连续）
   - 最大堆，父亲节点的值大于孩子节点的值
   - 最小堆，父亲节点的值小于孩子节点的值
   - 实现操作
     - 用一个数组而不是指针建立一个树。堆是完全二叉树，所以位置i节点父节点位置一定为 [(i-1)/2]，而它的两个子节点的位置又一定分别为 2i+1 和 2i+2
     - 上浮：如果一个节点比父节点小，那么需要交换这个两个节点；交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作
     - 下沉：如果一个节点比父节点小，那么需要交换这个两个节点；交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作


#### 锁模块
1. RALL
   - RAII即“资源获取即初始化”.
   - 在构造函数中申请分配资源，在析构函数中释放资源。因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定
   - RAII的核心思想是将资源或者状态与对象的生命周期绑定，通过C++的语言机制，实现资源和状态的安全管理,智能指针是RAII最好的例子
2. 锁机制的功能
   实现多线程同步，通过锁机制，确保任一时刻只能有一个线程能进入关键代码段.
3. 信号量sem_t
   等待(P)和信号(V)
   - P，如果SV的值大于0，则将其减一；若SV的值为0，则挂起执行
   - V，如果有其他进行因为等待SV而挂起，则唤醒；若没有，则将SV值加一 
   - sem_init函数用于初始化一个未命名的信号量
   - sem_destory函数用于销毁信号量
   - sem_wait函数将以原子操作方式将信号量减一,信号量为0时,sem_wait阻塞
   - sem_post函数以原子操作方式将信号量加一,信号量大于0时,唤醒调用sem_post的线程
   - 成功返回0，失败返回errno
4. 互斥量pthread_mutex_t
   - pthread_mutex_init函数用于初始化互斥锁
   - pthread_mutex_destory函数用于销毁互斥锁
   - pthread_mutex_lock函数以原子操作方式给互斥锁加锁
   - pthread_mutex_unlock函数以原子操作方式给互斥锁解锁
   - 成功返回0，失败返回errno
5. 条件变量pthread_cond_t
   条件变量提供了一种线程间的通知机制,当某个共享数据达到某个值时,唤醒等待这个共享数据的线程.
   - pthread_cond_init函数用于初始化条件变量
   - pthread_cond_destory函数销毁条件变量
   - pthread_cond_signal
   - pthread_cond_broadcast函数以广播的方式唤醒所有等待目标条件变量的线程
   - pthread_cond_timedwait线程等待一定的时间，如果超时或有信号触发，线程唤醒
   - pthread_cond_wait函数用于等待目标条件变量.该函数调用时需要传入 mutex参数(加锁的互斥锁) ,函数执行时,先把调用线程放入条件变量的请求队列,然后将互斥锁mutex解锁,当函数成功返回为0时,互斥锁会再次被锁上. 也就是说函数内部会有一次解锁和加锁操作
   - 比如在消费者与生产者模型中，没有资源时消费者通过pthread_cond_wait阻塞，同时这个函数又对互斥锁解锁，这样生产者开始生成资源，生产完成后通过pthread_cond_signal通知消费者，pthread_cond_wait不再阻塞，同时再对互斥锁加锁。实现了同步机制。


#### 项目设计
1. 头文件(.h)作用
   提供全局变量、全局函数的声明或公用数据类型的定义、自定义宏和类型，从而实现分离编译和代码复用。
   - 加强类型检查，提高类型安全性
      比如如果在不同源文件定义同一个类，但内部成员数据类型不同，可能会导致逻辑错误
   - 减少公用代码的重复书写，提高编程效率
      使用头文件，只需要修改头文件中的内容，就可以保证修改在所有源文件中生效，从而避免了繁琐易错的重复修改
   - 提供保密和代码重用的手段
      源代码不便（或不准）向用户公布，只要向用户提供头文件和二进制库即可。用户只需要按照头文件的接口声明来调用库函数，而不必关心接口的具体实现，编译器会从库中连接相应的实现代码。
2. 库文件(.cpp, .lib, .dll)作用
   头文件定义函数，库文件实现函数，通过将其编译为动态链接库或者静态连接库的方式实现代码保密。
3. <iostream.h> 与 <iostream>
   - #include <iostream.h>
      C++旧的头文件，位于全局命名空间
   - #include <iostream>
      using namespace std;
      位于std命名空间
   - C头文件
      <stdio.h>, <cstdio>继续使用
   - C++头文件
      <iostream.h>舍弃，使用<iostream>
   - <> 与 ""
      <>代表系统头文件，""代表自定义头文件
      不能使用""包含系统头文件，原因是编译器遇到双引号包裹的头文件默认为用户自定义头文件，从项目目录下查找，查找不到才会到系统目录中查找，如果存在与系统头文件同名的用户自定义头文件，则会出现不符合预期的错误。
4. 避免头文件被重复包含导致重复定义
   #ifndef HEADER_NAME
   #define HEADER_NAME
   ...
   #endif
5. 模板不支持分离编译
   因为模板只有在实例化才能生成相应的代码，链接时在.o文件的符号表中寻找不到对应模板函数的地址，会链接出错
   - 解决方法：
     - 可以在声明后，显示实例化
         只对一种类型有效
     - 不要采用分离编译（将其声明和实现放在一起）
6. 阻塞队列
   循环数组实现阻塞队列，而使用阻塞队列，就可以实现一个生产者-消费者模型。
   阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因此此时还没有数据可取，知道队列中有数据才能返回，如果队列已经满了，那么插入数据的操作就会阻塞，直到队列中有空闲位置后再插入数据，然后再返回。

