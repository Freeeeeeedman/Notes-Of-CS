### 如何看项目源码
1. 看github上的项目，首先要学会用，要把这个项目用起来，跑起来，然后再去看代码
2. 看开源项目可以分这么几步：
   1. 运行，跑起来，用起来，知道这个项目有什么功能，满足什么需求
   2. 找到项目入口 main函数
   3. 拆解项目模块，都有哪些功能，哪些模块
   4. 一个模块一个模块去看代码，而不是 囫囵吞枣
   5. 修改部分代码，重新跑项目，看看有哪些变动
   6. 完成这个项目代码的阅读
3. 开发原则：先调用，再具体设计使用


#### 项目细节
1. 补充man手册
   sudo apt-get install manpages-posix-dev
2. 在别的服务器上测试才有完整的性能
3. 记录要会手写一些模块，如线程池，单例模式等等
4. IP地址
   124.221.163.97
   10.0.16.15


#### 项目改进
游双的书上都有！
1. 相对高效的半同步/半异步模式
2. 零拷贝
3. 线程池线程数目动态创建
4. 定时器双向链表换成小顶堆
5. 懒汉模式改为智能指针方式，自动释放内存


#### 项目遇到的问题
1. 测试高并发的时候发现有一些连接丢失
   原因：socketfd使用ET触发模式，但是没有用while来循环accept()导致有些连接丢失
2. LT模式下一直触发写事件
   原因：忘记了在发送完数据后移除写事件
3. ET模式下传输的数据有时候会丢失
   原因：ET模式下写事件只会触发一次，如果一次写不完就还要再注册一次


#### 综合问题


#### 锁模块
1. RALL
   - RAII全称是“Resource Acquisition is Initialization”，直译过来是“资源获取即初始化”.
   - 在构造函数中申请分配资源，在析构函数中释放资源。因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定
   - RAII的核心思想是将资源或者状态与对象的生命周期绑定，通过C++的语言机制，实现资源和状态的安全管理,智能指针是RAII最好的例子
2. 锁机制的功能
   实现多线程同步，通过锁机制，确保任一时刻只能有一个线程能进入关键代码段.
3. 信号量sem_t
   等待(P)和信号(V)
   - P，如果SV的值大于0，则将其减一；若SV的值为0，则挂起执行
   - V，如果有其他进行因为等待SV而挂起，则唤醒；若没有，则将SV值加一 
   - sem_init函数用于初始化一个未命名的信号量
   - sem_destory函数用于销毁信号量
   - sem_wait函数将以原子操作方式将信号量减一,信号量为0时,sem_wait阻塞
   - sem_post函数以原子操作方式将信号量加一,信号量大于0时,唤醒调用sem_post的线程
   - 成功返回0，失败返回errno
4. 互斥量pthread_mutex_t
   - pthread_mutex_init函数用于初始化互斥锁
   - pthread_mutex_destory函数用于销毁互斥锁
   - pthread_mutex_lock函数以原子操作方式给互斥锁加锁
   - pthread_mutex_unlock函数以原子操作方式给互斥锁解锁
   - 成功返回0，失败返回errno
5. 条件变量pthread_cond_t
   条件变量提供了一种线程间的通知机制,当某个共享数据达到某个值时,唤醒等待这个共享数据的线程.
   - pthread_cond_init函数用于初始化条件变量
   - pthread_cond_destory函数销毁条件变量
   - pthread_cond_signal
   - pthread_cond_broadcast函数以广播的方式唤醒所有等待目标条件变量的线程
   - pthread_cond_timedwait线程等待一定的时间，如果超时或有信号触发，线程唤醒
   - pthread_cond_wait函数用于等待目标条件变量.该函数调用时需要传入 mutex参数(加锁的互斥锁) ,函数执行时,先把调用线程放入条件变量的请求队列,然后将互斥锁mutex解锁,当函数成功返回为0时,互斥锁会再次被锁上. 也就是说函数内部会有一次解锁和加锁操作
   - 比如在消费者与生产者模型中，没有资源时消费者通过pthread_cond_wait阻塞，同时这个函数又对互斥锁解锁，这样生产者开始生成资源，生产完成后通过pthread_cond_signal通知消费者，pthread_cond_wait不再阻塞，同时再对互斥锁加锁。实现了同步机制。


#### 并发模式
1. 服务器编程基本框架
   主要由I/O单元，逻辑单元和网络存储单元组成，其中每个单元之间通过请求队列进行通信，从而协同完成任务。
   其中I/O单元用于处理客户端连接，读写网络数据；逻辑单元用于处理业务逻辑的线程；网络存储单元指本地数据库和文件等。
2. IO模型
    - 阻塞IO：
        当⽤户程序执⾏ read ，线程会被阻塞，⼀直等到内核数据准备好，并把数据从内核缓冲区拷⻉到应⽤程序的缓冲区中，当拷⻉过程完成， read 才  会返回
        阻塞等待的是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程
    - 非阻塞IO:
        ⾮阻塞的 read 请求在数据未准备好的情况下⽴即返回，可以继续往下执⾏，此时应⽤程序不断轮询内核，直到数据准备好，内核将数据拷⻉到应⽤程序缓冲区， read 调⽤ 才可以获取到结果
        非阻塞等待的是「数据从内核态拷⻉到⽤户态」这个过程
    - 基于非阻塞IO多路复用
        当内核数据准备好时，再以事件通知应⽤程序进⾏操作.通过内核而不是程序来循环遍历文件描述符。监控多个文件描述符的同时减少了系统调用的次数。
        但还需要等待内核将数据从内核空间拷⻉到应⽤程序空间
    - 信号驱动IO
         通过信号处理函数，不阻塞，当进程收到SIGIO信号处理IO事件，但还需要等待内核将数据从内核空间拷⻉到应⽤程序空间
    - 同步IO
        包括阻塞 I/O、⾮阻塞 I/O，信号驱动IO，基于⾮阻塞 I/O 的多路复⽤。因为它们在 read调⽤时，内核将数据从内核空间拷⻉到应⽤程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷⻉效率不⾼， read调⽤就会在这个同步过程中等待⽐较⻓的时间。
    - 异步IO
        在IO模型中异步IO和同步区分的是内核向应用程序通知的是就绪事件还是完成事件，以及是应用程序和内核谁来完成读写。
        异步I/O 是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程都不⽤等待
        发起 aio_read 之后，就⽴即返回，内核准备数据，并且⾃动将数据从内核空间拷⻉到应⽤程序空间，这个拷⻉过程同样是异步的，内核⾃动完成的，和前⾯的同步操作不⼀样，应⽤程序并不需要主动发起拷⻉动作。
3. 同步I/O模拟proactor模式
   - 在同步和异步模拟中，epoll就相当于事件分离器，工作线程相当于事件处理器
   - reactor模式
      reactor模式中，主线程(I/O处理单元)只负责监听文件描述符上是否有事件发生，有的话立即通知工作线程(逻辑单元 )，读写数据、接受新连接及处理客户请求均在工作线程中完成。通常由同步I/O实现。
     1. 主线程往epoll内核时间表中注册socket上的读就绪事件。
     2. 主线程调用epoll_wait等待socket上有数据可读。
     3. 当socket上有数据可读时，epoll_wait通知主线程。主线程则将socket可读事件放入请求队列。
     4. 睡眠在请求队列上的某个工作线程被唤醒，它从socket读取数据，并处理客户请求，然后往epoll内核事件表中注册该socket上写就绪事件。
     5. 主线程调用epoll_wait等待socket可写。
     6. 当socket可写时，epoll_wait通知主线程。主线程将socket可写事件放入请求队列。
     7. 睡眠在请求队列上的某个工作线程被唤醒，它往socket上写入服务器处理客户请求的结果
   - proactor模式
      - 主线程和内核负责处理读写数据、接受新连接等I/O操作，工作线程仅负责业务逻辑，如处理客户请求。通常由异步I/O实现。
      - 区别在于socket上的读写事件是通过aio_read/aio_write向内核注册的，内核来负责整个IO。并且内核将通过信号来向应用程序报告连接socket上的读写事件。主线程中的epoll_wait调用仅能用来监听socket上的连接请求事件，而不能用来检测连接socket上的读写事件。
   - 同步I/O模拟proactor模式
      proactor模式中，工作线程仅负责业务逻辑不处理IO。那么使用同步I/O模拟proactor，就需要在主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一“完成事件”即可。
     1. 主线程往epoll内核事件表中注册socket上的读就绪事件。
     2. 主线程调用epoll_wait等待socket上有数据可读。
     3. 当socket上有数据可读时，epoll_wait通知主线程。主线程从socket循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列。
     4. 睡眠在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。
     5. 主线程调用epoll_wait等待socket可写。
     6. 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。
4. 并发模式
   - 并发模式是指I/O处理单元（处理客户端连接，读写网络数据）和多个逻辑单元（业务进程或者线程）之间协调完成任务的方法。
   - 服务器主要有两种并发编程模式：半同步/半异步模式和领导者/追随者模式。
5. 半同步/半异步模式
   - 同步指的是程序完成按照代码序列的顺序执行；按照同步方式运行的线程称为同步线程。同步线程虽然效率低，实时性差，但逻辑简单。
   - 异步指的是程序的执行需要操纵系统事件来驱动。常见的系统事件包括中断、信号等。按照异步方式运行的线程称为异步线程。，异步线程的执行效率高，实时性强，但是编写异步方式执行的程序相对复杂，难于调试和扩展，而且不适合大量的并发。
   - 因此想服务器这种既要求较好的实时性，有要求同时处理过个客户端请求的应用程序，我们就应该同时使用同步线程和异步线程来实现，即采用半同步/半异步模式来实现
   - 半同步/半异步模式中，同步线程用于处理客户端逻辑。异步线程用于处理I/O事件。异步线程监听到客户端请求后，就将其封装成了一个请求对象并插入到请求队列中。请求队列将通知某个工作在同步模式的工作线程来读取并处理该请求对象。
6. 半同步/半异步反应堆
   - 描述
      异步线程只有一个，由主线程来充当。他负责监听所有socket上的事件。如果监听socket上有可读事件发生，既有新的连接请求到来，主线程就接受之以得到的新的连接socket，然后往epoll内核事件表上注册该socket上的读写事件。如果连接socket上有读写事件发生，既有新的客户请求到来或者由数据要发送至客户端，主线程就将该连接socket插入请求队列中。
      半反应指的是工作线程需要自己从已就绪的socket上读取请求和写入应答
   - 分配方式
      所有的工作线程都睡眠在该请求队列中，当有任务到来时，他们通过竞争（比如申请互斥锁）获得任务的接管权。这种竞争机制使得只有空闲的工作线程才有机会来处理新任务。
   - 缺点
     - 主线程和工作线程共享请求队列。主线程往请求队列中添加任务，或者工作线程从请求队列中取出任务，都需要对请求队列加锁保护，从而耗费了CPU
     - 每个工作线程在同一时间只能处理一个客户请求。如果客户端数量较多，而工作线程较少，则请求队列中将堆积很多任务对象，客户端的响应速度将越来越慢。如果通过增加工作线程来解决这一问题，则工作线程的切换也将耗费大量的CPU时间。
7. *半同步/半异步模式*
   - 相对高效的半同步/半异步模式，它的每个工作线程都能同时处理多个客户连接
   - 区别在于主线程对监听socket调用epoll_wait，而将连接socket通过管道派送给工作线程监听，在各自的事件循环中分布监听不同的事件。
8. 进程池
   - 动态创建、销毁及切换线程都有开销，会导致客户响应慢
   - 池是一组资源的集合,这组资源在服务器启动之初就被完全创建好并初始化,这称为静态资源.当服务器进入正式运行阶段,开始处理客户请求的时候,如果它需要相关的资源,可以直接从池中获取,无需动态分配.当服务器处理完一个客户连接后,可以把相关的资源放回池中,无需执行系统调用释放资源
   - 实际设计
      设计进程池类，初始化类对象时就批量创建线程资源，同时设置线程分离，离开作用域时自动销毁。同时通过锁来对临界区即请求队列进行加锁。当有新请求产生时，通过信号量来唤醒工作线程进行处理。工作线程通过竞争申请互斥锁来获得任务的接管权。


#### ET/LT/ONESHOT
1. epoll
   - int epoll_create(int size)
     创建一个指示epoll内核事件表的文件描述符，该描述符将用作其他epoll系统调用的第一个参数，size不起作用。
   - int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)
     该函数用于操作内核事件表监控的文件描述符上的事件：注册、修改、删除
   - int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout)
     该函数用于等待所监控文件描述符上有事件的产生，返回就绪的文件描述符个，传出参数events用来存内核得到事件的集合
2. LT水平触发模式
   - 被监控的文件描述符有可读事件，只要内核缓冲区内还有数据，比如读缓冲区太小不能一次读完，就会一直触发，epoll_wait()会一直通知程序进行操作，确保读完
   - 对于可写事件，LT模式下只要内核缓冲区可写就一直会触发，所以要在数据发送完成后移除检测可写事件(*本项目里会重新注册，顺便也重新注册了EPOLLONESHOT*)
   - 和阻塞或者非阻塞文件描述符相使用，epoll_wait()通知有读事件后，通过recv()数据返回
3. ET边缘触发模式
   - 被监控的文件描述符有可读事件，如果读缓冲区过小不能一次读完，都只会触发一次，即epoll_wait()只会通知一次程序来进行操作，直到下一次新的数据到达。所以要通过while来循环读取数据。
   - 对于可写事件，ET模式下如果内核缓冲区可写则只会通知一次，所以如果send()发送数据不能一次发送完成时，则必须再次注册可写事件(*本项目里使用writev如果一次写不完，会返回errno为EAGAIN，需要再注册一次可写事件*)
   - 和非阻塞文件描述符相使用，避免最后一次循环阻塞，当缓冲区为空后会导致EAGAIN错误，即读取完毕，此时就可以返回
4. 对于监听socket文件描述符和读写的socket文件描述符
   - 对于监听的socket文件描述符最好使用ET模式。如果使用LT模式，会导致高并发情况下，全连接队列有多个就绪连接，而epoll_wait()只通知accept一次，有些连接会连接不上。一定要使用的话必须使用while来循环accept，由于监听socket是非阻塞的，就绪连接处理完后，返回-1直接break退出循环。
   - 对于读写的socket文件描述符，LT,ET模式都可以，LT支持阻塞与非阻塞，而ET必须用阻塞
5. ET模式相较于LT模式的优势
   ⼀般来说，边缘触发的效率⽐⽔平触发的效率要⾼，因为边缘触发可以减少 epoll_wait 的系统调⽤次数，比如如果一次没有读完内核缓冲区数据，LT模式下就会再调用一次epoll_wait，再触发一次。而系统调⽤也是有⼀定的开销的的
6. EPOLLONESHOT
   EPOLLONESHOT主要是为了应对多线程的情况，比如对应某一个连接事件到来，工作线程进行处理，如果这时又有新的事件到达，如果又触发了其他线程来进行处理，则会导致混乱。而注册了EPOLLONESHOT后，就相当于触发事件后将对应socket从epoll的检测列表中清除，所以之后还需要重新注册。    


#### 有限状态机
   有限状态机是逻辑单元内部一种编程方法，通过if-else,switch-case和函数指针来实现，这样服务器就可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂


#### 程序设计
1. roll思想
2. 分离式编译


#### 其他细节问题
1. 端口复用
   - 防止服务器重启时之前绑定的端口还未释放，因为在服务端结束后，也就是第三次挥手的时候会有个time_wait,此时仍占用端口
   - 程序突然退出而系统没有释放端口
   ```
   int reuse = 1;
   setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &reuse, sizeof(reuse));
   ```
2. socket缓冲区
   就是在内核中的发送缓冲区和接受缓冲区，执行 send 之后，数据只是拷贝到了socket 缓冲区。至于什么时候会发数据，发多少数据，取决于滑动窗口和拥塞控制。
3. 静态成员变量
   通过pthread_create创建多个工作线程时，传入的函数必须是静态函数，因为非静态函数隐含this参数，不符合pthread_create要求。同时由于静态函数只能访问静态成员，为了访问非静态成员，就需要将this指针作为参数传递进去。