### 如何看项目源码
1. 看github上的项目，首先要学会用，要把这个项目用起来，跑起来，然后再去看代码
2. 看开源项目可以分这么几步：
   1. 运行，跑起来，用起来，知道这个项目有什么功能，满足什么需求
   2. 找到项目入口 main函数
   3. 拆解项目模块，都有哪些功能，哪些模块
   4. 一个模块一个模块去看代码，而不是 囫囵吞枣
   5. 修改部分代码，重新跑项目，看看有哪些变动
   6. 完成这个项目代码的阅读
3. 开发原则：先调用，再具体设计使用

### 项目细节
1. 补充man手册
   sudo apt-get install manpages-posix-dev
2. 在别的服务器上测试才有完整的性能
3. 记录要会手写一些模块，如线程池，单例模式等等
4. IP地址
   124.221.163.97
   10.0.16.15



### 项目问题

#### 综合问题
1. 为什么要做这样的项目？
   在学校的科研项目偏向于科研算法，涉及后台开发的知识不多，同时觉得需要通过一个项目来实践计算机学习过程中的知识。而选择了webserver的项目。
2. 介绍下你的项目
   Linux下C++的轻量级Web服务器。采用线程池+非阻塞socket+ET和LT模式的epoll模拟的Proactor并发模型。
   使用主从状态机解析HTTP请求报文，支持解析GET和POST请求。
   访问服务器数据库实现web端用户注册、登录功能，可以请求服务器图片和视频文件。
   同时使用同步或者异步的日志来记录服务器运行状态。
   经Webbench压力测试可以实现上万的并发连接数据交换
3. 项目基本框架
   主要由I/O单元，逻辑单元和网络存储单元组成，其中每个单元之间通过请求队列进行通信。其中I/O单元用于处理客户端连接，读写网络数据；逻辑单元用于处理业务逻辑的线程；网络存储单元指本地数据库和文件等。
4. 项目大概流程
   并发模式采用半同步半反应堆，IO模型采用同步IO模拟Proactor模式。所以主线程充当异步线程，使用epoll监听所有socket上的事件。同时对连接进行读写也由主线程完成。     
     1. 主线程往epoll内核事件表中注册socket上的读就绪事件,调用epoll_wait等待socket上有数据可读。
     2. 当socket上有数据可读时，epoll_wait通知主线程读取数据。然后将读取到的数据封装成一个请求对象并插入请求队列。
     3. 线程池中的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。
     4. 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。
5. 说一下前端发送请求后，服务器处理的过程，中间涉及哪些协议？
   HTTP协议、TCP、IP协议等，计算机网络的知识。
6. 怎样应对服务器的大流量、高并发
   - 客户端：
      尽量减少请求数量：依靠客户端自身的缓存或处理能力
      尽量减少对服务端资源的不必要耗费：重复使用某些资源，如连接池
   - 服务端：
      增加资源供给：更大的网络带宽，使用更高配置的服务器
      请求分流：使用集群,分布式的系统架构
      应用优化：使用更高效的编程语言,优化处理业务逻辑的算法
7. 如何进行大文件传输？
   socket本身缓冲区有限，在传输大数据时客户端就需要进行分包，在目的地重新组包。一般使用一些通信用的中间件来完成，比如ActiveMQ，ZeroMQ等。（不过TCP本身不就分包了？）

#### 项目遇到的问题（测试时有没有产生什么问题？）
1. 测试高并发的时候发现有一些连接丢失
   原因：socketfd使用ET触发模式，但是没有用while来循环accept()导致有些连接丢失（通过netstat查看全连接队列发现没有被取出）
2. LT模式下一直触发写事件
   原因：忘记了在发送完数据后移除写事件
3. ET模式下传输的数据有时候会丢失
   原因：ET模式下写事件只会触发一次，如果一次写不完就还要再注册一次


#### 项目改进
1. 采用相对高效的半同步/半异步模式来替代半同步半异步反应堆
      主线程只管理监听socket，工作线程监听连接socket。主线程将新连接的socket派发给工作线程，所有的IO操作都由工作线程完成，节省了线程切换的开销，同时每个工作线程都能同时处理多个客户连接。
2. 动态创建线程池线程数目，定义活跃度，即活跃的线程/总线程，如果活跃度一直接近于1就动态增加线程，如果活跃度一直较低就可以动态减小线程
3. 定时器双向链表换成小顶堆
4. 懒汉模式改为智能指针方式，自动释放内存


#### 性能参数
1. 线程池中线程数量为8， 请求队列中最多允许的、等待处理的请求的数量为10000
2. 


#### 线程池问题
1. 如何实现线程池？
   线程池本质上就是生产者和消费者模型加上一个请求队列（采用链表实现）。首先线程池设计为一个类，通过RALL机制在构造函数中就批量动态创建线程资源，同时设置线程分离，离开作用域时自动销毁。在析构函数中释放动态申请的资源。线程池中的线程相当于消费者，而请求队列相当于生产者。同时通过锁来对临界区即请求队列进行加锁。当有新请求产生时，通过信号量来唤醒工作线程进行处理。也就是说工作线程通过竞争申请互斥锁来获得任务的接管权。
2. 手写线程池
3. 线程的同步机制有哪些？
   信号量、条件变量、互斥量等
4. 线程池中的工作线程是一直等待吗？
   是的，等待新任务的唤醒；
5. 你的线程池工作线程处理完一个任务后的状态是什么
    如果请求队列为空，则该线程进入线程池中等待；若不为空，则该线程跟其他线程一起进行任务的竞争；
6. 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？
   由于采用了基于非阻塞IO多路复用，通过时分复用的方式就可以解决这样的问题。当客户连接有事件需要处理的时，epoll会进行事件提醒，而后讲对应的任务加入请求队列，等待工作线程竞争执行。如果速度还是慢，那就只能够增大线程池容量，或者考虑集群分布式的做法
7. 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?
   会，因为线程的数量是固定的，如果一个客户请求长时间占用着线程资源，势必会影响到服务器对外的整体响应速度。解决的策略可以是给每一个线程处理任务设定一个时间阈值，当某一个客户请求时间过长，则将其置于任务请求最后，或断开连接
8. 怎样正确关闭线程池
   本项目中在析构函数中设置了一个控制线程池结束的bool值，当delete线程池对象时会直接关闭线程池，无论是否在处理请求。如果要安全地关闭线程池，应当在执行完正在执行的任务和队列中等待的任务后才彻底关闭，并直接拒绝后续地新的提交

#### 并发模型问题
1. 简单说一下服务器使用的并发模型？
      并发模式采用半同步半反应堆，IO模型采用同步IO模拟Proactor模式。所以主线程充当异步线程，使用epoll监听所有socket上的事件。同时对连接进行读写也由主线程完成。     
     1. 主线程往epoll内核事件表中注册socket上的读就绪事件,调用epoll_wait等待socket上有数据可读。
     2. 当socket上有数据可读时，epoll_wait通知主线程读取数据。然后将读取到的数据封装成一个请求对象并插入请求队列。
     3. 线程池中的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。
     4. 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。
2. reactor、proactor、主从reactor模型的区别？
   - Reactor模式：
      reactor模式中，主线程(I/O处理单元)只负责监听文件描述符上是否有事件发生，有的话立即通知工作线程(逻辑单元)，读写数据、接受新连接及处理客户请求均在工作线程中完成。通常由同步I/O实现。
   - Proactor模式
      Proactor 模式将所有 IO 操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑，如处理客户请求。一般由异步I/O实现。
   - 同步I/O模拟proactor模式
      proactor模式中，工作线程仅负责业务逻辑不处理IO。那么使用同步I/O模拟proactor，就需要在主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一“完成事件”即可。
   - 主从Reactor模式
      核心思想是，主反应堆线程只负责分发Acceptor连接建立，已连接套接字上的I/O事件交给sub-reactor负责分发。
3. 你用了epoll，说一下为什么用epoll，还有其他复用方式吗？区别是什么？
   复用方式，比较常用的有三种：select/poll/epoll
   为什么使用epoll也就是区别在于
   - 首先底层数据结构不同
      select使用线性表描述文件描述符集合，文件描述符有上限；poll使用链表来描述，文件描述符没有上限，epoll底层通过红黑树来描述
   - 其次epoll不需要拷贝整个文件描述符表
      epoll在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字，把需要监控的 socket 加⼊内核中的红⿊树⾥，红⿊树增删查⼀般时间复杂度是O(logn) ，就不需要每次都拷贝一整个socket集合，减少了拷贝开销和内存占用。而select和poll都需要从⽤户态与内核态之间拷⻉整个⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。
   - 最后epoll不遍历所有的文件描述符
      由于底层数据结构的不同，select和poll都需要遍历文件描述符集合，时间复杂度为O(n), 而epoll使⽤异步事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件，当某个 socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件链表中。epoll所以遍历的时间复杂度为O(1)
   - 当监测的fd数量较小，且各个fd都很活跃的情况下，建议使用select和poll；当监听的fd数量较多，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。
4. 为什么epoll需要将socket设为非阻塞？
   主要是看对应socket是LT模式还是ET模式。对于LT模式阻塞和非阻塞都可以实现，因为一旦缓冲区未读尽epoll_wait会一直返回，不会遗漏数据。但对于ET模式，由于epoll_wait只会返回一次，所以我们要用循环一次性将缓冲区中数据读完，如果设置阻塞，就会阻塞在最后一次循环，导致任务进行不下去。
5. 客户端断开连接，服务端epoll监听到的事件是什么
   对端连接断开触发的 epoll 事件会包含 EPOLLIN | EPOLLRDHUP
6. epoll的线程安全
   epoll是通过锁来保证线程安全的, epoll中粒度最小的自旋锁ep->lock(spinlock)用来保护就绪的队列, 互斥锁ep->mtx用来保护epoll的重要数据结构红黑树


#### HTTP报文解析相关
1. 为什么要用状态机？
   有限状态机是逻辑单元内部一种编程方法，通过if-else,switch-case和函数指针来实现，这样服务器就可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂
2. 画一下状态机的转移图
   ![状态机](https://pic4.zhimg.com/v2-053512c11e9e80de7c1bd1e68153f93b_r.jpg)
3. https协议为什么安全？
4. https的ssl连接过程？
5. GET和POST的区别
6. HTTP报文的格式
7. 一次HTTP请求响应的流程
   - 域名解析
   - 发起TCP的3次握手
   - 建立TCP连接后发起http请求
   - 服务器响应http请求，浏览器得到html代码
   - 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）
   - 浏览器对页面进行渲染呈现给用户
8. GET、POST区别
   - GET重点在从服务器上获取资源,post重点在向服务器发送数据
   - GET数据通过URL传递，而POST是放在请求体中，所以GET不能传递大量数据
   - GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息
   - GET产生一个TCP数据包，POST产生两个TCP数据包。POST会先发送请求头部，服务器会响应100continue，再发送请求体，服务器响应200.在网络好的情况下效率差别不大，但在网络比较差的情况下，两次包在验证数据包完整性上，有非常大的优点
9.  HTTP请求如何判断get提交还是post提交？
   本项目中对于密码和用户名的传输是采用post提交的，因为get提交会直接暴露早url中。客户端要判断是get还是post就直接看url就可以了，服务器端判断是通过解析状态行，查看请求方法来判断的。
10. http报文怎么检测头部和包体的间隔
      通过\r\n
11. 怎么检测包体的结束
   在头部有一个content-length,然后你收内容为这个长度即可
11. HTTP请求怎么拆包
   HTTP请求内容：请求行，请求头，请求体。通过\r\n检测头部和包体的间隔。而在头部有一个content-length来检测包体的结束
12. HTTP怎么接收图片和视频流
   使用Content-Type字段，说明响应体中的媒体数据类型



#### SQL连接问题
1. 客户端如何登录？
   首先是服务端会载入数据库表，将数据库中的数据载入到服务器中。然后对报文进行解析，提取用户名和密码，并对用户名和密码进行登录校验。最后是通过设置编号来对不同的资源进行访问。
2. 你这个保存状态了吗？如果要保存，你会怎么做？
   可以利用session或者cookie的方式进行状态的保存。
   cookie其实就是服务器给客户分配了一串“身份标识”，比如“123456789happy”这么一串字符串。每次客户发送数据时，都在HTTP报文附带上这个字符串，服务器就知道你是谁了；
   session是保存在服务器端的状态，每当一个客户发送HTTP报文过来的时候，服务器会在自己记录的用户数据中去找，类似于核对名单；
3. 如何实现SQL连接池？
   采用单例模式和链表来创建数据库连接池。和线程池类似，本质上也是生产者和消费者模型。首先将连接池设计为一个单例类。通过RALL机制在构造函数中批量创建连接并存放在链表中。同时在析构函数中销毁连接。这里线程相当于消费者，链表中的连接相当于生产者。同时通过锁来对链表来对链表进行加锁。当线程申请SQL连接时，信号量减1，如果连接池内没有连接则阻塞等待。
4. 登录中的用户名和密码你是load到本地，然后使用map匹配的，如果有10亿数据，即使load到本地后hash，也是很耗时的，你要怎么优化？
   对于大数据最遍历的方法就是进行hash，利用hash建立多级索引的方式来加快用户验证。比如将10亿的用户信息，利用大致缩小1000倍的hash算法进行hash，这时就获得了100万的hash数据，每一个hash数据代表着一个用户信息块（一级）；而后再分别对这100万的hash数据再进行hash，例如最终剩下1000个hash数据（二级）。在这种方式下，服务器只需要保存1000个二级hash数据，当用户请求登录的时候，先对用户信息进行一次hash，找到对应信息块（二级），在读取其对应的一级信息块，最终找到对应的用户数据。


#### 定时器相关
1. 为什么要用定时器？
   处理定时任务，或者非活跃连接，节省系统资源；
2. 说一下定时器的工作原理？
   服务器为各事件分配一个定时器。该项目使用SIGALRM信号来实现定时器，首先每一个定时事件都处于一个升序链表上，通过alarm()函数周期性触发SIGALRM信号，而后信号回调函数利用管道通知主循环，主循环接收到信号之后对升序链表上的定时器进行处理：若一定时间内无数据交换则关闭连接。
3. 双向链表啊，删除和添加的时间复杂度说一下？还可以优化吗？
   添加一般情况下都是O(N)，删除只需要O(1)。从双向链表的方式优化不太现实，可以考虑使用最小堆优化
4. 最小堆优化？说一下时间复杂度和工作原理
   最小堆以每个定时器的过期时间进行排序，最小的定时器位于堆顶，当SIGALRM信号触发tick（）函数时执行过期定时器清除，如果堆顶的定时器时间过期，则删除，并重新建堆，再判定是否过期，如此循环直到未过期为止。插入和删除的时间复杂度都是O(logN)


#### 日志相关
1. 如何实现日志系统？
   初始化服务器时，利用单例模式初始化日志系统，根据配置文件确认是同步还是异步写入的方式。如果是同步写入，则每次需要写日志的时候，就直接调用日志类中的公有函数对日志文件进行加锁写入。而如果是异步写入的方式，就需要创建一个线程以及阻塞队列。每次需要写日志的时候，将日志信息加入阻塞队列。再由新的线程通过生产者与消费者的模式写入日志文件。
2. 为什么要异步？和同步的区别是什么？
   同步方式写入日志时会产生比较多的系统调用比如fput()，若是某条日志信息过大，会阻塞日志系统和主线程，造成系统瓶颈。而异步方式采用生产者-消费者模型，具有较高的并发能力。
3. 这个阻塞队列如何实现？
   采用循环数组的方式。定义front和rear遍历，front指向队列的第一个元素，rear指向队列的最后一个元素，rear == front即队列为空，而(rear + 1) % maxSize == front则代表队列已满。
4. 现在你要监控一台服务器的状态，输出监控日志，请问如何将该日志分发到不同的机器上？
   可以使用消息队列进行消息的分发，例如mqtt、rabitmq等等
5. 说一说你的系统日志的分级
   分为debug测试用，info显示一般信息，warn显示警告，error显示错误信息
6. 针对高并发情况下，写线程数量不足，如何处理？
   采用线程池的方式写入。


#### 压测相关
1. 服务器并发量测试过吗？怎么测试的？
   测试过，利用webbench，至少满足万余的并发量
2. webbench是什么？介绍一下原理
   是一款轻量级的网址压力测试工具，可以实现高达3万的并发测试。
   其原理：Webbench实现的核心原理是：父进程fork若干个子进程，每个子进程在用户要求时间或默认的时间内对目标web循环发出实际访问请求，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在时间到后结束，父进程在所有子进程退出后统计并给用户显示最后的测试结果，然后退出。
3. 测试的时候有没有遇到问题？
   见上文
4. 压测的瓶颈会在哪里
   - io读取速度
   - CPU占用
   - 内存大小
5. 如何验证压测瓶颈
   - 一个是查看内核参数，通过watch命令结合/proc/cpuinfo查看
   - 还要就是利用一下性能分析命令，比如对于网络性能分析可以用netstat,ss,sar,对于IO性能的话通过iostat以及iotop查看吞吐量，对于CPU和内存的话htop,ps,vmstat等等
6. 如何进行多线程调试
   这里利用vscode编辑器+GDB进行调试，对程序中需要监测的位置打断点，利用-exec执行对应的 GDB 调试指令。在此基础上，让程序全速运行到指定的断点处，此时在调试控制台中采用info threads 可以显示当前可调试的所有线程，其中带*号的是正在调试的线程。此时如果需要在当前线程中单步运行的话，可以使用set scheduler-locking on命令进行上锁，执行单步调试。在最后使用set scheduler-locking off 解除锁定，返回原先的线程。



#### 其他细节问题
1. 端口复用
   - 防止服务器重启时之前绑定的端口还未释放，因为在服务端结束后，也就是第三次挥手的时候会有个time_wait,此时仍占用端口
   - 程序突然退出而系统没有释放端口
   ```
   int reuse = 1;
   setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &reuse, sizeof(reuse));
   ```
2. socket缓冲区
   就是在内核中的发送缓冲区和接受缓冲区，执行 send 之后，数据只是拷贝到了socket 缓冲区。至于什么时候会发数据，发多少数据，取决于滑动窗口和拥塞控制。
3. 静态成员变量
   通过pthread_create创建多个工作线程时，传入的函数必须是静态函数，因为非静态函数隐含this参数，不符合pthread_create要求。同时由于静态函数只能访问静态成员，为了访问非静态成员，就需要将this指针作为参数传递进去。
4. 大端序小端序
   0x12345678，从左往右数据字节序由高向低
   网络端是大端字节序，高位字节存低地址，地位字节存高地址
   主机端是小端字节序，低位字节存低地址，高位字节存高地址
   大端字节序方便人类阅读，小端字节序方便计算机内部处理，因为这样计算机读取数据时先独到的就是低位字节再是高位字节。


### 基础知识
#### Proactor模式
1. IO模型
    - 阻塞IO：
        当⽤户程序执⾏ read ，线程会被阻塞，⼀直等到内核数据准备好，并把数据从内核缓冲区拷⻉到应⽤程序的缓冲区中，当拷⻉过程完成， read 才  会返回
        阻塞等待的是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程
    - 非阻塞IO:
        ⾮阻塞的 read 请求在数据未准备好的情况下⽴即返回，可以继续往下执⾏，此时应⽤程序不断轮询内核，直到数据准备好，内核将数据拷⻉到应⽤程序缓冲区， read 调⽤ 才可以获取到结果
        非阻塞等待的是「数据从内核态拷⻉到⽤户态」这个过程
    - 基于非阻塞IO多路复用
        当内核数据准备好时，再以事件通知应⽤程序进⾏操作.通过内核而不是程序来循环遍历文件描述符。监控多个文件描述符的同时减少了系统调用的次数。
        但还需要等待内核将数据从内核空间拷⻉到应⽤程序空间
    - 信号驱动IO
         通过信号处理函数，不阻塞，当进程收到SIGIO信号处理IO事件，但还需要等待内核将数据从内核空间拷⻉到应⽤程序空间
    - 同步IO
        包括阻塞 I/O、⾮阻塞 I/O，信号驱动IO，基于⾮阻塞 I/O 的多路复⽤。因为它们在 read调⽤时，内核将数据从内核空间拷⻉到应⽤程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷⻉效率不⾼， read调⽤就会在这个同步过程中等待⽐较⻓的时间。
    - 异步IO
        在IO模型中异步IO和同步区分的是内核向应用程序通知的是就绪事件还是完成事件，以及是应用程序和内核谁来完成读写。
        异步I/O 是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程都不⽤等待
        发起 aio_read 之后，就⽴即返回，内核准备数据，并且⾃动将数据从内核空间拷⻉到应⽤程序空间，这个拷⻉过程同样是异步的，内核⾃动完成的，和前⾯的同步操作不⼀样，应⽤程序并不需要主动发起拷⻉动作。
2. reactor模式
   reactor模式中，主线程(I/O处理单元)只负责监听文件描述符上是否有事件发生，有的话立即通知工作线程(逻辑单元)，读写数据、接受新连接及处理客户请求均在工作线程中完成。通常由同步I/O实现。
   - 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件，程调用 epoll_wait 等待 socket 上有数据可读。
   - 当 socket 上有数据可读时，epoll_wait 通知主线程。主线程则将socket可读事件放入请求队列。
   - 睡眠在请求队列上的工作线程被唤醒，它从 socket 读取数据，并处理客户请求，然后往 epoll 内核事件表中注册该 socket 上的写就绪事件。
   - 当 socket 可写时，epoll_wait 通知主线程。主线程将 socket 可写事件放入请求队列。
   - 睡眠在请求队列上的某个工作线程被唤醒，它往 socket 上写入服务器处理客户请求的结果。
3. proactor模式
   - Proactor 模式将所有 IO 操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑，如处理客户请求。一般由异步I/O实现。
   - 连接 socket 上的读写事件是通过 aio_read/aio_write 向内核注册的，因此内核将通过信号向应用程序报告连接 socket 上的读写事件。所以主线程的 epoll_wait 仅能检测监听 socket 上的连接请求事件，不能用来检测连接 socket 上的读写事件
4. 同步I/O模拟proactor模式
   - proactor模式中，工作线程仅负责业务逻辑不处理IO。那么使用同步I/O模拟proactor，就需要在主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一“完成事件”即可。
     1. 主线程往epoll内核事件表中注册socket上的读就绪事件,调用epoll_wait等待socket上有数据可读。
     2. 当socket上有数据可读时，epoll_wait通知主线程读取数据。然后将读取到的数据封装成一个请求对象并插入请求队列。
     3. 线程池中的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。
     4. 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。
   - 注意在真正的proactor模式中，主线程仅监听新连接，而模拟的proactor模式中都监听


#### 半同步/半异步反应堆
1. 并发模式
   - 并发模式是指I/O处理单元（处理客户端连接，读写网络数据）和多个逻辑单元（业务进程或者线程）之间协调完成任务的方法。
   - 服务器主要有两种并发编程模式：半同步/半异步模式和领导者/追随者模式。
   - 同步指的是程序完成按照代码序列的顺序执行；按照同步方式运行的线程称为同步线程。同步线程虽然效率低，实时性差，但逻辑简单。
   - 异步指的是程序的执行需要操纵系统事件来驱动。常见的系统事件包括中断、信号等。按照异步方式运行的线程称为异步线程。异步线程的执行效率高，实时性强，但是编写异步方式执行的程序相对复杂，难于调试和扩展，而且不适合大量的并发。
   - 因此想服务器这种既要求较好的实时性，有要求同时处理过个客户端请求的应用程序，我们就应该同时使用同步线程和异步线程来实现，即采用半同步/半异步模式来实现
2. 半同步/半异步反应堆
   - 主线程充当异步线程，监听所有事件，有事件发生则将事件插入请求队列中。工作线程休眠在请求队列中，当任务到来时，通过竞争获取任务处理权。可以看作Reactor模式，也可以模拟为Proactor模式。即主线程完成数据的读写，将数据封装成任务对象插入请求队列，工作线程从请求队列取出任务对象处理。
   - 缺点
     - 主线程和工作线程共享请求队列，对请求队列的操作需求加锁，耗费CPU时间
     - 每一个工作线程在同一时间只能处理一个客户请求。客户数量多，工作线程少，请求队列任务堆积，响应满，如果添加试图通过增加线程则，由于线程切换导致的CPU时间消耗。。
3. 半同步/半异步模式
   主线程只管理监听socket，工作线程监听连接socket。主线程将新连接的socket派发给工作线程，所有的IO操作都由工作线程完成，节省了线程切换的开销，同时每个工作线程都能同时处理多个客户连接。


#### ET/LT/ONESHOT
1. epoll
   - int epoll_create(int size)
     创建一个指示epoll内核事件表的文件描述符，该描述符将用作其他epoll系统调用的第一个参数，size不起作用。
   - int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)
     该函数用于操作内核事件表监控的文件描述符上的事件：注册、修改、删除
   - int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout)
     该函数用于等待所监控文件描述符上有事件的产生，返回就绪的文件描述符个，传出参数events用来存内核得到事件的集合
2. LT水平触发模式
   - 被监控的文件描述符有可读事件，只要内核缓冲区内还有数据，比如读缓冲区太小不能一次读完，就会一直触发，epoll_wait()会一直通知程序进行操作，确保读完
   - 对于可写事件，LT模式下只要内核缓冲区可写就一直会触发，所以要在数据发送完成后移除检测可写事件(*本项目里会重新注册，顺便也重新注册了EPOLLONESHOT*)
   - 和阻塞或者非阻塞文件描述符相使用，epoll_wait()通知有读事件后，通过recv()数据返回
3. ET边缘触发模式
   - 被监控的文件描述符有可读事件，如果读缓冲区过小不能一次读完，都只会触发一次，即epoll_wait()只会通知一次程序来进行操作，直到下一次新的数据到达。所以要通过while来循环读取数据。
   - 对于可写事件，ET模式下如果内核缓冲区可写则只会通知一次，所以如果send()发送数据不能一次发送完成时，则必须再次注册可写事件(*本项目里使用writev如果一次写不完，会返回errno为EAGAIN，需要再注册一次可写事件*)
   - 和非阻塞文件描述符相使用，避免最后一次循环阻塞，当缓冲区为空后会导致EAGAIN错误，即读取完毕，此时就可以返回
4. 对于监听socket文件描述符和读写的socket文件描述符
   - 对于监听的socket文件描述符最好使用ET模式。如果使用LT模式，会导致高并发情况下，全连接队列有多个就绪连接，而epoll_wait()只通知accept一次，有些连接会连接不上。一定要使用的话必须使用while来循环accept，由于监听socket是非阻塞的，就绪连接处理完后，返回-1直接break退出循环。
   - 对于读写的socket文件描述符，LT,ET模式都可以，LT支持阻塞与非阻塞，而ET必须用阻塞
5. ET模式相较于LT模式的优势
   ⼀般来说，边缘触发的效率⽐⽔平触发的效率要⾼，因为边缘触发可以减少 epoll_wait 的系统调⽤次数，比如如果一次没有读完内核缓冲区数据，LT模式下就会再调用一次epoll_wait，再触发一次。而系统调⽤也是有⼀定的开销的的
6. EPOLLONESHOT
   EPOLLONESHOT主要是为了应对多线程的情况，比如对应某一个连接事件到来，工作线程进行处理，如果这时又有新的事件到达，如果又触发了其他线程来进行处理，则会导致混乱。而注册了EPOLLONESHOT后，就相当于触发事件后将对应socket从epoll的检测列表中清除，所以之后还需要重新注册。    


#### 有限状态机
  - 有限状态机是逻辑单元内部一种编程方法，通过if-else,switch-case和函数指针来实现，这样服务器就可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂
  - 分为主从状态机，主状态机判断是在分析请求行、分析请求头或是请求体。而每次在主状态机判断之前通过从中状态机判断是读取了完整的一行，是没有读到完整的一行，还是读取行错误。判断依据是根据请求报文的结构，即行结束和空行的\r\n。


#### 线程池
   - 动态创建、销毁及切换线程都有开销，会导致客户响应慢
   - 池是一组资源的集合,这组资源在服务器启动之初就被完全创建好并初始化,这称为静态资源.当服务器进入正式运行阶段,开始处理客户请求的时候,如果它需要相关的资源,可以直接从池中获取,无需动态分配.当服务器处理完一个客户连接后,可以把相关的资源放回池中,无需执行系统调用释放资源


#### SQL连接池
   - 如果需要频繁访问数据库，不创建连接池就只能反复的创建数据库连接和断开连接，而这是很耗时的，而且容易造成据库安全隐患
   - 连接池中的资源为一组数据库连接，由程序动态地对池中的连接进行使用，释放。当系统开始处理客户请求的时候，如果它需要相关的资源，可以直接从池中获取，无需动态分配；当服务器处理完一个客户连接后,可以把相关的资源放回池中，无需执行系统调用释放资源。

#### 锁模块
1. RALL
   - RAII即“资源获取即初始化”.
   - 在构造函数中申请分配资源，在析构函数中释放资源。因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定
   - RAII的核心思想是将资源或者状态与对象的生命周期绑定，通过C++的语言机制，实现资源和状态的安全管理,智能指针是RAII最好的例子
2. 锁机制的功能
   实现多线程同步，通过锁机制，确保任一时刻只能有一个线程能进入关键代码段.
3. 信号量sem_t
   等待(P)和信号(V)
   - P，如果SV的值大于0，则将其减一；若SV的值为0，则挂起执行
   - V，如果有其他进行因为等待SV而挂起，则唤醒；若没有，则将SV值加一 
   - sem_init函数用于初始化一个未命名的信号量
   - sem_destory函数用于销毁信号量
   - sem_wait函数将以原子操作方式将信号量减一,信号量为0时,sem_wait阻塞
   - sem_post函数以原子操作方式将信号量加一,信号量大于0时,唤醒调用sem_post的线程
   - 成功返回0，失败返回errno
4. 互斥量pthread_mutex_t
   - pthread_mutex_init函数用于初始化互斥锁
   - pthread_mutex_destory函数用于销毁互斥锁
   - pthread_mutex_lock函数以原子操作方式给互斥锁加锁
   - pthread_mutex_unlock函数以原子操作方式给互斥锁解锁
   - 成功返回0，失败返回errno
5. 条件变量pthread_cond_t
   条件变量提供了一种线程间的通知机制,当某个共享数据达到某个值时,唤醒等待这个共享数据的线程.
   - pthread_cond_init函数用于初始化条件变量
   - pthread_cond_destory函数销毁条件变量
   - pthread_cond_signal
   - pthread_cond_broadcast函数以广播的方式唤醒所有等待目标条件变量的线程
   - pthread_cond_timedwait线程等待一定的时间，如果超时或有信号触发，线程唤醒
   - pthread_cond_wait函数用于等待目标条件变量.该函数调用时需要传入 mutex参数(加锁的互斥锁) ,函数执行时,先把调用线程放入条件变量的请求队列,然后将互斥锁mutex解锁,当函数成功返回为0时,互斥锁会再次被锁上. 也就是说函数内部会有一次解锁和加锁操作
   - 比如在消费者与生产者模型中，没有资源时消费者通过pthread_cond_wait阻塞，同时这个函数又对互斥锁解锁，这样生产者开始生成资源，生产完成后通过pthread_cond_signal通知消费者，pthread_cond_wait不再阻塞，同时再对互斥锁加锁。实现了同步机制。

