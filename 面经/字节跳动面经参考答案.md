### 字节跳动面经参考答案

---

**计算机网络**

1.说一说四次挥手全过程

```
客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。
服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。
客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。
等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。
客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态
服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，至此服务端已经完成连接的关闭。
客户端在经过 2MSL 一段时间后，自动进入 CLOSED 状态，至此客户端也完成连接的关闭。
你可以看到，每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。
```

2.为什么要等待2MSL

```
原因一: 确保本次TCP连接中产生的所有报文都消失在网络中, 从而防止历史连接中的数据，被后面相同四元组的新连接错误的接收.
假设不等待2MSL时间, 那么当此次TCP连接结束后, 网络中可能还存在这次连接中产生的数据包, 如果我们紧接着又重新开始一次新的TCP	连接, 那么很有可能上次历史连接中的数据包正好处于接收窗口中, 从而被接收, 这样会导致一些错误.

原因二: 使TCP连接双方都能够正常的关闭连接. 
如果客户端发送给服务端的ACK报文在网络中丢失了, 2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 在网络中丢失或阻塞, 没有传送到服务端，那么服务端会在2MSL的时间内重传FIN报文给客户端. 客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时. 等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。
```

3.HTTPS协议过程

```
SSL/TLS 协议基本流程：
    客户端向服务器索要并验证服务器的公钥。
    双方协商生产「会话秘钥」。
    双方采用「会话秘钥」进行加密通信。
前两步也就是 SSL/TLS 的建立过程，也就是握手阶段。SSL/TLS 的「握手阶段」涉及四次通信，可见下图：
1. ClientHello
首先, 由客户端向服务器发起加密通信请求, 也就是ClientHello请求.
在这一步, 客户端主要向服务器发送如下信息:
（1）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。
（2）客户端生产的随机数（Client Random），后面用于生产「会话秘钥」。
（3）客户端支持的密码套件列表，如 RSA 加密算法。

2. ServerHello
服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。
服务器回应的内容有如下内容：
（1）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。
（2）服务器生产的随机数（Server Random），后面用于生产「会话秘钥」。
（3）确认的密码套件列表，如 RSA 加密算法。
（4）服务器的数字证书。

3. 客户端回应
客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。
如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：
（1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。
（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。
上面第一项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。

4. 服务器的最后回应

服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发生最后的信息：
（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。

至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过使用「会话秘钥」加密内容。
```

4.GET, POST区别

```
GET - 从指定的资源请求数据
POST - 向指定的资源提交要被处理的数据。

白话:
根据 RFC 规范,GET 的语义是从服务器获取指定的资源,这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中,URL 规定只能支持 ASCII,所以 GET 请求的参数只允许 ASCII 字符 ,而且浏览器会对 URL 的长度有限制（但是HTTP协议本身对 URL长度并没有做任何规定）。
根据 RFC 规范,POST 的语义是根据请求负荷（报文body）对指定的资源做出处理,具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中, body 中的数据可以是任意格式的数据,只要客户端与服务端协商好即可,而且浏览器不会对 body 大小做限制。
另一个呢, GET 方法就是安全且幂等的,因为它是「只读」操作,无论操作多少次,服务器上的数据都是安全的,且每次的结果都是相同的。所以,可以对 GET 请求的数据做缓存,POST 因为是「新增或提交数据」的操作,会修改服务器上的资源,所以是不安全的,且多次提交数据就会创建多个资源,所以不是幂等的。所以,浏览器一般不会缓存 POST 请求,也不能把 POST 请求保存为书签。
```

5.TCP, UDP的应用场景

```
由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：
    FTP 文件传输；
    HTTP / HTTPS；
由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于包总量较少的通信，
	如 DNS 、SNMP 等；
	视频、直播等多媒体通信；
	广播通信
```

6.DNS查询的详细过程

```
DNS查询就是寻找哪台机器上有我们所需要资源的过程. 就是将域名 映射到 具体的IP地址的过程
...
所以DNS根据域名查询IP地址的过程为：浏览器缓存 --> 操作系统缓存(本地Hosts文件) --> 路由器缓存-->本地（ISP）域名服务器缓存 --> 根域名服务器 --> 顶级域名服务器 --> 权限域名服务器。
```

7.TCP, UDP的区别

```
1. 连接
TCP 是面向连接的传输层协议，传输数据前先要建立连接。
UDP 是不需要连接，即刻传输数据。
2. 服务对象
TCP 是一对一的两点服务，即一条连接只有两个端点。UDP 支持一对一、一对多、多对多的交互通信
3. 可靠性
TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。
UDP 是尽最大努力交付，不保证可靠交付数据。
4. 拥塞控制, 流量控制
TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
5. 传输方式
TCP 是流式传输，没有边界，但保证顺序和可靠。
UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。
```

8.TCP的包丢了怎么办, 重传有哪几种类型?

```
TCP要保证所有的数据包都可以到达，所以，必需要有重传机制。
重传主要有两种类型, 一种是超时重传, 一种是快速重传.
超时重传就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据. TCP会在两种情况下发生超时重传, 一是发送给对方的数据包丢失, 二是对方返回的ACK确认应答丢失.超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。
但是, 超时触发重传的问题是, 超时等待的时间可能相对较长,那么我们可以采用快速重传机制, 他不以时间为驱动, 而是以数据为驱动来进行重传动作.
例子:
发送方发出了1, 2, 3, 4, 5份数据, 第一份数据先送到了于是服务端返回ACK为2, 但是第二份数据在网络中丢失或者阻塞了, 后面的第三份数据, 第四份数据都陆续收到了, 但是这时候接收方都是返回ACK为2的确认应答. 这时发送方连续收到了三个ACK = 2的确认, 就知道第二份数据还没有送到接收方, 就在定时器过期之前, 立刻重传第二份数据. 这样可以节省了等待超时的时间.
但是关于是否只重传第二份数据, 还是重传之后的所有数据, 发送方并不清楚, 因为不知道是哪几份数据发回来的ACK = 2的确认, 
... SACK DSACK
```

9.TCP粘包怎么解决?

```
粘包出现的原因:
简单得说，在流传输中出现，UDP不会出现粘包，因为它有消息边界, UDP 报文中的数据部分就是完整的用户消息，也就是每个 UDP 报文就是一个用户消息的边界，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。

而对于TCP协议来说, 它是面向字节流的
也就是说, 当用户消息通过 TCP 协议传输时，消息可能会被操作系统分组成多个的 TCP 报文，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。
我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议。
当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。

原因:
1发送端需要等缓冲区满才发送出去，造成粘包
2接收方不及时接收缓冲区的包，造成多个包接收
具体点：
（1）发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一包数据。若连续几次发送的数据都很少，通常TCP会根据Nagle优化算法(TCP默认开启, 为了避免网络充斥着过多的小包，提高网络传输的效率)把这些数据合成一包后一次发送出去，这样接收方就收到了粘包数据。
（2）接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。

解决办法:
粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。
一般有三种方式分包的方式：

固定长度的消息；
特殊字符作为边界；
自定义消息结构。

#固定长度的消息
这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。
但是这种方式灵活性不高，实际中很少用。

#特殊字符作为边界
我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。
HTTP 是一个非常好的例子。HTTP 通过设置回车换行符作为 HTTP 报文协议的边界。有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。

#自定义消息结构
我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。
```

10.TCP为什么要三次握手

```
我认为TCP三次握手主要有两个原因,首要原因是为了防止历史连接初始化造成混乱和资源浪费, 其次是为了同步双方的起始序列号.
对于第一个原因, 
我们考虑这样的情况,假设客户端先发了一个序列号为90的SYN请求报文, 但是它在网络中某个节点被阻塞了, 然后客户端又发送了另一个新的SYN请求报文, 序列号为100, 但是旧的请求报文比新的先到达服务端, 然后服务端回返回一个SYN ACK报文, 其中ack确认号为91, 这显示是错的, 客户端收到该ACK报文之后, 发现确认号为91而不是101, 判定这是一个历史连接, 客户端就发送一个RST报文回去告知服务端, 终止这次连接.
如果没有三次握手, 那么服务端在接收到请求报文之后立刻建立连接, 没有等待客户端的确认, 那么显然会出现混乱和资源浪费.
第二个原因就是, 
TCP 协议的通信双方， 都必须维护一个「序列号」， 以标识发送出去的数据包中, 哪些是已经被对方收到的。序列号是可靠传输的一个关键因素. 序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。
```

11.HTTP协议有哪几种请求方法

```
GET 请求指定的页面信息
POST 向指定资源提交数据进行处理请求(例如提交表单或者上传文件). 文件被包含在请求体中, POST请求可能会导致新的资源的建立或者已有资源的修改
HEAD 类似于get请求, 只不过返回的响应中没有具体的内容, 用于获取报头
DELETE 请求服务器删除指定的页面
PUT 向指定资源位置上传其最新内容
```

12.GET和POST哪个能传较大的数据

```
POST
使用GET方法时，请求参数和对应的值会附加在URL后面, 不同浏览器会对URL的长度有所限制, 当超过这个长度会报错. 一般来说, GET方法中请求体中不携带数据
而POST会将数据放在请求体中传过去
```

13.HTTP头部字段

```
Host字段 客户端发送请求时，用来指定服务器的域名
Connection字段 最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。
User-Agent:客户端程序的信息，就是我发送请求的浏览器信息。
Accept：列出了浏览器可以接收的媒体数据类型：
Accept-Language:告知服务器浏览器能够处理的自然语言集（中文、英文等）。zh-CN中文简体。
Cookie：浏览器记录的用户相关信息。
Content-Length字段 服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。
Content-Type字段 用于服务器回应时，告诉客户端，本次数据是什么格式。
Content-Encoding字段 说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式
```

14.HTTP版本的区别

```
https://blog.csdn.net/qq_40860852/article/details/93632106
HTTP/0.9：功能简陋，只支持GET方法，只能发送HTML格式字符串。
HTTP/1.0：支持多种数据格式，增加POST、HEAD等方法，增加头信息，每次只能发送一个请求（无持久连接）
HTTP/1.1：默认持久连接、请求管道化、增加缓存处理、增加Host字段、支持断点传输分块传输等。
HTTP/2.0：二进制分帧、多路复用、头部压缩、服务器推送
```

15.HTTP状态码

```
1xx 1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少
2xx 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。
	200 OK 是最常见的成功状态码, 表示一切正常。除了HEAD请求, body体都会带有数据
	204 No Content	和200 OK基本相同, 但响应头没有body数据
3xx 3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。
	301 Moved Permanently 表示永久重定向, 说明请求的资源已经不存在了，需改用新的 URL 再次访问。
	302 Found 表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。
4xx 4xx类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义
	400 Bad Request 表示客户端请求的报文有错误，但只是个笼统的错误
	403 Forbidden 表示服务器禁止访问资源，并不是客户端的请求出错。
	404 Not Found 表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。
5xx  5xx类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。
	
```

16.说一下七层OSI模型

```
OSI七层模型: 物联         网    淑   慧试用
TCP/IP模型: 网络接口层  网络层 传输层 应用层
```

17.TCP, UDP的区别和适用场景

```
1. 连接
TCP 是面向连接的传输层协议，传输数据前先要建立连接。
UDP 是不需要连接，即刻传输数据。
2. 服务对象
TCP 是一对一的两点服务，即一条连接只有两个端点。UDP 支持一对一、一对多、多对多的交互通信
3. 可靠性
TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。
UDP 是尽最大努力交付，不保证可靠交付数据。
4. 拥塞控制, 流量控制
TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
5. 传输方式
TCP 是流式传输，没有边界，但保证顺序和可靠。
UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

适用场景:
由于 TCP 是面向连接,能保证数据的可靠性交付,因此经常用于：
FTP 文件传输；
HTTP / HTTPS；

由于 UDP 面向无连接,它可以随时发送数据,再加上UDP本身的处理既简单又高效,因此经常用于：
包总量较少的通信,如 DNS 、SNMP 等；
视频、音频等多媒体通信；
广播通信；
```

18.IP协议的报头

```
IP协议版本字段 头长度  服务类型 包总长度
  标志位(DF, MF) 片偏移量
源IP
目的IP
选项为非固定信息，可变长度，选项最长可达40个字节，这个字段主要用于测试。
```

19.说下三次握手的原理

```
1.一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态
2.客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。
3.服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。
4.客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。

从上面的过程可以发现第三次握手是可以携带数据的，前两次握手是不可以携带数据的，这也是面试常问的题。
```

20.说一下SYN攻击

```
我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 请求报文发送给服务端，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端返回给客户端的 ACK + SYN 报文，全部都被客户端给有意忽略掉不进行确认，同时服务端还会不停重发SYN ACK报文, 久而久之就会占满服务端的半连接队列，服务端的内存, 带宽资源都会耗尽, 使得服务器不能为正常用户服务。
```

21.如何防范SYN攻击

```
如果不断受到 SYN 攻击，就会导致 SYN 队列（半连接队列）被占满，从而导致无法再建立新的连接。
第一个办法就是通过增加服务端SYN半连接队列的大小, 我们通过修改应用的listen函数调用和一个操作系统内核参数来显示的扩充SYN半连接队列的大小, 但显然这种方法本身并不能被完全认为是抵御SYN洪泛的有效方法，即使在一些能够有效支持超大SYN半连接队列分配的操作系统中，因为攻击者能够任意生成比其操作系统支持的队列上线还多得多的数据报。

其实最常用的一个手段就是优化主机系统设置。比如降低SYN timeout时间，使得主机尽快释放半连接的占用, 如果短时间内收到了某个IP的重复SYN请求，我们就认为受到了攻击。我们合理的采用防火墙设置等外部网络也可以进行拦截。

我们还可以采用SYN Cookies的策略, 当 「SYN 队列」满之后，后续服务器收到 SYN 包，就不再进入「 SYN 队列」；
TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来. 然后服务端再检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」。
也就是说后续的合法的TCP连接不用再进入SYN半连接队列, 而是直接进入Accept全连接队列, 等待应用程序调用 accpet() socket 接口，从「 Accept 队列」取出连接。

请注意，请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为，synccookies是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择，第一个是：tcp_synack_retries 可以用他来减少重试次数；第二个是：tcp_max_syn_backlog，可以增大SYN连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。
```

22.

23.说下TCP的拥塞控制机制

```
慢启动 
拥塞避免
快速重传
快恢复
```

24.

25.什么是Cookie 和 Session?

```
HTTP Cookie是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。

Session是另一种记录客户状态的机制，不同于Cookie保存在客户端浏览器中，而Session保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。每个用户访问服务器都会建立一个Session并自动分配一个SessionId，用于标识用户的唯一身份。
```

26.Cookie 和 Session 有什么不同？

```
作用范围不同，Cookie 保存在客户端（浏览器），Session 保存在服务器端。
存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。
有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。
隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。
存储大小不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie。
```





**操作系统**

1.IO多路复用原理

```
相比于传统的多进程模型和多线程模型面对大量连接时的做法, 即每一个socket连接都用一个进程或者线程来处理, IO多路复用做了一个很大的改变, 就是可以只用一个进程或者线程来监视多个文件描述符, 一旦某个描述符就绪（一般是读就绪或者写就绪），内核能够通知进程进行相应的读写操作。
Linux系统提供了三个用于IO多路复用的系统调用, 即select, poll, epoll, 但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写(将数据从内核缓冲区拷贝至用户缓冲区)，也就是说这个读写过程是阻塞的 ，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。
```

2.select, poll, epoll区别, 底层实现

```
select/poll
select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将需要监视的文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。
所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。

但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。

epoll
epoll 通过两个方面，很好解决了 select/poll 的问题。
第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述符，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是 O(logn)，通过对这棵黑红树进行操作，这样就不需要像 select/poll 每次操作时都传入整个 socket 集合，只需要传入新的待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。

第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 文件描述符上 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有读写事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。epoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。
```

3.进程通信的方式

```
管道(匿名, 有名) ---> 消息队列 ---> 共享内存 ---> 信号量 ---> 信号 --->socket
Linux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。

匿名管道顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有文件实体存在于文件系统中，shell 命令中的「|」竖线就是匿名管道，通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

命名管道突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。

消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。

共享内存可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，它直接分配一个共享空间，每个进程都可以直接访问，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有最快的进程间通信方式之名。但是便捷高效的共享内存通信，带来新的问题，多进程竞争同个共享资源会造成数据的错乱。

那么，就需要信号量来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。

与信号量名字很相似的叫信号，它俩名字虽然相似，但功能一点儿都不一样。信号是进程间通信机制中唯一的异步通信机制，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，这是为了方便我们能在任何时候结束或停止某个进程。

前面说到的通信机制，都是工作于同一台主机，如果要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。

以上，就是进程间通信的主要机制了。你可能会问了，那线程通信间的方式呢？
```

4.为什么一个线程挂掉了其他线程也会挂掉

```
1.进程（主线程）创建了多个线程，多个子线程均拥有自己独立的栈空间（存储函数参数、局部变量等），但是多个子线程和主线程共享堆、全局变量等非栈内存。

2.如果子线程的崩溃是由于自己的一亩三分地引起的，那就不会对主线程和其他子线程产生影响，但是如果子线程的崩溃是因为对共享区域造成了破坏，那么大家就一起崩溃了。3.举个栗子：主线程是一节车厢的乘务员，诸多乘客（也就是子线程）就是经过乘务员（主线程）检票确定可以进入车厢的，也就是主线程创建了诸多子线程，每个子线程有自己独立的区域（座位啊啥的），但是诸多乘客和乘务员共享走廊啊卫生间啊等等，如果其中一名乘客座位坏了，摔了（可以认为奔溃了），那么其他乘客和乘务员都不受影响，但是如果乘客将卫生间给破坏了，他也无法使用卫生间（崩溃了），其他乘客和乘务员也不能用卫生间，好吧，那么大家一起憋着吧（崩溃了）。

总体来说，线程没有独立的地址空间，如果崩溃，会发信号，如果没有错误处理的handler，OS一般直接杀死进程。就算是有handler了处理，一般也会导致程序崩溃，因为很有可能其他线程或者进程的数据被破坏了。
```

5.进程调度算法

```
FCFS --> SJF --> HRRN --> RR --> HPF --> MFQ
进程调度算法:
先来先服务(FCFS)
每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。有利于长作业, 不利于短作业, 适合CPU繁忙型, 不适合IO繁忙型作业的系统

短作业优先(SJF)
优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。长作业长期不会被运行。

高响应比优先(HRRN)
主要是权衡了短作业和长作业。
每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行
优先权 = (等待时间 + 运行时间) / 运行时间

时间片轮转(RR)
最古老、最简单、最公平且使用最广的算法就是时间片轮转, 每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行
时间片过短导致过多的进程上下文切换，降低了 CPU 效率；
时间片过长则退化为FCFS

最高优先级调度算法(HPF)
能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。可能会导致低优先级的进程永远不会运行。

多级反馈队列调度算法(MFQ)
「时间片轮转算法」和「最高优先级算法」的综合和发展。
「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；
对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。


缺页中断:
当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。
页面置换算法:
最佳页面置换算法（OPT） 		置换在「未来」最长时间不访问的页面。
先进先出置换算法（FIFO）       选择在内存驻留时间很长的页面进行中置换
最近最久未使用的置换算法（LRU） 选择最长时间没有被访问的页面进行置换
时钟页面置换算法（Lock）		 
最不常用置换算法（LFU）		当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰
```

6.死锁问题, 解决方案

```
四个条件: 互斥, 持有等待, 不可剥夺, 环路等待

诊断死锁的方法：
1. 超时法: 
2. 等待图法: 对事务创建有向图,事务等待图,系统周期性的生成并检测事务等待图,如果发现图中存在回路,则表示系统中出现了死锁。

死锁的解除方法:
重启: 重新启动死锁进程, 甚至重启操作系统
撤销: 撤销死锁进程, 回收资源, 优先选择占用资源最多或者撤销代价最小的, 撤销一个不行就撤销多个, 直到解除死锁
回滚: 根据系统保存的检查点, 使进程或系统回退到死锁前的状态

解决方案:
互斥无法解决
一次性申请所有的资源, 这样就不会说导致占有了一个或多个，等待着另一个资源的情况了
如果申请不到别的资源, 主动释放自身所拥有的资源
按需申请所需资源,比如A,B线程都需要资源1,资源2, 那么规定一个次序,统一先申请资源1,再申请资源2
```

7.同步和互斥的理解

```
所谓互斥,就是不同线程通过竞争进入临界区（共享的数据和硬件资源）,为了防止访问冲突,在有限的时间内只允许其中之一独占性的使用共享资源。如不允许同时写

同步关系则是多个线程彼此合作,通过一定的逻辑关系来共同完成一个任务。即并发进程/线程在一些关键点上可能需要互相等待与互通消息,这种相互制约的等待与互通信息称为进程/线程同步。
一般来说,同步关系中往往包含互斥,同时对临界区的资源会按照某种逻辑顺序进行访问。如先生产后使用

总的来说,两者的区别就是：
互斥是通过竞争对资源的独占使用,彼此之间不需要知道对方的存在,执行顺序是一个乱序。
同步是协调多个相互关联线程合作完成任务,彼此之间知道对方存在,执行顺序往往是有序的。
```

8.Linux查看CPU负载和进程状态命令

```
top命令
top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的[任务管理器]。
ps命令
ps命令用于报告当前系统的进程状态。ps命令是最基本同时也是非常强大的进程查看命令，使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等，总之大部分信息都是可以通过执行该命令得到的。
free命令
free命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。
```

9.Linux用过哪些命令

```
cd ps free top cat vim rm
mkdir chmod ls 
```

10.操作系统的内存管理是干什么的

```
操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。

如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。
我们程序(包括CPU直接接触的)所使用的内存地址叫做虚拟内存地址（Virtual Memory Address）
实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。
操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：
```

11.为什么要有逻辑地址

```
如果没有逻辑地址, 用户直接使用物理地址的话, 在多个程序运行的情况下, 很容易产生冲突, 造成严重的内存混乱与冲突
所以我们就需要提供一层抽象的逻辑地址,用户不必关心底层的物理地址, 同时结合虚拟内存的思想, 使得每个任务都感觉自己好像拥有整个内存空间一样, 当程序要访问虚拟地址的时候，是由操作系统来将其转换成不同的物理地址，这样不同的进程运行的时候，虽说是用一个逻辑地址, 但实际上写入的是不同的物理地址，这样就不会冲突了。
```

12.操作系统中的虚拟地址转换物理地址的全过程

```
1.段式存储
虚拟地址切分为段选择因子 段内偏移
而段选择因子包括了段号, 特权等标志位, 我们通过段号去段表里面查询可以获得段基地址, 段界限等, 
最后通过段基地址和段内偏移量进行组装得到真正的物理地址

2.页式存储
把虚拟内存地址，切分成页号和偏移量；
根据页号，从页表(页表的起始地址和长度存在于页表寄存器中, 每一个进程被调度的时候, 操作系统就会从PCB中取出页表的起始地址和长度刷新到页表寄存器中)里面，查询对应的物理页号；
直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。
多级页表, 虚拟地址切分为一级页号, 二级页号, 页内偏移

3.段页式存储
先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；
这样，地址结构就由段号、段内页号和页内位移三部分组成。
虚拟地址切分为段号, 段内页号, 页内位移
用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，[段表中存放的的内容是页表的起始地址]，而页表中的地址则为某页的物理页号，
```

13.进程和线程的区别

```
根本区别：进程是操作系统资源分配的基本单位,而线程是处理器任务调度和执行的基本单位
资源开销：每个进程都有独立的代码和数据空间（程序上下文）,程序之间的切换会有较大的开销；线程可以看做轻量级的进程,同一类线程共享代码和数据空间,每个线程都有自己独立的运行栈和程序计数器（PC）,线程之间切换的开销小。
影响关系：一个进程崩溃后,在保护模式下不会对其他进程产生影响,但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。
执行过程:每个独立的进程有一个程序运行的入口、顺序执行序列和程序入口,执行开销大。但是线程不能独立执行,必须依存在应用程序中,由应用程序提供多个线程执行控制,执行开销小。
```

14.进程上下文切换步骤

```
进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。
所以进程上下文切换主要有如下步骤:
1.保存CPU上下文, 包括程序计数器和其他寄存器, 保存至当前进程的PCB中
2.将被替换的进程的PCB移入相应的队列, 如就绪队列, 阻塞队列
3.调度器选择另一个进程执行, 将其PCB中的存储的CPU上下文信息填入, 恢复CPU上下文
4.更新内存管理的数据结构, 刷新TLB快表, 填入该进程页表的起始地址和长度到页表寄存器, 为新进程服务

CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存至进程的PCB中(在内核区, PCB排在各种队列)，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。
系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。
```

15.讲讲fork的整个过程实现

```
当调用fork()系统调用之后, 内核会做这四件事情
1.分配新的内存块和内核数据结构给子进程
2.将父进程部分数据结构内容(数据空间, 堆栈等)拷贝至子进程
3.添加子进程到系统进程列表当中
4.fork返回, 开始调度器调度

但是, Linux中, fork()函数调用采用了读时共享写时复制这一机制, 是由MMU来实现的。
在fork之后两个进程用的是相同的物理空间（内存区），子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。即父子进程在逻辑上仍然是严格相互独立的两个进程，各自维护各自的参数，只是在物理上实现了读时共享，写时复制。 
当进程空间的各段的内容要发生变化时（子进程或父进程进行写操作时，都会引起复制），才会将父进程的内容复制一份给子进程。
```

16.讲讲缺页中断的整个过程, TLB是怎么实现加速的

```
缺页中断:
当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。

整个过程:
在 CPU 里访问一条 Load M 指令，先访问TLB, 如果有的话, 直接访问内存, 没有的话 CPU 会去物理内存中的页表 找 M 所对应的页表项。
如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。
操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置(inode?)。
找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。(如果没有空闲页, 需要执行页面调度算法, 从物理内存中选择一个物理块换出到磁盘中, 同时还要记得刷脏, 即如果该页的修改位为1, 表示该页调入内存之后被修改过, 所以要重新将该页写回磁盘, 使磁盘保留一个最新的副本)
页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。
最后，CPU 重新执行导致缺页异常的指令。

TLB是如何实现加速的:
因为程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件, 所以计算机科学家们在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB. ，通常称为页表缓存, 快表.
在CPU芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果找到了需要的页面, 那么直接到内存中取, 如果没找到，才会继续去内存中查常规的页表, 再进行地址转换工作, 最后再访问内存获取数据。
```

17.讲讲Linux从代码到进程的整个过程, 每一步发生了什么

```

```

18.线程通信的方式

```
1.共享内存
同一个进程中的多个线程, 共享进程堆段, 全局变量区, 代码区等, 通过对  隐式的通信

2.锁机制  
互斥锁, 自旋锁, 自旋锁

3.信号量机制
实现同步互斥

4.信号机制
wait() join()
```

19.虚拟内存的功能

```
虚拟内存提供了三个重要的能力： 缓存，内存管理，内存保护

1. 将主存视为一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据. 因为程序的局部性原理, 将程序一次性装入内存是不必要的, 只要正确的调度, 我们可以保证程序正确无误的执行. 因此, 我们可以将磁盘也就是外存作为内存的补充, 将暂时不需要用到的页面存放在外存中, 以便让其他的大进程可以得到运行, 

2. 为每个进程提供了一致的地址空间，简化内存管理

3. 保护了每个进程的地址空间不被其他进程破坏
```

21.讲讲MMU工作流程

```
MMU内存管理单元完成虚拟内存地址转换成物理地址的工作。
CPU 在寻址时，MMU会先查 TLB，如果命中了，就可以获得物理块号, 然后直接去物理内存中取出页面
如果没找到, 才会去物理内存中继续查常规的页表, 然后进行虚拟地址转换, 然后再访问物理内存, 读出页面。
```

22.操作系统进程与进程间通信有哪些方式？线程与线程间呢？

```
管道(匿名, 有名) ---> 消息队列 ---> 共享内存 ---> 信号量 ---> 信号 --->socket
Linux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。

匿名管道顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「|」竖线就是匿名管道，通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

命名管道突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。

消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。

共享内存可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，它直接分配一个共享空间，每个进程都可以直接访问，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有最快的进程间通信方式之名。但是便捷高效的共享内存通信，带来新的问题，多进程竞争同个共享资源会造成数据的错乱。

那么，就需要信号量来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。

与信号量名字很相似的叫信号，它俩名字虽然相似，但功能一点儿都不一样。信号是进程间通信机制中唯一的异步通信机制，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，这是为了方便我们能在任何时候结束或停止某个进程。

前面说到的通信机制，都是工作于同一台主机，如果要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。

以上，就是进程间通信的主要机制了。你可能会问了，那线程通信间的方式呢？

共享内存, 锁机制, 信号量机制, 信号机制
```

23.用户态是什么, 内核态是什么? 什么时候会发送用户态到内核态的转化

```
当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；反之，当程序运行在0级特权级上时，就可以称之为运行在内核态。

虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序, 只能受限的访问内存，且不允许访问外围设备
 
用户态切换到内核态的3种方式
a. 系统调用
这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统内核提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

b. 异常
当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

c. 中断信号
当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。
```

24.内存管理的方式

```
在计算机发展历程中, 最古老的内存管理方式是分区式内存管理, 比如固定分区式, 可变分区式, 它们都具有一个共同的特点 --- 连续性
每道程序都要占用内存中一块连续的存储区域, 当系统运行一段时间后, 会在内存中产生很多"碎片", 虽然我们可以利用紧凑技术将内存中的"碎片"重新整合再利用, 但是紧凑技术的系统开销是巨大的.
为了解决这一问题, 出现了非连续的内存分配方式, 也叫离散分配方式, 其基本出发点就是打破程序装入的整体性和存储分配的连续性, 将用户进程的逻辑地址空间划分成多个子部分, 以子部分为单位装入物理内存, 这些子部分可以分布在若干非连续的内存块上, 实现了离散存储, 以充分利用内存.内存的非连续分配方式主要包括页式存储管理和段式存储管理两种方式

页式存储管理:
将用户进程的逻辑地址空间划分为大小相等的区, 每个区称为一页或者一个页面, 同时将物理内存也划分成和页大小相等的区, 每个区成为一个物理块(block). Linux系统中, 一页的大小为4kb, 内存分配的基本单位为页, 当装入一个用户程序时, 按页为单位, 每页装入一个物理块中, 一个用户进程装入内存中时, 各个物理块之间不需要连续.在进行内存分配的时候, 操作系统为进入内存的每个用户作业建立一张页表, 页表用来指出逻辑地址中的页号与内存中物理块号的对应关系, 每个在内存中的用户进程都会建立一张页表, 页表的起始地址和长度都存放在进程的PCB中, 只有某一进程被调度运行时, 系统才会从运行进程的PCB中将页表起始地址和长度装入页表寄存器. 
虚拟地址切分为 页号 + 页内偏移, 利用页号可以从页表中找到对应的物理块号, 然后得到物理地址

段式存储管理:
一个程序往往是由是由若干个逻辑分段组成的,如可由代码分段、数据分段、栈段、堆段组成。因此, 我们可以按照程序的逻辑段结构, 将一个程序按段为单位来分配内存, 一段占用一块连续的内存地址空间, 段与段之间不需要连续.
在页式存储管理中, 逻辑地址如何分页用户是不可见的, 连续的逻辑地址空间根据内存物理块的大小自动分页, 而在段式存储管理中, 则是由用户来决定逻辑地址是如何分段的.
虚拟地址切分为 段选择因子 + 段内偏移, 段选择子里面最重要的是段号，用作段表的索引, 

段页式存储管理:
内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。
先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；
这样，地址结构就由段号、段内页号和页内位移三部分组成。
```

25.内存分配的堆区和栈区有什么区别, 分别存储哪些数据, 底层原理是什么?

```
一般对于一个程序来说, 我们可以将它对应的虚拟内存空间划分为5个段, 从低地址到高地址分别是 代码段 数据段 堆段 共享内存段 栈段

栈中存放的内容使程序在需要的时候分配，在不需要的时候自动清楚的变量的存储区。里面的变量通常是局部变量、函数参数等。 
堆中资源由程序员控制（容易产生memory leak）。
栈资源由编译器自动管理，无需手工控制。

系统响应：
   对于堆，应知道系统有一个记录空闲内存地址的链表，当系统收到程序申请时，遍历该链表，寻找第一个空间大于申请空间的堆结点，删除空闲结点链表中的该结点，并将该结点空间分配给程序（大多数系统会在这块内存空间首地址记录本次分配的大小，这样delete才能正确释放本内存空间，另外系统会将多余的部分重新放入空闲链表中）。
   对于栈，只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则报异常提示栈溢出。
   
栈：在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意
思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是2M（也有
的说是1M，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将
提示overflow。因此，能从栈获得的空间较小。
堆：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储
的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小
受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。

栈由系统自动分配，速度较快。但程序员是无法控制的。
堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便.
```

**数据库**

1.数据库的三大范式, 为什么一定要有主键

```
我们可以通俗的将三大范式理解为在设计数据库时需要遵循的规则，它可以有效的帮助我们建立冗余小且结构合理的数据库。
第一范式:
数据库中所有的属性字段都是不可分解的，即我们创建的属性在此字段中一定是你设计表的最小的字段值，遵循数据的原子性

第二范式:
表中的属性字段必须依赖于表的主键

第三范式：
不能出现传递依赖

为什么一定要有主键?
没有主键，更新或删除表中特定行很困难，因为没有安全的方法保证只涉及相关的行。
虽然并不总是都需要主键，但大多数数据库设计人员都应保证他们创建的每个表有一个主键，以便于以后数据操纵和管理
表中的任何列都可以作为主键，只要它满足以下条件：
 1、任何两行都不具有相同的主键值
 2、每个行都必须具有一个主键值（主键列不允许NULL值）
```

2.MySQL的引擎你有什么了解?

```
目前MySQL使用的是InnoDB引擎, 它是一个事务安全的存储引擎, 具备提交, 回滚以及崩溃恢复的功能以保护用户数据. InnoDB的行级锁保证数据一致性的前提下提高了并发性能. InnoDB将用户数据存储在聚簇索引中以减少基于主键的普通查询所带来的I/O开销, 为了保证数据的完整性, InnoDB还支持外键约束, 默认使用B+ Tree数据结构存储索引.
在MySQL5.0版本之前, 使用的是MyISAM引擎, 它不支持事务, 也不支持外键, 其优势是访问速度快, 但是表级别的锁定限制了他在读写负载方面的性能, 因此它经常应用于只是读或者以读为主的数据场景, 默认使用B+树结构存储索引.
```

3.说一下InnoDB存储引擎和MyISAN存储引擎的区别

```
InnoDB:
支持事务, 支持4个事务隔离级别
行级锁定(更新时锁定当前行)
读写阻塞与事务隔离级别有关
既能缓存索引又能缓存数据
支持外键

MyISAM:
不支持事务
表级锁定(更新时锁定整个表)
读写互相阻塞(写入时阻塞读入, 读时阻塞写入, 但是读不会互相阻塞)
只能缓存索引, 不会缓存数据
不支持外键
读取速度快
```

4.对聚簇索引了解吗?

```
InnoDB 存储引擎根据索引类型不同，分为聚簇索引和二级索引。它们区别在于，聚簇索引的叶子节点存放的是实际数据，所有完整的用户数据都存放在聚簇索引的叶子节点，找到了索引也就找到了数据. 而二级索引的叶子节点存放的是主键值，而不是实际数据。所以如果我们使用二级索引列作为查询条件, 如果要查询的数据都在「聚簇索引」的叶子节点里，那么需要检索两颗B+树.
在创建表时，InnoDB 存储引擎默认会创建一个主键索引，也就是聚簇索引，且一张表只允许存在一个聚簇索引。其它索引都属于二级索引。
如果没有定义主键, 那么存储引擎会自动选择第一列唯一且不为空的列作为聚簇索引, 如果没有主键也没有合适的唯一索引，那么innodb内部会生成一个隐藏的主键作为聚集索引
```

5.了解慢SQL吗？ 一条SQL语句是如何执行的?

```
运行时间较长的SQL即为慢SQL, MySQL慢查询，是运行时间超过long_query_time值的SQL。
SQL运行快慢是一个相对的概念，不同的业务场景下要求不同，慢SQL的标准也就不同。
MySQL中long_query_time参数定义了SQL运行阈值，默认为10s，可通过设置该阈值来调整基准。

一条SQL语句的执行过程:
如上图所示，一条SQL语句执行时，分为以下几步：
1. 若查询缓存打开则会优先查询缓存，若命中则直接直接返回结果给客户端。
2. 若缓存未命中，此时MySQL需要搞清楚这条语句需要做什么，则通过分析器进行词法分析、语法分析。
3. 搞清楚要做什么之后，MySQL需要通过优化器进行优化执行计划。
4. 最后通过执行器与存储引擎提供的接口进行交互，将结果返回给客户端。
```

6.说一说EXPLAIN

```
MySQL 提供了一个 EXPLAIN 命令，它可以对 SQL 语句进行分析，并输出 SQL 执行的详细信息，以供开发人员针对性优化.
主要关注的字段:
type: 
这是最重要的字段之一，显示s何种类型. 比如ALL表示使用的全表扫描, 这是性能最差的, index 表示对索引进行了把索引从头到尾扫一遍, range表示索引范围查询
possible_keys:
可能会使用到的索引会在这里列出来
key:
查询真正使用到的索引
rows:
这是MySQL估算的需要扫描的行数, 这个值直观的显示了SQL的效率好坏, 原则上rows越少越好
extra:
EXPLAIN中的很多额外信息会在extra字段显示出来, 比如Using index
"覆盖索引扫描", 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错 Using temporary查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化.
```

7.ACID是什么?C的具体含义, 如何保证?

```
ACID
A(Atomicity): 
事物的原子性, 指一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，如果事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样；

C(Consistency): 
指事务的执行并不改变数据库中数据的一致性. 例如, 完整性约束了 a+b=10, 在一个事务中改变了a, 那么b也应该随之改变

I(Isolation): 
事物的独立性也称作隔离性, 是指两个以上的事务不会出现交错执行的状态, 因为这样可能会导致数据不一致.

D(Durability): 
事务的持久性是指事务执行成功以后, 该事务对数据所做的更改是持久的保存在数据库之中, 不会无缘无故的回滚.

数据库通过原子性（A）、隔离性（I）、持久性（D）来保证一致性（C）。其中一致性是目的，原子性、隔离性、持久性是手段。因此数据库必须实现AID三大特性才有可能实现一致性。
```

8.MVCC了解吗?原理是什么

```
MVCC即多版本并发控制, 数据库隔离级别读已提交、可重复读 都是基于MVCC实现的，相对于加锁简单粗暴的方式，它用更好的方式去处理读写冲突，能有效提高数据库并发性能。

通俗的讲，数据库中同时存在多个版本的数据，并不是整个数据库的多个版本，而是某一条记录的多个版本同时存在，这些旧版本都存放在undo log中. InnoDB存储引擎中每一条记录都有两个隐藏列, 一个是trx_id, 记录了最近一次修改本条记录的事务ID, 一个是roll_ptr, 指向undo_log中的旧版本记录, 这些旧版本记录通过链表连接起来, 可以通过roll_ptr可以找到修改前的记录。

Read View 在 MVCC中如何工作的?
在可重复读和读已提交隔离级别下, MVCCRead View 来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，称为实时读. 而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View, 称为快照读.

Read View中包含了四个字段, 比如当前本事务ID, read view创建时的其余活跃事务id列表(活跃事务”指的就是，启动了但还没提交的事务。), 活跃事务id中最小的id, 以及创建Read View时应当给下一个事务的id.

一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：
如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。
如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。
如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：
如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。
如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。

根据不同的隔离级别, 生成Read View的时机不同, 因此造成的效果也不同
```

9.如果给你一个3阶B+树, 每行数据的大小为1KB, 那么B+树能存储多少个数据?

```
大概2000多万条数据
因为InnoDB存储引擎的最小存储单位是页, 为16kb, 页可以用于存放数据也可以用于存放键值+指针，在B+树中叶子节点存放数据，非叶子节点存放键值+指针。索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而在去数据页中查找到需要的数据；

假设这里我们先假设B+树高为2，即存在一个根节点和若干个叶子节点，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数。

上文我们已经说明单个叶子节点（页）中的记录数=16K/1K=16。（这里假设一行记录的数据大小为1k，实际上现在很多互联网业务数据记录大小通常就是1K左右）。

那么现在我们需要计算出非叶子节点能存放多少指针，其实这也很好算，我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即16384/14=1170。那么可以算出一棵高度为2的B+树，能存放1170*16=18720条这样的数据记录。

根据同样的原理我们可以算出一个高度为3的B+树可以存放：1170*1170*16=21902400(2000多万)条这样的记录。所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时 一次页的查找代表一次IO， 所以通过主键索引查询通常 只需要1-3次IO操作 即可查找到数据。
```

10.索引, 联合索引, 最左原则

```
索引是帮助MySQL高效获取数据的数据结构.索引是对数据库表中一列或多列的值进行排序的一种结构。MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度
简单类比一下, 简单类比一下，数据库如同书籍，索引如同书籍目录，假如我们需要从书籍查找与 xx 相关的内容，我们可以直接从目录中查找，定位到 xx 内容所在页面，如果目录中没有 xx 相关字符或者没有设置目录（索引），那只能逐字逐页阅读文本查找，效率可想而知。

多个普通字段组合在一起创建的索引就叫做联合索引，也叫组合索引. 只会构建出一棵索引树, 每个节点的键值不是单个的, 而是组合值.
字典排序

最左匹配原则, 在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。
也就是说，如果我们想使用联合索引中尽可能多的列，查询条件中的各个列必须是联合索引中从最左边开始连续的列。如果我们仅仅按照第二列搜索，肯定无法走索引  
```

11.事务的隔离级别, 具体展开讲讲

```
读未提交 读已提交 可重复读 串行化
安全性越来越高, 并发程度越来越低
读未提交隔离级别什么问题都没有解决, 它会发生读脏数据, 不可重复读, 幻读问题.
读已提交解决了脏读问题, 未解决不可重复读和幻读问题
可重复读隔离级别解决了脏读和不可重复读问题, 它是MySQL默认的隔离级别, 对于幻读问题, 使用next_key_lock解决
串行化三个问题都解决了, 但是使得数据库的并发性能大大降低, 一般不使用.
```

12.200w数据放数据库中层数多高

```
3层
因为InnoDB存储引擎中最小的存储单位为页, 一页默认16KB, 如果我们的一行数据大小为1KB, 那么一页就可以存放16条数据.
因为InnoDB存储引擎使用的是B+树来存储数据, 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引, 假如我们的主键为BigInt, 占8位, 对应的指针默认占6位, 那么一页可以存放 16KB / 14 = 1170, 所以会有1170子节点, 1170 * 16 =  两层不够
三层
```

13.数据库加锁的系统调用是什么?

```

```

14.行锁在什么情况下出现

```
只有通过索引条件检索数据，InnoDB才会使用行级锁，否则，InnoDB将使用表锁
在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。
————————————————

行级锁的类型主要有三类：
Record Lock，记录锁，也就是仅仅把一条记录锁上；		
Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；	 (左开右开)
Next-Key Lock：临键锁, Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。 (左开右闭)
```

15.联合索引是怎么存放在磁盘上的

```
我们创建了一个联合索引（b，c，d）也会生成一个索引树，同样是B+树的结构，只不过它的data部分存储的是联合索引所在行的主键值. 对于联合索引，存储引擎会首先根据第一个索引列排序，如上图我们可以单看第一个索引列，如，1 1 5 12 13....他是单调递增的；如果第一列相等则再根据第二列排序，依次类推就构成了上图的索引树，上图中的1 1 4 ，1 1 5以及13 12 4,13 16 1,13 16 5就可以说明这种情况。
字典排序
```

16.B树和B+树的区别

```
MySQL 默认的存储引擎 InnoDB 采用的是 B+ 树作为索引的数据结构，原因有：

B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比既存储索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的时候磁盘 I/O次数会更少。(相同的数据量，B+树更矮壮，也是就说，相同的数据量，B+树数据结构，查询磁盘的次数会更少。)
B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。
```





**项目**

```

```

**C++**

1.C++ 11的新特性

```
C++新特性主要包括包含语法改进和标准库扩充两个方面
语法的改进
（1）统一的初始化方法
（2）成员变量默认初始化
（3）auto关键字 用于定义变量，编译器可以自动判断的类型（前提：定义一个变量时对其进行初始化）
（4）decltype 求表达式的类型
（5）智能指针 shared_ptr
（6）空指针 nullptr（原来NULL）
（7）基于范围的for循环 
（8）右值引用和move语义 让程序员有意识减少进行深拷贝操作

标准库扩充（往STL里新加进一些模板类，比较好用）
（9）无序容器（哈希表） 用法和功能同map一模一样，区别在于哈希表的效率更高
（10）正则表达式 可以认为正则表达式实质上是一个字符串，该字符串描述了一种特定模式的字符串
（11）Lambda表达式
```

