### 美团一面面经

---

1.自我介绍

2.听你说到项目用到了压力测试, 说一说

```
Webbench 是 Linux 上一款知名的、优秀的 web 性能压力测试工具。
基本原理：Webbench 首先 fork 出多个子进程, 在每个子进程都循环做 web 访问测试。子进程把访问的
		结果通过pipe 告诉父进程,父进程做最终的统计结果。
测试用例: webbench -c 1000 -t 30 http://192.168.110.129:10000/index.html  
		参数：-c 表示客户端数 -t 表示时间
```

3.进程和线程的区别

```
根本区别：进程是操作系统资源分配的基本单位,而线程是处理器任务调度和执行的基本单位
资源开销：每个进程都有独立的代码和数据空间（程序上下文）,程序之间的切换会有较大的开销；线程可以看做轻量级的进程,同一类线程共			享代码和数据空间,每个线程都有自己独立的运行栈和程序计数器（PC）,线程之间切换的开销小。
影响关系：一个进程崩溃后,在保护模式下不会对其他进程产生影响,但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。
执行过程:每个独立的进程有一个程序运行的入口、顺序执行序列和程序入口,执行开销大。但是线程不能独立执行,必须依存在应用程序中,由		应用程序提供多个线程执行控制,执行开销小。
```

4.为什么用线程池?

```
使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销,解决资源不足的问题。如果不使用线程池,有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。线程池里会维护一部分活跃线程,如果有需要,就直接去线程池里取线程使用,用完即归还到线程池里,免去了创建和销毁线程的开销,从而实现对创建的线程进行复用且线程池也会线程的数量有一定的限制。
这些资源都是在服务端启动之初就已经加载好的, 我们称之为静态资源.

推荐使用如下的回答:
池化技术在开发中比较常见,比如线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗,提高对资源的利用率。线程池就是池化思想的一个很好利用,它的好处我认为有三点:
1.降低资源消耗。通过重复利用已创建的线程降低线程动态创建和销毁造成的消耗。
2.提高响应速度。当任务到达时,任务可以不需要等到线程创建就能立即执行, 减少了创建线程这段时间的开销。
3.提高线程的可管理性。线程是稀缺资源,如果无限制的创建,不仅会消耗系统资源,还会降低系统的稳定性,使用线程池可以进行统一的分配,调优和监控。
```

5.创建一个线程需要哪些开销?   **寄**

```
因为线程是共享它所属进程的一些资源, 比如代码段, 数据段, 一些公有数据等, 所以创建一个线程只需要分配给他一些必不可少的资源, 比如堆栈段要划分给一个新的线程, 还会分配给他一组寄存器. 
```

6.多线程 多进程? 为什么用多线程, 优势是什么   **寄**

```
花销小, 切换快.  方便的通信机制
使用多线程的理由之一是和进程相比,它是一种非常花销小,切换快,更"节俭"的多任务操作方式。在Linux系统下,启动一个新的进程必须分配给它独立的地址空间,建立众多的数据表来维护它的代码段、堆栈段和数据段,这是一种"昂贵"的多任务工作方式。而运行于一个进程中的多个线程,它们彼此之间使用相同的地址空间,共享大部分数据,启动一个线程所花费的空间远远小于启动一个进程所花费的空间,而且,线程间彼此切换所需的时间也远远小于进程间切换所需要的时间。

使用多线程的理由之二是线程间方便的通信机制。对不同进程来说,它们具有独立的数据空间,要进行数据的传递只能通过通信的方式进行,这种方式不仅费时,而且很不方便。线程则不然,由于同一进程下的线程之间共享数据空间,所以一个线程的数据可以直接为其它线程所用,这不仅快捷,而且方便。
```

7.进程状态模型

```
三态模型  五态模型  七态模型
```

8.说一说线程安全, 怎么保证线程安全		**寄中寄**

```
线程安全是多线程领域的问题，线程安全可以简单理解为一个方法或者一个实例可以在多线程环境中使用而不会出现问题.在拥有共享数据的多条线程并行执行的程序中，线程安全的代码会通过同步机制保证各个线程都可以正常且正确的执行，不会出现数据污染等意外情况。

在并发执行的环境中,对于共享数据通过同步机制保证各个线程都可以正确的执行,不会出现数据污染的情况,或者对于某个资源,在被多个线程访问时,不管运行时执行这些线程有什么样的顺序或者交错,都不会出现错误的行为,就认为这个资源是线程安全的.
一般来说,对于某个资源如果只有读操作,则这个资源无需同步就是线程安全的,若有多个线程进行读写操作,则需要线程同步来保证线程安全。

一般通过同步机制来保证线程安全
```

9.信号量和锁啥区别   有哪几种锁  说一说  互斥,同步   **寄中寄**

```
信号量: 用于实现多线程的同步问题,一个线程完成了某一个动作就通过信号量告诉别的线程,别的线程再进行某些动作.是服务于多个线程间的		执行的逻辑顺序的,即调度线程。
锁: 用于实现从多线程开发中的互斥问题.一个线程占用了某一个资源,那么别的线程就无法访问,直到这个线程unlock,其他的线程才开始可	     以利用这个资源。

信号量(semaphore)用在多线程多任务同步的,一个线程完成了某一个动作就通过信号量告诉别的线程,别的线程再进行某些动作。而互斥锁(Mutual exclusion,缩写 Mutex)是用在多线程多任务互斥的,一个线程占用了某一个资源,那么别的线程就无法访问,直到这个线程unlock,其他的线程才开始可以利用这个资源。比如对全局变量的访问,有时要加锁,操作完了,在解锁。尽管两个概念有点类似,但是他们的侧重点不一样,信号量不一定是锁定某一个资源,而是流程上的概念,比如：有A,B两个线程,B线程要等A线程完成某一任务以后再进行自己下面的步骤,这个任务并不一定是锁定某一资源,还可以是进行一些计算或者数据处理之类。而线程互斥量则是“锁住某一资源”的概念,在锁定期间内,其他线程无法对被保护的数据进行操作。
不难看出,mutex是semaphore的一种特殊情况（n=1时）。也就是说,完全可以用后者替代前者。但是,因为mutex较为简单,且效率高,所以在必须保证资源独占的情况下,还是采用这种设计。


所谓互斥,就是不同线程通过竞争进入临界区（共享的数据和硬件资源）,为了防止访问冲突,在有限的时间内只允许其中之一独占性的使用共享资源。如不允许同时写

同步关系则是多个线程彼此合作,通过一定的逻辑关系来共同完成一个任务。即并发进程/线程在一些关键点上可能需要互相等待与互通消息,这种相互制约的等待与互通信息称为进程/线程同步。
一般来说,同步关系中往往包含互斥,同时对临界区的资源会按照某种逻辑顺序进行访问。如先生产后使用

总的来说,两者的区别就是：
互斥是通过竞争对资源的独占使用,彼此之间不需要知道对方的存在,执行顺序是一个乱序。
同步是协调多个相互关联线程合作完成任务,彼此之间知道对方存在,执行顺序往往是有序的。
```

10.什么是死锁

```
是指两个或两个以上的进程（或线程）在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁
```

11.避免死锁的方法, 出现死锁的几个条件    **寄中寄**

```
出现死锁的几个条件:
1.互斥条件  
	多个线程不能同时使用同一个资源。
	比如一个线程 A 已经持有的资源,不能再同时被线程 B 持有,如果线程 B 请求获取线程 A 已经占用的	  资源,那线程 B 只能等待,直到线程 A 释放了资源。
2.持有等待条件
	进程在申请新的资源的同时,保持对原有资源的占有.
	比如线程 A 已经持有了资源 1,又想申请资源 2,而资源 2 已经被线程 B 持有了,所以线程 A 就会处于等待状态,但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 
3.不可剥夺条件
	资源申请者不能强行从资源占有者手中夺取资源,资源只能由占有者自愿释放
	当线程已经持有了资源 ,在自己使用完之前不能被其他线程获取,线程 B 如果也想使用此资源,则只能在线程 A 使用完并释放后才能获	取。
4.环路等待条件
	在死锁发生的时候,两个线程获取资源的顺序构成了环形链。
	
避免死锁的方法:
对于以上 4 个条件,只要破坏其中一个条件,就可以避免死锁的发生。
对于第一个条件 "互斥" 是不能破坏的,因为加锁就是为了保证互斥。
其他三个条件,我们可以尝试
1.一次性申请所有的资源,这样就不会说导致占有了一个或多个，等待着另一个的情况了  破坏"持有等待" 条件
2.占有部分资源的线程进一步申请其他资源时,如果申请不到, 主动释放它占有的资源, 破坏 "不可剥夺" 条件
3.按序申请资源, 比如上述例子，让两个线程都先争夺资源s1，再争夺资源s2.破坏 "循环等待" 条件
```

12.说一说活锁   **寄中寄中寄**

```
活锁: 
多线程中出现了相互谦让,都主动将资源释放给别的线程使用,这样资源在多个线程之间跳动而又得不到执行,形成活锁。活锁是加不上锁就放开已获得的资源重试
活锁恰恰与死锁相反,死锁是大家都拿不到资源却又都占用着对方的资源,而活锁是可以拿到资源却又相互释放不执行。当多线程中出现了相互谦让,都主动将资源释放给别的线程使用,这样这个资源在多个线程之间跳动而又得不到执行,这就是活锁。
活锁同样会发生在多个相互协作的线程间，当他们为了彼此间的响应而相互礼让，使得没有一个线程能够继续前进，那么就发生了活锁。
好比两个过于礼貌的人在半路相遇，出于礼貌他们相互礼让，避开对方的路，但是在另一条路上又相遇了。就这样，不停地一直避让下去

解决办法:
解决活锁的一个简单办法就是在下一次尝试获取资源之前,随机休眠一小段时间。


死锁: 
是指两个或两个以上的进程（或线程）在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁

死锁的预防:
见上 破坏四个条件


诊断死锁的方法：
1. 超时法: 
2. 等待图法: 对事务创建有向图,事务等待图,系统周期性的生成并检测事务等待图,如果发现图中存在回路,则表示系统中出现了死锁。

死锁的解除方法:
重启: 重新启动死锁进程, 甚至重启操作系统
撤销: 撤销死锁进程, 回收资源, 优先选择占用资源最多或者撤销代价最小的, 撤销一个不行就撤销多个, 直到解除死锁
回滚: 根据系统保存的检查点, 使进程或系统回退到死锁前的状态


饥饿:
饥饿是指一个或者多个线程因为种种原因始终无法获得所需要的资源,导致一直无法执行的状态。
通常来说, 这个线程优先级很低. 优先级高的线程能够插队并优先执行,这样如果优先级高的线程一直抢占优先级低线程的资源,导致低优先级线程无法得到执行,这就是饥饿。与死锁不同的是饥饿在以后一段时间内还是能够得到执行的,如那个占用资源的线程结束了并释放了资源。
死锁进程等待永远不会被释放的资源,饿死进程等待会被释放但却不会分配给自己的资源,表现为等待时限没有上界.死锁一定涉及多个进程,而饥饿或被饿死的进程可能只有一个.
饥饿和饿死与资源分配策略有关,因而防止饥饿与饿死可从公平性考虑,确保所有线程不被忽视,如FCFS分配算法。
```

13.说一下Linux的常用命令

14.内存泄漏和内存溢出  (虚拟内存空间)

```
内存泄漏:
由于疏忽或错误造成程序未能释放已经不再使用的 内存 。. 内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，导致在释放该段内存之前就失去了对该段内存的控制，从而造成了内存的浪费。一般是发生在程序中已动态分配的堆内存, 如new了一个对象, 之后忘记了释放, 结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给需要的程序。
内存溢出:
内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory；比如申请了一个integer,但给它存了long才能存下的数，那就是内存溢出。
内存溢出就是你要求分配的内存超出了系统能给你的，系统不能满足需求，于是产生溢出。stackOverflow
```

15.介绍一下索引 B+树, B树  说一说区别    (B+树节点大, 开销为什么大)   **寄中寄中寄**

```
索引是帮助MySQL高效获取数据的数据结构.索引是对数据库表中一列或多列的值进行排序的一种结构。MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度
简单类比一下, 数据库如同书籍，索引如同书籍目录，假如我们需要从书籍查找与 xx 相关的内容，我们可以直接从目录中查找，定位到 xx 内容所在页面，如果目录中没有 xx 相关字符或者没有设置目录（索引），那只能逐字逐页阅读文本查找，效率可想而知。


MySQL 默认的存储引擎 InnoDB 采用的是 B+树 作为索引的数据结构，原因有：

B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比既存储索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的时候磁盘 I/O次数会更少。(相同的数据量，B+树更矮壮，也是就说，相同的数据量，B+树数据结构，查询磁盘的次数会更少。) 3阶的B+树就可以存放千万级的数据
B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
B+ 树叶子节点之间用双向链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。
```

16.事务隔离级别, 并说明分别解决了什么问题   

17.事务的ACID特性

```
ACID
A(Atomicity): 
事物的原子性, 指一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，如果事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样；

C(Consistency): 
指事务执行前后并不改变数据库中数据的一致性. 例如, 完整性约束了 a+b=10, 在一个事务中改变了a, 那么b也应该随之改变

I(Isolation): 
事物的独立性也称作隔离性, 是指两个以上的事务不会出现交错执行的状态, 因为这样可能会导致数据不一致.

D(Durability): 
事务的持久性是指事务执行成功以后, 该事务对数据所做的更改是持久的保存在数据库之中, 不会无缘无故的回滚.
```

18.说一下GET 和 POST, 二者之间的差别  	**寄中寄**

```
GET - 从指定的资源请求数据
POST - 向指定的资源提交要被处理的数据。

白话:
根据 RFC 规范,GET 的语义是从服务器获取指定的资源,这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中,URL 规定只能支持 ASCII,所以 GET 请求的参数只允许 ASCII 字符 ,而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。
根据 RFC 规范,POST 的语义是根据请求负荷（报文body）对指定的资源做出处理,具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中, body 中的数据可以是任意格式的数据,只要客户端与服务端协商好即可,而且浏览器不会对 body 大小做限制。
另一个呢, GET 方法就是安全且幂等的,因为它是「只读」操作,无论操作多少次,服务器上的数据都是安全的,且每次的结果都是相同的。所以,浏览器可以对 GET 请求的数据做缓存,POST 因为是「新增或提交数据」的操作,会修改服务器上的资源,所以是不安全的,且多次提交数据就会创建多个资源,所以不是幂等的。所以,浏览器一般不会缓存 POST 请求,也不能把 POST 请求保存为书签。
```

19.三次握手可以改成两次吗?

```
我认为TCP三次握手主要有两个原因,首要原因是为了防止历史连接初始化造成混乱和资源浪费, 其次是为了同步双方的起始序列号.
对于第一个原因, 
我们考虑这样的情况,假设客户端先发了一个序列号为90的SYN请求报文, 但是它在网络中某个节点被阻塞了, 然后客户端又发送了另一个新的SYN请求报文, 序列号为100, 但是旧的请求报文比新的先到达服务端, 然后服务端回返回一个SYN ACK报文, 其中ack确认号为91, 这显示是错的, 客户端收到该ACK报文之后, 发现确认号为91而不是101, 判定这是一个历史连接, 客户端就发送一个RST报文回去告知服务端, 终止这次连接.
如果没有第三次握手, 那么服务端在接收到请求报文之后立刻建立连接, 没有等待客户端的确认, 那么显然会出现混乱和资源浪费.
第二个原因就是, 
TCP 协议的通信双方， 都必须维护一个「序列号」， 以标识发送出去的数据包中, 哪些是已经被对方收到的。序列号是可靠传输的一个关键因素. 序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。
两次不可靠, 四次不高效
```

19.算法题: 

- [剑指 Offer 58 - I. 翻转单词顺序](https://leetcode-cn.com/problems/fan-zhuan-dan-ci-shun-xu-lcof/)
- [爬楼梯](https://leetcode-cn.com/problems/climbing-stairs/)

20.聊职业规划, 个人的优势, 向往的企业



### 总结

---

语气词太多了, "然后那个, 就是"语气词说的太多, 太紧张了

八股文准备不充分

算法题 没说的, 多写就完事了



### 拓展

---

21. 互斥锁和自旋锁

```
互斥锁加锁失败后,线程会释放 CPU ,自己由运行态切换到阻塞态, 将CPU资源分配给其他线程；
自旋锁加锁失败后,线程会忙等待, 仍旧是处于运行态, 不会释放CPU资源, 直到它拿到锁；

线程的上下文切换的是什么？当两个线程是属于同一个进程,因为虚拟内存是共享的,所以在切换时,虚拟内存这些资源就保持不动,只需要切换线程的私有数据、寄存器等不共享的数据。

上下切换的耗时有大佬统计过,大概在几十纳秒到几微秒之间,如果你锁住的代码执行时间比较短,那可能上下文切换的时间都比你锁住的代码执行时间还要长。所以,如果你能确定被锁住的代码执行时间很短,就不应该用互斥锁,而应该选用自旋锁,否则使用互斥锁。

自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap）,在「用户态」完成加锁和解锁操作,不会主动产生线程上下文切换,所以相比互斥锁来说,会快一些,开销也小一些。
自旋锁是最比较简单的一种锁,一直自旋,利用 CPU 周期,直到锁可用。需要注意,在单核 CPU 上,需要抢占式的调度器（即不断通过时钟中断一个线程,运行其他线程）。否则,自旋锁在单 CPU 上无法使用,因为一个自旋的线程永远不会放弃 CPU。

自旋锁与互斥锁使用层面比较相似,但实现层面上完全不同：当加锁失败时,互斥锁用「线程切换」来应对,自旋锁则用「忙等待」来应对。
它俩是锁的最基本处理方式,更高级的锁都会选择其中一个来实现
```

22. 乐观锁和悲观锁

```
前面提到的互斥锁、自旋锁、读写锁,都是属于悲观锁。

悲观锁做事比较悲观,它认为多线程同时修改共享资源的概率比较高,于是很容易出现冲突,所以访问共享资源前,先要上锁。

那相反的,如果多线程同时修改共享资源的概率比较低,就可以采用乐观锁。

乐观锁做事比较乐观,它假定冲突的概率很低,它的工作方式是：先修改完共享资源,再验证这段时间内有没有发生冲突,如果没有其他线程在修改资源,那么操作完成,如果发现有其他线程已经修改过这个资源,就放弃本次操作。
可见,乐观锁的心态是,不管三七二十一,先改了资源再说。另外,你会发现乐观锁全程并没有加锁,所以它也叫无锁编程。
乐观锁虽然去除了加锁解锁的操作,但是一旦发生冲突,重试的成本非常高,所以只有在冲突概率非常低,且加锁成本非常高的场景时,才考虑使用乐观锁。(例子, 共享文档)
```

23.说一说锁

```
多线程开发过程中,最常见的就是互斥锁的了,互斥锁加锁失败时,会用「线程切换」来应对,当加锁失败的线程再次加锁成功后的这一过程,会有两次线程上下文切换的成本,性能损耗比较大。

如果我们明确知道被锁住的代码的执行时间很短,那我们应该选择开销比较小的自旋锁,因为自旋锁加锁失败时,并不会主动产生线程切换,而是一直忙等待,直到获取到锁,那么如果被锁住的代码执行时间很短,那这个忙等待的时间相对应也很短。

如果能区分读操作和写操作的场景,那读写锁就更合适了,它允许多个读线程可以同时持有读锁,提高了读的并发性。根据偏袒读方还是写方,可以分为读优先锁和写优先锁,读优先锁并发性很强,但是写线程会被饿死,而写优先锁会优先服务写线程,读线程也可能会被饿死,那为了避免饥饿的问题,于是就有了公平读写锁,它是用队列把请求锁的线程排队,并保证先入先出的原则来对线程加锁,这样便保证了某种线程不会被饿死,通用性也更好点。

互斥锁和自旋锁都是最基本的锁,读写锁可以根据场景来选择这两种锁其中的一个进行实现。

另外,互斥锁、自旋锁、读写锁都属于悲观锁,悲观锁认为并发访问共享资源时,冲突概率可能非常高,所以在访问共享资源前,都需要先加锁。

相反的,如果并发访问共享资源时,冲突概率非常低的话,就可以使用乐观锁,它的工作方式是,在访问共享资源时,不用先加锁,修改完共享资源后,再验证这段时间内有没有发生冲突,如果没有其他线程在修改资源,那么操作完成,如果发现有其他线程已经修改过这个资源,就放弃本次操作。

但是,一旦冲突概率上升,就不适合使用乐观锁了,因为它解决冲突的重试成本非常高。

不管使用的哪种锁,我们的加锁的代码范围应该尽可能的小,也就是加锁的粒度要小,这样执行速度会比较快。再来,使用上了合适的锁,就会快上加快了。
```

24.说一说页式存储管理和段式存储管理

```
在计算机发展历程中, 最古老的内存管理方式是分区式内存管理, 比如固定分区式, 可变分区式, 它们都具有一个共同的特点 --- 连续性
每道程序都要占用内存中一块连续的存储区域, 当系统运行一段时间后, 会在内存中产生很多"碎片", 虽然我们可以利用紧凑技术将内存中的"碎片"重新整合再利用, 但是紧凑技术的系统开销是巨大的.
为了解决这一问题, 出现了非连续的内存分配方式, 也叫离散分配方式, 其基本出发点就是打破程序装入的整体性和存储分配的连续性, 将用户进程的逻辑地址空间划分成多个子部分, 以子部分为单位装入物理内存, 这些子部分可以分布在若干非连续的内存块上, 实现了离散存储, 以充分利用内存.内存的非连续分配方式主要包括页式存储管理和段式存储管理两种方式

页式存储管理:
将用户进程的逻辑地址空间划分为大小相等的区, 每个区称为一页或者一个页面, 同时将物理内存也划分成和页大小相等的区, 每个区成为一个物理块(block). Linux系统中, 一页的大小为4kb, 内存分配的基本单位为页, 当装入一个用户程序时, 按页为单位, 每页装入一个物理块中, 一个用户进程装入内存中时, 各个物理块之间不需要连续.在进行内存分配的时候, 操作系统会为进入内存的每个用户作业建立一张页表, 页表用来指出逻辑地址中的页号与内存中物理块号的对应关系, 每个在内存中的用户进程都会建立一张页表, 页表的起始地址和长度都存放在进程的PCB中, 只有某一进程被调度运行时, 系统才会从运行进程的PCB中将页表起始地址和长度装入页表寄存器.

段式存储管理:
一个程序往往是由是由若干个逻辑分段组成的,如可由代码分段、数据分段、栈段、堆段组成。因此, 我们可以按照程序的逻辑段结构, 将一个程序按段为单位来分配内存, 一段占用一块连续的内存地址空间, 段与段之间不需要连续.
在页式存储管理中, 逻辑地址如何分页用户是不可见的, 连续的逻辑地址空间根据内存物理块的大小自动分页, 而在段式存储管理中, 则是由用户来决定逻辑地址是如何分段的.
```

25.说一说TLB

```
多级页表虽然解决了空间上的问题,但是虚拟地址到物理地址的转换就多了几道转换的工序,这显然就降低了这俩地址转换的速度,也就是带来了时间上的开销。

程序是有局部性的,即在一段时间内,整个程序的执行仅限于程序中的某一部分。相应地,执行所访问的存储空间也局限于某个内存区域。我们就可以利用这一特性,把最常访问的几个页表项存储到访问速度更快的硬件,于是计算机科学家们,就在 CPU 芯片中,加入了一个专门存放程序最常访问的页表项的 Cache,这个 Cache 就是 TLB（Translation Lookaside Buffer） ,通常称为页表缓存、转址旁路缓存、快表等。

在 CPU 芯片里面,封装了内存管理单元（Memory Management Unit）芯片,它用来完成地址转换和 TLB 的访问与交互。
有了 TLB 后,那么 CPU 在寻址时,会先查 TLB,如果没找到,才会继续查常规的页表。TLB 的命中率其实是很高的,因为程序最常访问的页就那么几个。
```

26.说一说程序的局部性原理和虚拟存储

```
程序的局部性原理: 即在一段时间内, 整个程序的执行仅限于程序中的某一部分, 相应的, 执行所访问的存储空间也局限于某一个内存区域.局部性原理表现在时间局部性和空间局部性.
程序的局部性说明, 程序的一次性装入内存与全部驻留内存都是不必要的, 只装入一部分的假设是合理的, 只要操作系统调度得当, 不仅程序可以正确运行, 而且可以在内存中装入更多程序, 充分利用处理器和内存空间.

虚拟存储技术的思想是: 将外存作为内存的补充, 因为作业运行时不需要将作业的全部信息放入内存, 将暂时不需要用到的作业信息存放在外存, 通过内存与外存的兑换, 使系统逐步将作业信息放入内存, 最终能够达到运行整个作业, 从逻辑上扩充内存的目的.
```

27.说一说键入网址到网页显示, 期间发生了什么

```
1.URL解析
首先浏览器做的第一步工作就是要对 URL 进行解析,判断你输入的是一个合法的 URL ,并且根据你输入的内容进行自动补全、字符编码等操作。浏览器还会进行一些额外的操作,比如安全检查、访问限制, 比如有时候需要强制使用HTTPS协议而不能使用HTTP协议.
接着从处理过的URL中提取出域名, 然后开始进行第二步 --- DNS查询

2.DNS查询
DNS查询就是寻找哪台机器上有我们所需要资源的过程. 就是将域名 映射到 具体的IP地址的过程
...
所以DNS根据域名查询IP地址的过程为：浏览器缓存 --> 操作系统缓存(本地Hosts文件) --> 路由器缓存-->本地（ISP）域名服务器缓存 --> 根域名服务器 -> 顶级域名服务器 --> 权限域名服务器。

3.TCP连接
浏览器终于得到了目的IP地址以后,可以开始向服务器发送TCP连接,经过三次握手之后建立了TCP连接之后, 我们可以开始正式的通信

4.浏览器发送HTTP请求
浏览器和服务器建立连接以后,浏览器接着按这个IP地址给服务器发送一个HTTP请求,方式为get,例如访问www.baidu.com。其本质是在建立起的TCP连接中,按照HTTP协议标准发送一个索要网页的请求。

4.服务器处理请求
服务器端收到了客户端的HTTP请求报文之后, 会对它进行相应的解析, 然后生成一个响应头和具体响应内容, 将客户端所需要的资源封装成一个HTTP响应报文发送回去

5.浏览器接受响应
浏览器接收到来自服务器的HTTP响应报文之后,会对其进行分析处理,再经过解析和渲染，就将文字、图片、视频等元素呈现给用户。

6.关闭TCP连接
当数据完成请求到返回的过程之后,根据Connection字段的Keep-Alive属性可以选择是否断开TCP连接,HTTP/1.1 版本的默认连接都是持久连接
```

28.HTTP和HTTPS有什么区别

```
HTTP 是超文本传输协议,信息是明文传输,存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷,在 TCP传输层 和 HTTP 应用层之间加入了 SSL/TLS 安全协议,使得报文能够加密传输。
HTTP 连接建立相对简单, TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后,还需进行 SSL/TLS 的握手过程,才可进入加密报文传输。
HTTP 的端口号是 80,HTTPS 的端口号是 443。
HTTPS 协议需要向 CA（证书权威机构）申请数字证书, 来保证服务器的身份是可信的。
```

29.HTTP五大类状态码

```
1xx: 提示信息, 表示目前是协议处理的中间状态, 还需要后续的操作
2xx: 成功, 报文已经收到并被正确处理				 
3xx: 重定向, 资源位置发生变动, 需要客户端重新发送请求
4xx: 客户端错误, 请求报文有误, 服务器无法处理
5xx: 服务器错误, 服务器在处理请求时内部发生了错误
```

30.HTTP常用字段

```
Host字段 客户端发送请求时，用来指定服务器的域名
Connection字段 最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。
User-Agent:客户端程序的信息，就是我发送请求的浏览器信息。
Accept：列出了浏览器可以接收的媒体数据类型：
Accept-Language:告知服务器浏览器能够处理的自然语言集（中文、英文等）。zh-CN中文简体。
Accept-Encoding: 告知服务器能够接收的压缩格式
Cookie：浏览器记录的用户相关信息。
Content-Length字段 服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。
Content-Type字段 用于服务器回应时，告诉客户端，本次数据是什么格式。
Content-Encoding字段 说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式
```

31.你知道的 HTTP/1.1的优点有哪些,怎么体现的？

```
HTTP/1.1最突出的优点是: 简单, 灵活和易于拓展,应用广泛和跨平台
1.简单
HTTP 基本的报文格式就是 header + body,头部信息也是 key-value 简单文本的形式,易于理解,降低了学习和使用的门槛。

2.灵活和易于扩展
HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死,都允许开发人员自定义和扩充。同时 HTTP 由于是工作在应用层（ OSI 第七层）,则它下层可以随意变化。
例如 HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层,而HTTP/3 甚至把 TCP 层换成了基于 UDP 的 QUIC。

3.应用广泛和跨平台
互联网发展至今,HTTP 的应用范围非常的广泛,从台式机的浏览器到手机上的各种 APP,从看新闻、刷贴吧到购物、理财、吃鸡,HTTP 的应用遍地开花,同时天然具有跨平台的优越性。
```

32.HTTP/1.1的缺点, 你知道什么不

```
双刃剑: 无状态, 明文传输
无状态:
无状态的好处,因为服务器不会去记忆 HTTP 的状态,所以不需要额外的资源来记录状态信息,这能减轻服务器的负担,能够把更多的 CPU 和内存用来对外提供服务。
无状态的坏处,既然服务器没有记忆能力,它在完成有关联性的操作时会非常麻烦。
cookie技术 贴纸例子

明文传输:
明文意味着在传输过程中的信息,是可方便阅读的,通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看,为我们调试工作带了极大的便利性。
但是这正是这样,HTTP 的所有信息都暴露在了光天化日下,相当于信息裸奔。在传输的漫长的过程中,信息的内容都毫无隐私可言,很容易就能被窃取,如果里面有你的账号密码信息,那...


缺点: 不安全
```

33.说说HTTP/1.1相比于HTTP/1.0提高了什么性能

```
HTTP/1.1 相比 HTTP/1.0 性能上的改进：

使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
支持管道（pipeline）网络传输,只要第一个请求发出去了,不必等其回来,就可以发第二个请求出去,可以减少整体的响应时间。
```

34.TCP和UDP的区别

```
1. 连接
TCP 是面向连接的传输层协议,传输数据前先要建立连接。
UDP 是不需要连接,即刻传输数据。

2. 服务对象
TCP 是一对一的两点服务,即一条连接只有两个端点。
UDP 支持一对一、一对多、多对多的交互通信

3. 可靠性
TCP 是可靠交付数据的,数据可以无差错、不丢失、不重复、按序到达。
UDP 是尽最大努力交付,不保证可靠交付数据。

4. 拥塞控制、流量控制
TCP 有拥塞控制和流量控制机制,保证数据传输的安全性。
UDP 则没有,即使网络非常拥堵了,也不会影响 UDP 的发送速率。

5. 首部开销
TCP 首部长度较长,会有一定的开销,首部在没有使用「选项」字段时是 20 个字节,如果使用了「选项」字段则会变长的。
UDP 首部只有 8 个字节,并且是固定不变的,开销较小。

6. 传输方式
TCP 是流式传输,没有边界,但保证顺序和可靠。
UDP 是一个包一个包的发送,是有边界的,但可能会丢包和乱序。

7. 分片不同
TCP 的数据大小如果大于 MSS 大小,则会在传输层进行分片,目标主机收到后,也同样在传输层组装 TCP 数据包,如果中途丢失了一个分片,只需要传输丢失的这个分片。
UDP 的数据大小如果大于 MTU 大小,则会在 IP 层进行分片,目标主机收到后,在 IP 层组装完数据,接着再传给传输层。
```

35.TCP和UDP应用场景

```
由于 TCP 是面向连接,能保证数据的可靠性交付,因此经常用于：
FTP 文件传输；
HTTP / HTTPS；

由于 UDP 面向无连接,它可以随时发送数据,再加上UDP本身的处理既简单又高效,因此经常用于：
包总量较少的通信,
如 DNS 、SNMP 等；
视频、音频等多媒体通信；
广播通信；
```

36.四次挥手的过程

```
客户端打算关闭连接,此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文,也即 FIN 报文,之后客户端进入 FIN_WAIT_1 状态。
服务端收到该报文后,就向客户端发送 ACK 应答报文,接着服务端进入 CLOSED_WAIT 状态。
客户端收到服务端的 ACK 应答报文后,之后进入 FIN_WAIT_2 状态。
等待服务端处理完数据后,也向客户端发送 FIN 报文,之后服务端进入 LAST_ACK 状态。
客户端收到服务端的 FIN 报文后,回一个 ACK 应答报文,之后进入 TIME_WAIT 状态
服务器收到了 ACK 应答报文后,就进入了 CLOSED 状态,至此服务端已经完成连接的关闭。
客户端在经过 2MSL 一段时间后,自动进入 CLOSED 状态,至此客户端也完成连接的关闭。
你可以看到,每个方向都需要一个 FIN 和一个 ACK,因此通常被称为四次挥手。
需要注意的一点是, 主动关闭连接的一方才会有Time-Wait阶段
```

36.为什么挥手需要四次

```
再来回顾下四次挥手双方发 FIN 包的过程,就能理解为什么需要四次了。

关闭连接时,客户端向服务端发送 FIN 时,仅仅表示客户端不再发送数据了但是还能接收数据
服务器收到客户端的 FIN 报文时,先回一个 ACK 应答报文,而服务端可能还有数据需要处理和发送,等服务端不再发送数据时,才发送 FIN 报文给客户端来表示同意现在关闭连接。
从上面过程可知,服务端通常需要等待完成数据的发送和处理,所以服务端的 ACK 和 FIN 一般都会分开发送,从而比三次握手导致多了一次。
```

37.为什么 TIME_WAIT 等待的时间是 2MSL？

```
MSL 是 Maximum Segment Lifetime,报文最大生存时间,它是任何报文在网络上存在的最长时间,超过这个时间报文将被丢弃。
TIME_WAIT 等待 2 倍的 MSL,我认为主要有两个原因:
1. 使双方都能够正常的关闭
为了保证客户端发送的最后一个ACK报文段能够到达服务端, 因为这个ACK报文段有可能丢失, 因为使处于LAST_ACK状态的服务端收不到对已发送的FIN + ACK报文段的确认, 服务端就会重传这个FIN + ACK报文段, 一来一回就是2MSL, 这样客户端就能在2MSL时间内收到这个重传的FIN + ACK报文段.接着客户端重传一次确认, 重新启动2MSL计时器, 最后两者才能都正常进入Closed状态. 如果客户端在TIME-Wait状态下不等待一段时间, 而是在发送完ACK报文段后立即释放连接, 那么就无法收到服务端重传的FIN + ACK报文段, 因而也不会再发送一次确认报文段, 这样, 服务端就无法按照正常步骤进入Closed状态.
2. 使本次连接中产生的所有报文都消失在网络中
客户端在发送完最后一个ACK报文之后, 在经过时间2MSL, 就可以使本连接持续的时间内所产生的所有报文段都从网络中消失, 这样就可以使下一个连接中不会出现这种已经失效的连接请求报文段.
```

38.说一说什么是事务

```
事务就是一组原子性的SQL操作,或者说一个独立的工作单元.如果数据库引擎能够成功地对数据库应用该组查询的全部语句,那么就执行该组查询.如果有任何一条语句因为崩溃或者其他原因无法执行,那么所有的语句都不会执行.
也就是说事务内的语句,要么全部执行成功,要么全部执行失败
```

39.MySQL用的什么引擎

```
目前MySQL使用的是InnoDB引擎, 它是一个事务安全的存储引擎, 具备提交, 回滚以及崩溃恢复的功能以保护用户数据. InnoDB的行级锁保证数据一致性的前提下提高了并发性能. InnoDB将用户数据存储在聚簇索引中以减少基于主键的普通查询所带来的I/O开销, 为了保证数据的完整性, InnoDB还支持外键约束, 默认使用B+ Tree数据结构存储索引.
在MySQL5.0版本之前, 使用的是MyISAM引擎, 它不支持事务, 也不支持外键, 其优势是访问速度快, 但是表级别的锁定限制了他在读写负载方面的性能, 因此它经常应用于只是读或者以读为主的数据场景, 默认使用B+树结构存储索引.
```

40.InnoDB存储引擎的索引结构

```
InnoDB存储引擎使用的索引结构是B+树, 它是一个多路平衡搜索树,  
```

41.B+树和B树有什么区别(为什么使用B+树不使用B树)

```
MySQL 默认的存储引擎 InnoDB 采用的是 B+ 树作为索引的数据结构，原因有：

1. B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比既存储索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的时候磁盘 I/O次数会更少。(相同的数据量，B+树更矮壮，也是就说，相同的数据量，B+树数据结构，查询磁盘的次数会更少。)
2. B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
3. B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。
```

42.说一说聚簇索引和二级索引

```
InnoDB 存储引擎根据索引类型不同，分为聚簇索引和二级索引。它们区别在于，聚簇索引的叶子节点存放的是实际数据，所有完整的用户数据都存放在聚簇索引的叶子节点，找到了索引也就找到了数据. 而二级索引的叶子节点存放的是主键值，而不是实际数据。所以如果我们使用二级索引列作为查询条件, 如果要查询的数据都在「聚簇索引」的叶子节点里，那么需要检索两颗B+树. 进行回表操作
在创建表时，InnoDB 存储引擎默认会创建一个主键索引，也就是聚簇索引，且一张表只允许存在一个聚簇索引。其它索引都属于二级索引。
如果没有定义主键, 那么存储引擎会自动选择第一列唯一且不为空的列作为聚簇索引, 如果没有这样的列存在, 那么会自动生成一个自增的主键id作为索引
```

43.回表是什么意思, 覆盖索引什么意思?

```
在我们使用「二级索引」字段作为条件查询的时候，如果要查询的数据都在「聚簇索引」的叶子节点里，那么需要检索两颗B+树：

先在「二级索引」的 B+ 树找到对应的叶子节点，获取主键值；
然后用上一步获取的主键值，在「聚簇索引」中的 B+ 树检索到对应的叶子节点，然后获取要查询的数据。
上述过程叫做回表

在我们使用「二级索引」字段作为条件查询的时候，如果要查询的数据就在「二级索引」的叶子节点，那么只需要在「二级索引」的 B+ 树找到对应的叶子节点，然后读取要查询的数据就可以了, 不需要再回表, 这个过程叫做覆盖索引。
```

44.索引失效的几种原因

```
1.对索引使用左或者左右模糊匹配. 
也就是 like %xx 或者 like %xx% 这两种方式都会造成索引失效。 like x% 这种不会
原因: 因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。

2.对索引使用函数
原因: 因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。
不过，从 MySQL 8.0 开始，索引特性增加了函数索引，即可以针对函数计算后的值建立一个索引，也就是说该索引的值是函数计算后的值，所以就可以通过扫描索引来查询数据。

3.对索引进行表达式计算
原因跟对索引使用函数差不多。 ... WHERE id = 10 - 1; 可以  ... WHERE id - 1 = 10; 不行

4.对索引隐式类型转换
如果索引字段是字符串类型，但是在条件查询中，输入的参数是整型的话，你会在执行计划的结果发现这条语句会走全表扫描。

5.联合索引非最左匹配
原因是，在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。(类似于字典排序)
也就是说，如果我们想使用联合索引中尽可能多的列，查询条件中的各个列必须是联合索引中从最左边开始连续的列。如果我们仅仅按照第二列搜索，肯定无法走索引。

6.WHERE 子句中的 OR
因为 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的，只要有条件列不是索引列，就会进行全表扫描。
```

45.什么是联合索引, 了解最左原则吗?

```
多个普通字段组合在一起创建的索引就叫做联合索引，也叫组合索引. 只会构建出一棵索引树, 每个节点的键值不是单个的, 而是组合值

最左匹配原则, 在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。
也就是说，如果我们想使用联合索引中尽可能多的列，查询条件中的各个列必须是联合索引中从最左边开始连续的列。如果我们仅仅按照第二列搜索，肯定无法走索引  
例如以下:
1 5 a
1 5 d
1 6 c
2 2 b
2 3 a
5 2 a
5 9 b
9 3 t
```

46.为什么使用联合索引

```
1.减少开销
建立一个联合索引, 实际上相当于建立了多个单列索引. 而每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！
比如我们对a, b, c三个字段建立一个联合索引(a, b, c), 其实就相当于建立了三个单列索引, 在我们做这样的查询时, 比如:
select * from user where a = 10 and b = 11, 我们只需要查询一颗联合索引树就可以得到结果, 不需要查询两个单列索引树, 然后再将各自所得的结果过滤合并, 这样可以大大减少磁盘I/O次数, 减少开销, 提高性能

2.覆盖索引
使用联合索引的话, 有可能出现覆盖索引的情况, 即我们要查询的数据全部在这一棵联合索引树中, 那么我们只要查询一次就可以从叶子节点中得到数据, 而不用再回表去聚簇索引树中查找

3.索引列越多，通过索引筛选出的数据越少, 更加高效

```

47.InnoDB引擎通过什么技术来保证事务的这四个特性?

```
持久性是通过 redo log （重做日志） 来保证的；
原子性是通过 undo log （回滚日志） 来保证的；
隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
一致性则是通过持久性+原子性+隔离性来保证；
```

48.读已提交和可重复读是怎么实现的?

```
MVCC即多版本并发控制, 数据库隔离级别读已提交、可重复读 都是基于MVCC实现的，相对于加锁简单粗暴的方式，它用更好的方式去处理读写冲突，能有效提高数据库并发性能。

通俗的讲，数据库中同时存在多个版本的数据，并不是整个数据库的多个版本，而是某一条记录的多个版本同时存在，这些旧版本数据都存放在undo log中. InnoDB存储引擎中每一条记录都有两个隐藏列, 一个是trx_id, 记录了最近一次修改本条记录的事务ID, 一个是roll_ptr, 指向undo_log中的旧版本记录, 这些旧版本记录通过链表连接起来, 可以通过roll_ptr可以找到修改前的记录。

Read View 在 MVCC中如何工作的?
在可重复读和读已提交隔离级别下,它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读已提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，称为实时读. 而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View, 称为快照读.

Read View中包含了四个字段, 比如当前事务ID, read view创建时的其余活跃事务id列表(活跃事务”指的就是，启动了但还没提交的事务。), 活跃事务id列表中最小的id, 以及创建Read View时应当给下一个事务的id.

一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：
如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。
如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。
如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：
如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。
如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。

对于读已提交和可重复读隔离级别, 差别就在于生成Read View的时机不同, 
正是因为在读已提交隔离级别下，事务每次读数据时都重新创建 Read View，那么在事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。
而在可重复读隔离级别下, 只在事务开始之初生成了Read View, 后面整个事务执行期间都是用的同一个Read View, 自然所有的数据都会是一致的, 当然如果在事务中要执行UPDATE, DELETE, INSERT这些操作时, 就必须要获取新的Read View, 那么就会产生我们所说的幻读问题. 普通的Select查询都是快照读, 其余的操作是实时读.
对于幻读问题, 我们使用next_key_lock(临键锁)来解决, 它是记录锁和间隙锁的组合, 锁住我们要修改的记录之间的间隙以及记录本身, 使得别的事务想要在此期间插入删除数据的话会被阻塞, 从而解决了幻读问题
```

49.幻读是怎么被解决的

```
读者做的实验之所以看不到幻读现象，是因为在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。
可重复读隔离级是由 MVCC（多版本并发控制）实现的，实现的方式是启动事务后，在执行第一个查询语句后，会创建一个视图，然后后续的查询语句都用这个视图，「快照读」读的就是这个视图的数据，视图你可以理解为版本数据，这样就使得每次查询的数据都是一样的。
MySQL 里除了普通查询是快照度，其他都是当前读，比如update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。
这很好理解，假设你要 update 一个记录，另一个事务已经 delete 这条记录并且 提交事务了，这样不是会产生冲突吗，所以 update 的时候肯定要知道最新的数据。
另外，select ... for update 这种查询语句是当前读，每次执行的时候都是读取最新的数据。

因此，要讨论「可重复读」隔离级别的幻读现象，是要建立在「当前读」的情况下。


Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了 next-key 锁，就是记录锁和间隙锁的组合。
记录锁，锁的是记录本身；
间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。(左开右开)
对于幻读问题, 我们使用next_key_lock(临键锁)来解决, 它是记录锁和间隙锁的组合, 锁住我们要修改的记录之间的间隙以及记录本身, (左开右闭) 使得别的事务想要在此期间插入数据的话会被阻塞, 从而解决了幻读问题
```

50.说一说redo, undo日志 binlog日志

```
Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前会把数据拷贝到undo log 里，当事务进行回滚时可以通过undo log 里的日志进行数据还原。各个数据记录之间通过链表相连, InnoDB引擎下每个记录后都有两个隐藏列. roll_ptr可以找到旧版本的记录

redo log主要用于在进行日志回放的时候把已经COMMIT的事务重做一遍，对于没有commit的事务交由undo log进行数据回滚操作。

区别在于redo log关注的是已经commit的事务保证了持久性(已经commit的事务存放在内存中, 这时候掉电导致数据还没有更新回磁盘)，undo log是没有commit的事务需要进行回滚的, 保证了原子性。

那么对数据进行一系列的修改之前都会把其历史数据保存到undo log，undo log 是一个链表结构, 然后把更新的数据记录到redo log日志里。 当我们的事务进行commit后可以通过redo log日志来保证只要commit后的事务数据都会全部同步修改到数据库。当事务进行rollback时，我们可以通过undo log记录的历史版本来对整个事务关联的修改的数据进行回滚。


主要作用是用于数据库的主从复制及数据的增量恢复。
1.啥是binlog? 记录数据库增删改,不记录查询的二进制日志.
2.作用:用于数据恢复.

层次不同。redo/undo log是innodb层维护的，而binlog是mysql server层维护的，跟采用何种引擎没有关系，记录的是所有引擎的更新操作的日志记录
记录时机不同。redo/undo日志在事务执行过程中会不断的写入
显然，我们执行SELECT等不涉及数据更新的语句是不会记binlog的，而涉及到数据更新则会记录。要注意的是，对支持事务的引擎如innodb而言，必须要提交了事务才会记录binlog。
binlog刷新到磁盘的时机跟sync_binlog参数相关，
```

51.数据库是如何保证事务的隔离性的

```
加锁和MVCC
数据库是通过加锁，来实现事务的隔离性的。这就好像，如果你想一个人静静，不被别人打扰，你就可以在房门上加上一把锁。
加锁确实好使，可以保证隔离性。比如串行化隔离级别就是加锁实现的。但是频繁的加锁，导致读数据时，没办法修改，修改数据时，没办法读取，大大降低了数据库性能。
那么，如何解决加锁后的性能问题的？
答案就是,MVCC多版本并发控制！它实现读取数据不用加锁，可以让读取数据同时修改。修改数据时同时可读取。
...
```

51. MVCC是什么?

```
MVCC即多版本并发控制, 数据库隔离级别读已提交、可重复读 都是基于MVCC实现的，相对于加锁简单粗暴的方式，它用更好的方式去处理读写冲突，能有效提高数据库并发性能。

通俗的讲，数据库中同时存在多个版本的数据，并不是整个数据库的多个版本，而是某一条记录的多个版本同时存在，这些旧版本都存放在undo log中. InnoDB存储引擎中每一条记录都有两个隐藏列, 一个是trx_id, 记录了最近一次修改本条记录的事务ID, 一个是roll_ptr, 指向undo_log中的旧版本记录, 这些旧版本记录通过链表连接起来, 可以通过roll_ptr可以找到修改前的记录。

Read View 在 MVCC中如何工作的?
在可重复读和读已提交隔离级别下,它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，称为实时读. 而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View, 称为快照读.

Read View中包含了四个字段, 比如当前本事务ID, read view创建时的其余活跃事务id列表(活跃事务”指的就是，启动了但还没提交的事务。), 活跃事务id中最小的id, 以及创建Read View时应当给下一个事务的id.

一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：
如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。
如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。
如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：
如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。
如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。
```

52.协程是什么

```
协程
协程（Coroutines）是一种比线程更加轻量级的存在。协程完全由程序所控制（在用户态执行, 协程之间的切换不会x），带来的好处是性能大幅度的提升。
 一个操作系统中可以有多个进程；一个进程可以有多个线程；同理，一个线程可以有多个协程。

协程是一个特殊的函数，这个函数可以在某个地方挂起，并且可以重新在挂起处继续运行。
 一个线程内的多个协程的运行是串行的，这点和多进程（多线程）在多核CPU上执行时是不同的。 多进程（多线程）在多核CPU上是可以并行的。当线程内的某一个协程运行时，其它协程必须挂起。
 协程可以看作是一个用户级线程, 切换代价很小
```





