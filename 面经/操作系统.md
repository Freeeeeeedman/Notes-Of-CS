### 操作系统

---

1.进程和线程的区别

```
根本区别：进程是操作系统资源分配的基本单位,而线程是处理器任务调度和执行的基本单位
资源开销：每个进程都有独立的代码和数据空间（程序上下文）,程序之间的切换会有较大的开销；线程可以看做轻量级的进程,同一类线程共			享代码和数据空间,每个线程都有自己独立的运行栈和程序计数器（PC）,线程之间切换的开销小。
影响关系：一个进程崩溃后,在保护模式下不会对其他进程产生影响,但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。
执行过程:每个独立的进程有一个程序运行的入口、顺序执行序列和程序入口,执行开销大。但是线程不能独立执行,必须依存在应用程序中,由		应用程序提供多个线程执行控制,执行开销小。
		线程是进程当中的一条执行流程。
```

2.PCB具体包括哪些东西?

```
1.进程描述信息
进程标识符:标识各个进程, 每个进程都有一个并且唯一的标识符；
用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

2.进程控制和管理信息
进程当前状态，如 new、ready、running、waiting 或 blocked 等；
进程优先级：进程抢占 CPU 时的优先级；

3.资源分配清单
(进程上下文切换时需要保存的全局变量, 虚拟内存等资源)
有关内存地址空间或虚拟地址空间的信息，文件描述符表和所使用的 I/O 设备信息。

4.CPU相关信息
CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。
```

3.CPU上下文包括什么?

```
程序计数器和CPU寄存器
每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要操作系统事先帮它设置好 CPU 寄存器和程序计数器(Program Counter，PC)。

CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。
而这些保存下来的上下文，会存储在系统内核(对应进程的PCB中)中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。
```

3.进程和线程的区别

4.为什么用线程池?

```
使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销,解决资源不足的问题。如果不使用线程池,有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。我们线程池里会维护一部分活跃线程,如果有需要,就直接去线程池里取线程使用,用完即归还到线程池里,免去了创建和销毁线程的开销,从而实现对创建的线程进行复用且线程池也会线程的数量有一定的限制。
这些资源都是在服务端启动之初就已经加载好的, 我们称之为静态资源.

推荐使用如下的回答:
池化技术在开发中比较常见,比如线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗,提高对资源的利用率。线程池就是池化思想的一个很好利用,它的好处我认为有三点:
1.降低资源消耗。通过重复利用已创建的线程降低线程动态创建和销毁造成的消耗。
2.提高响应速度。当任务到达时,任务可以不需要等到线程创建就能立即执行, 减少了创建线程这段时间的开销。
3.提高线程的可管理性。线程是稀缺资源,如果无限制的创建,不仅会消耗系统资源,还会降低系统的稳定性,使用线程池可以进行统一的分配,调优和监控。
```

5.创建一个线程需要哪些开销?   **寄**

```
因为线程是共享它所属进程的一些资源, 比如代码段, 数据段, 堆段, 一些公有数据等, 所以创建一个线程只需要分配给他一些必不可少的资源, 比如堆栈段要划分给一个新的线程, 还会分配给他一组寄存器. 
```

6.多线程 多进程? 为什么用多线程, 优势是什么   **寄**

```
花销小, 切换快.  方便的通信机制
使用多线程的理由之一是和进程相比,它是一种非常花销小,切换快,更"节俭"的多任务操作方式。在Linux系统下,启动一个新的进程必须分配给它独立的地址空间,建立众多的数据表(即PCB中的资源分配清单)来维护它的代码段、堆栈段和数据段,这是一种"昂贵"的多任务工作方式。而运行于一个进程中的多个线程,它们彼此之间使用相同的地址空间,共享大部分数据,启动一个线程所花费的空间远远小于启动一个进程所花费的空间,而且,线程间彼此切换所需的时间也远远小于进程间切换所需要的时间。

使用多线程的理由之二是线程间方便的通信机制。对不同进程来说,它们具有独立的数据空间,要进行数据的传递只能通过通信的方式进行,这种方式不仅费时,而且很不方便。线程则不然,由于同一进程下的线程之间共享数据空间,所以一个线程的数据可以直接为其它线程所用,这不仅快捷,而且方便。
```

7.进程状态模型

```
三态模型  五态模型  七态模型
```

8.说一说线程安全, 怎么保证线程安全		**寄中寄**

```
线程安全是多线程领域的问题，线程安全可以简单理解为一个方法或者一个实例可以在多线程环境中使用而不会出现问题.在拥有共享数据的多条线程并行执行的程序中，线程安全的代码会通过同步机制保证各个线程都可以正常且正确的执行，不会出现数据污染等意外情况。

在并发执行的环境中,对于共享数据通过同步机制保证各个线程都可以正确的执行,不会出现数据污染的情况,或者对于某个资源,在被多个线程访问时,不管运行时执行这些线程有什么样的顺序或者交错,都不会出现错误的行为,就认为这个资源是线程安全的.
一般来说,对于某个资源如果只有读操作,则这个资源无需同步就是线程安全的,若有多个线程进行读写操作,则需要线程同步来保证线程安全。

一般通过同步机制来保证线程安全
```

9.信号量和锁啥区别   有哪几种锁  说一说  互斥,同步   **寄中寄**

```
信号量: 用于实现多线程的同步问题,一个线程完成了某一个动作就通过信号量告诉别的线程,别的线程再进行某些动作.是服务于多个线程间的		执行的逻辑顺序的,即调度线程。
锁: 用于实现从多线程开发中的互斥问题.一个线程占用了某一个资源,那么别的线程就无法访问,直到这个线程unlock,其他的线程才开始可	     以利用这个资源。

信号量(semaphore)用在多线程多任务同步的,一个线程完成了某一个动作就通过信号量告诉别的线程,别的线程再进行某些动作。而互斥锁(Mutual exclusion,缩写 Mutex)是用在多线程多任务互斥的,一个线程占用了某一个资源,那么别的线程就无法访问,直到这个线程unlock,其他的线程才开始可以利用这个资源。比如对全局变量的访问,有时要加锁,操作完了,在解锁。尽管两个概念有点类似,但是他们的侧重点不一样,信号量不一定是锁定某一个资源,而是流程上的概念,比如：有A,B两个线程,B线程要等A线程完成某一任务以后再进行自己下面的步骤,这个任务并不一定是锁定某一资源,还可以是进行一些计算或者数据处理之类。而线程互斥量则是“锁住某一资源”的概念,在锁定期间内,其他线程无法对被保护的数据进行操作。
不难看出,mutex是semaphore的一种特殊情况（n=1时）。也就是说,完全可以用后者替代前者。但是,因为mutex较为简单,且效率高,所以在必须保证资源独占的情况下,还是采用这种设计。


所谓互斥,就是不同线程通过竞争进入临界区（共享的数据和硬件资源）,为了防止访问冲突,在有限的时间内只允许其中之一独占性的使用共享资源。如不允许同时写

同步关系则是多个线程彼此合作,通过一定的逻辑关系来共同完成一个任务。即并发进程/线程在一些关键点上可能需要互相等待与互通消息,这种相互制约的等待与互通信息称为进程/线程同步。
一般来说,同步关系中往往包含互斥,同时对临界区的资源会按照某种逻辑顺序进行访问。如先生产后使用

总的来说, 两者的区别就是：
互斥是通过竞争对资源的独占使用,彼此之间不需要知道对方的存在,执行顺序是一个乱序。
同步是协调多个相互关联线程合作完成任务,彼此之间知道对方存在,执行顺序往往是有序的。
```

10.什么是死锁

```
是指两个或两个以上的进程（或线程）在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁
```

11.避免死锁的方法, 出现死锁的几个条件    **寄中寄**

```
出现死锁的几个条件:
1.互斥条件  
	多个线程不能同时使用同一个资源。
	比如一个线程 A 已经持有的资源,不能再同时被线程 B 持有,如果线程 B 请求获取线程 A 已经占用的	  资源,那线程 B 只能等待,直到线程 A 释放了资源。
2.持有等待条件
	进程在申请新的资源的同时,保持对原有资源的占有.
	比如线程 A 已经持有了资源 1,又想申请资源 2,而资源 2 已经被线程 B 持有了,所以线程 A 就会处于等待状态,但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 
3.不可剥夺条件
	资源申请者不能强行从资源占有者手中夺取资源,资源只能由占有者自愿释放
	当线程已经持有了资源 ,在自己使用完之前不能被其他线程获取,线程 B 如果也想使用此资源,则只能在线程 A 使用完并释放后才能获	取。
4.环路等待条件
	在死锁发生的时候,两个线程获取资源的顺序构成了环形链。
	
避免死锁的方法:
对于以上 4 个条件,只要破坏其中一个条件,就可以避免死锁的发生。
对于第一个条件 "互斥" 是不能破坏的,因为加锁就是为了保证互斥。
其他三个条件,我们可以尝试
1.一次性申请所有的资源,这样就不会说导致占有了一个或多个，等待着另一个的情况了  破坏"持有等待" 条件
2.占有部分资源的线程进一步申请其他资源时,如果申请不到, 主动释放它占有的资源, 破坏 "不可剥夺" 条件
3.按序申请资源, 比如上述例子，让两个线程都先争夺资源s1，再争夺资源s2.破坏 "环路等待" 条件
```

12.说一说活锁   **寄中寄中寄**

```
活锁: 
多线程中出现了相互谦让,都主动将资源释放给别的线程使用,这样资源在多个线程之间跳动而又得不到执行,形成活锁。活锁是加不上锁就放开已获得的资源重试
活锁恰恰与死锁相反,死锁是大家都拿不到资源却又都占用着对方所需的资源,而活锁是可以拿到资源却又相互释放不执行。当多线程中出现了相互谦让,都主动将资源释放给别的线程使用,这样这个资源在多个线程之间跳动而又得不到执行,这就是活锁。
活锁同样会发生在多个相互协作的线程间，当他们为了彼此间的响应而相互礼让，使得没有一个线程能够继续前进，那么就发生了活锁。
好比两个过于礼貌的人在半路相遇，出于礼貌他们相互礼让，避开对方的路，但是在另一条路上又相遇了。就这样，不停地一直避让下去

解决办法:
解决活锁的一个简单办法就是在下一次尝试获取资源之前,随机休眠一小段时间。


死锁: 
是指两个或两个以上的进程（或线程）在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁

死锁的预防:
见上 破坏四个条件


诊断死锁的方法：
1. 超时法: 
2. 等待图法: 对事务创建有向图,事务等待图,系统周期性的生成并检测事务等待图,如果发现图中存在回路,则表示系统中出现了死锁。

死锁的解除方法:
重启: 重新启动死锁进程, 甚至重启操作系统
撤销: 撤销死锁进程, 回收资源, 优先选择占用资源最多或者撤销代价最小的, 撤销一个不行就撤销多个, 直到解除死锁
回滚: 根据系统保存的检查点, 使进程或系统回退到死锁前的状态


饥饿:
饥饿是指一个或者多个线程因为种种原因始终无法获得所需要的资源,导致一直无法执行的状态。
通常来说, 这个线程优先级很低. 优先级高的线程能够插队并优先执行,这样如果优先级高的线程一直抢占优先级低线程的资源,导致低优先级线程无法得到执行,这就是饥饿。与死锁不同的是饥饿在以后一段时间内还是能够得到执行的,如那个占用资源的线程结束了并释放了资源。
死锁进程等待永远不会被释放的资源,饿死进程等待会被释放但却不会分配给自己的资源,表现为等待时限没有上界.死锁一定涉及多个进程,而饥饿或被饿死的进程可能只有一个.
饥饿和饿死与资源分配策略有关,因而防止饥饿与饿死可从公平性考虑,确保所有线程不被忽视,如FCFS分配算法。
```

13.说一下Linux的常用命令

14.内存泄漏和内存溢出  (虚拟内存空间)

```
内存泄漏:
由于疏忽或错误造成程序未能释放已经不再使用的 内存 。. 内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，导致在释放该段内存之前就失去了对该段内存的控制，从而造成了内存的浪费。一般是发生在程序中已动态分配的堆内存, 如new了一个对象, 之后忘记了释放, 结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给需要的程序。
内存溢出:
内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory；比如申请了一个integer,但给它存了long才能存下的数，那就是内存溢出。
内存溢出就是你要求分配的内存超出了系统能给你的，系统不能满足需求，于是产生溢出。stackOverflow
```

15.IO多路复用原理

```
相比于传统的多进程模型和多线程模型面对大量连接时的做法, 即每一个socket连接都用一个进程或者线程来处理, IO多路复用做了一个很大的改变, 就是可以只用一个进程或者线程来监视多个文件描述符, 一旦某个描述符就绪（一般是读就绪或者写就绪），内核能够通知进程进行相应的读写操作。
Linux系统提供了三个用于IO多路复用的系统调用, 即select, poll, epoll, 但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写(将数据从内核缓冲区拷贝至用户缓冲区)，也就是说这个读写过程是阻塞的 ，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责自动把数据从内核拷贝到用户空间。
```

16.select, poll, epoll区别, 底层实现

```
select/poll
select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将需要监视的文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。
所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。

但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。

epoll
epoll 通过两个方面，很好解决了 select/poll 的问题。
第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述符，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是 O(logn)，通过对这棵黑红树进行操作，这样就不需要像 select/poll 每次操作时都传入整个 socket 集合，只需要传入新的待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。

第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 文件描述符上 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有读写事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。epoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。
```

17.进程通信的方式

```
管道(匿名, 有名) ---> 消息队列 ---> 共享内存 ---> 信号量 ---> 信号 --->socket
Linux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。

匿名管道顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有文件实体存在于文件系统中，shell 命令中的「|」竖线就是匿名管道，通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

命名管道突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。

消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。

共享内存可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，它直接分配一个共享空间，每个进程都可以直接访问，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有最快的进程间通信方式之名。但是便捷高效的共享内存通信，带来新的问题，多进程竞争同个共享资源会造成数据的错乱。

那么，就需要信号量来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。

与信号量名字很相似的叫信号，它俩名字虽然相似，但功能一点儿都不一样。信号是进程间通信机制中唯一的异步通信机制，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SIGSTOP，这是为了方便我们能在任何时候结束或停止某个进程。

前面说到的通信机制，都是工作于同一台主机，如果要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。

以上，就是进程间通信的主要机制了。你可能会问了，那线程通信间的方式呢？
```

18.为什么一个线程挂掉了其他线程也会挂掉

```
1.进程（主线程）创建了多个线程，多个子线程均拥有自己独立的栈空间（存储函数参数、局部变量等），但是多个子线程和主线程共享堆、全局变量等非栈内存。

2.如果子线程的崩溃是由于自己的一亩三分地引起的，那就不会对主线程和其他子线程产生影响，但是如果子线程的崩溃是因为对共享区域造成了破坏，那么大家就一起崩溃了。3.举个栗子：主线程是一节车厢的乘务员，诸多乘客（也就是子线程）就是经过乘务员（主线程）检票确定可以进入车厢的，也就是主线程创建了诸多子线程，每个子线程有自己独立的区域（座位啊啥的），但是诸多乘客和乘务员共享走廊啊卫生间啊等等，如果其中一名乘客座位坏了，摔了（可以认为奔溃了），那么其他乘客和乘务员都不受影响，但是如果乘客将卫生间给破坏了，他也无法使用卫生间（崩溃了），其他乘客和乘务员也不能用卫生间，好吧，那么大家一起憋着吧（崩溃了）。

总体来说，线程没有独立的地址空间，如果崩溃，会发信号，如果没有错误处理的handler，OS一般直接杀死进程。就算是有handler了处理，一般也会导致程序崩溃，因为很有可能其他线程或者进程的数据被破坏了。
```

19.进程调度算法

```
FCFS --> SJF --> HRRN --> RR --> HPF --> MFQ
进程调度算法:
先来先服务(FCFS)
每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。有利于长作业, 不利于短作业, 适合CPU繁忙型, 不适合IO繁忙型作业的系统

短作业优先(SJF)
优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。长作业长期不会被运行。

高响应比优先(HRRN)
主要是权衡了短作业和长作业。
每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行
优先权 = (等待时间 + 运行时间) / 运行时间

时间片轮转(RR)
最古老、最简单、最公平且使用最广的算法就是时间片轮转, 每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行
时间片过短导致过多的进程上下文切换，降低了 CPU 效率；
时间片过长则退化为FCFS

最高优先级调度算法(HPF)
能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。可能会导致低优先级的进程永远不会运行。

多级反馈队列调度算法(MFQ)
「时间片轮转算法」和「最高优先级算法」的综合和发展。
「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；
对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。


缺页中断:
当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存, 并且物理内存中没有空闲页
页面置换算法:
最佳页面置换算法（OPT） 		置换在「未来」最长时间不访问的页面。
先进先出置换算法（FIFO）       选择在内存驻留时间很长的页面进行中置换
最近最久未使用的置换算法（LRU） 选择最长时间没有被访问的页面进行置换
时钟页面置换算法（Lock）		 
最不常用置换算法（LFU）		当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰
```

20.死锁问题, 解决方案

```
四个条件: 互斥, 持有等待, 不可剥夺, 环路等待

诊断死锁的方法：
1. 超时法: 
2. 等待图法: 对事务创建有向图,事务等待图,系统周期性的生成并检测事务等待图,如果发现图中存在回路,则表示系统中出现了死锁。

死锁的解除方法:
重启: 重新启动死锁进程, 甚至重启操作系统
撤销: 撤销死锁进程, 回收资源, 优先选择占用资源最多或者撤销代价最小的, 撤销一个不行就撤销多个, 直到解除死锁
回滚: 根据系统保存的检查点, 使进程或系统回退到死锁前的状态

解决方案:
互斥无法解决
一次性申请所有的资源, 这样就不会说导致占有了一个或多个，等待着另一个资源的情况了
如果申请不到别的资源, 主动释放自身所拥有的资源
按需申请所需资源,比如A,B线程都需要资源1,资源2, 那么规定一个次序,统一先申请资源1,再申请资源2
```

21.同步和互斥的理解

```
所谓互斥,就是不同线程通过竞争进入临界区（共享的数据和硬件资源）,为了防止访问冲突,在有限的时间内只允许其中之一独占性的使用共享资源。如不允许同时写

同步关系则是多个线程彼此合作,通过一定的逻辑关系来共同完成一个任务。即并发进程/线程在一些关键点上可能需要互相等待与互通消息,这种相互制约的等待与互通信息称为进程/线程同步。
一般来说,同步关系中往往包含互斥,同时对临界区的资源会按照某种逻辑顺序进行访问。如先生产后使用

总的来说,两者的区别就是：
互斥是通过竞争对资源的独占使用,彼此之间不需要知道对方的存在,执行顺序是一个乱序。
同步是协调多个相互关联线程合作完成任务,彼此之间知道对方存在,执行顺序往往是有序的。
```

22.Linux查看CPU负载和进程状态命令

```
top命令
top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的[任务管理器]。
ps命令
ps命令用于报告当前系统的进程状态。ps命令是最基本同时也是非常强大的进程查看命令，使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等，总之大部分信息都是可以通过执行该命令得到的。
free命令
free命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。
```

23.Linux用过哪些命令

```
cd ps free top cat vim rm
mkdir chmod ls 
```

24.操作系统的内存管理是干什么的

```
操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。

如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。
我们程序(包括CPU直接接触的)所使用的内存地址叫做虚拟内存地址（Virtual Memory Address）
实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。
操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：
```

25.为什么要有逻辑地址

```
如果没有逻辑地址, 用户直接使用物理地址的话, 在多个程序运行的情况下, 很容易产生冲突, 造成严重的内存混乱与冲突
所以我们就需要提供一层抽象的逻辑地址,用户不必关心底层的物理地址, 同时结合虚拟内存的思想, 使得每个任务都感觉自己好像拥有整个内存空间一样, 当程序要访问虚拟地址的时候，是由操作系统来将其转换成不同的物理地址，这样不同的进程运行的时候，虽说是用一个逻辑地址, 但实际上写入的是不同的物理地址，这样就不会冲突了。
```

26.操作系统中的虚拟地址转换物理地址的全过程

```
1.段式存储
虚拟地址切分为段选择因子 段内偏移
而段选择因子包括了段号, 特权等标志位, 我们通过段号去段表(进程运行时，操作系统会将内存中PCB中段表的起始地址F和段表长度M传送到段表寄存器中。)里面查询可以获得段基地址, 段界限等, 
最后通过段基地址和段内偏移量进行组装得到真正的物理地址

2.页式存储
把虚拟内存地址，切分成页号和偏移量；
根据页号，从页表(页表的起始地址和长度存在于页表寄存器中, 每一个进程被调度的时候, 操作系统就会从PCB中取出页表的起始地址和长度刷新到页表寄存器中)里面，查询对应的物理页号；
直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。
多级页表, 虚拟地址切分为一级页号, 二级页号, 页内偏移

3.段页式存储
先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；
这样，地址结构就由段号、段内页号和页内位移三部分组成。
虚拟地址切分为段号, 段内页号, 页内位移
利用段号从段表中查出对应页表的地址, 然后用段内页号去页表中查找对应的物理页地址, 再和页内位移组装的到物理地址
用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，[段表中存放的的内容是页表的起始地址]，而页表中的地址则为某页的物理页号，
```

27.进程和线程的区别

28.进程上下文切换步骤

```
进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。
通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行
所以进程上下文切换主要有如下步骤:
1.保存CPU上下文, 包括程序计数器和其他寄存器, 保存至当前进程的PCB中
2.将被替换的进程的PCB移入相应的队列, 如就绪队列, 阻塞队列
3.调度器选择另一个进程执行, 将其PCB中的存储的CPU上下文信息填入, 恢复CPU上下文
4.更新内存管理的数据结构, 刷新TLB快表, 填入该进程页表的起始地址和长度到页表寄存器, 为新进程服务

CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存至进程的PCB中(在内核区, PCB排在各种队列)，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。
系统内核会存储保持下来的上下文信息到PCB中，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。
```

29.线程上下文切换

```
这还得看线程是不是属于同一个进程：

当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
当两个线程是属于同一个进程，因为虚拟内存, 全局变量, 堆内存是共享的，所以在切换时，这些资源就保持不动，只需要切换线程的私有数据即栈段、寄存器等不共享的数据；
所以，线程的上下文切换相比进程，开销要小很多。
```

30.讲讲fork的整个过程实现

```
当调用fork()系统调用之后, 内核会做这四件事情
1.分配新的内存块和内核数据结构给子进程
2.将父进程部分数据结构内容(数据空间, 堆栈等)拷贝至子进程
3.添加子进程到系统进程列表当中
4.fork返回, 开始调度器调度

但是, Linux中, fork()函数调用采用了读时共享写时复制这一机制, 是由MMU来实现的。
在fork之后两个进程用的是相同的物理空间（内存区），子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。即父子进程在逻辑上仍然是严格相互独立的两个进程，各自维护各自的参数，只是在物理上实现了读时共享，写时复制。 
当进程空间的各段的内容要发生变化时（子进程或父进程进行写操作时，都会引起复制），才会将父进程的内容复制一份给子进程。
```

31.讲讲缺页中断的整个过程, TLB是怎么实现加速的

```
缺页中断:
当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。

整个过程:
在 CPU 里访问一条 Load M 指令，先访问TLB, 如果有的话, 直接访问内存, 没有的话 CPU 会去物理内存中的页表 找 M 所对应的页表项。
如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。
操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置(inode?)。
找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。(如果没有空闲页, 需要执行页面调度算法, 从物理内存中选择一个物理块换出到磁盘中, 同时还要记得刷脏, 即如果该页的修改位为1, 表示该页调入内存之后被修改过, 所以要重新将该页写回磁盘, 使磁盘保留一个最新的副本)
页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。
最后，CPU 重新执行导致缺页异常的指令。

TLB是如何实现加速的:
因为程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件, 所以计算机科学家们在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB. ，通常称为页表缓存, 快表.
在CPU芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果找到了需要的页面, 那么直接到内存中取, 如果没找到，才会继续去内存中查常规的页表, 再进行地址转换工作, 最后再访问内存获取数据。
```

32.讲讲Linux从代码到进程的整个过程, 每一步发生了什么

```

```

33.线程通信的方式

```
1.共享内存
同一个进程中的多个线程, 共享进程堆段, 数据段, 代码段等, 我们可以利用它们通过对  隐式的通信

2.锁机制  
互斥锁, 自旋锁, 自旋锁

3.信号量机制
实现同步互斥

4.信号机制
wait() join()
```

34.虚拟内存的功能

```
虚拟内存提供了三个重要的能力： 缓存，内存管理，内存保护

1. 将主存视为一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据. 因为程序的局部性原理, 将程序一次性装入内存是不必要的, 只要正确的调度, 我们可以保证程序正确无误的执行. 因此, 我们可以将磁盘也就是外存作为内存的补充, 将暂时不需要用到的页面存放在外存中, 以便让其他的大进程可以得到运行, 

2. 虚拟内存为每个进程提供了一致的地址空间，用户不必关心底层的物理地址, 简化内存管理

3. 保护了每个进程的地址空间不被其他进程破坏
```

35.讲讲MMU工作流程

```
MMU内存管理单元完成虚拟内存地址转换成物理地址的工作。
CPU 在寻址时，MMU会先查 TLB，如果命中了，就可以获得物理块号, 然后直接去物理内存中取出页面
如果没找到, 才会去物理内存中继续查常规的页表, 然后进行虚拟地址转换, 然后再访问物理内存, 读出页面。
```

36.操作系统进程与进程间通信有哪些方式？线程与线程间呢？

```
管道(匿名, 有名) ---> 消息队列 ---> 共享内存 ---> 信号量 ---> 信号 --->socket
Linux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。

匿名管道顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「|」竖线就是匿名管道，通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

命名管道突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。

消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。

共享内存可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，它直接分配一个共享空间，每个进程都可以直接访问，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有最快的进程间通信方式之名。但是便捷高效的共享内存通信，带来新的问题，多进程竞争同个共享资源会造成数据的错乱。

那么，就需要信号量来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。

与信号量名字很相似的叫信号，它俩名字虽然相似，但功能一点儿都不一样。信号是进程间通信机制中唯一的异步通信机制，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，这是为了方便我们能在任何时候结束或停止某个进程。

前面说到的通信机制，都是工作于同一台主机，如果要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。

以上，就是进程间通信的主要机制了。你可能会问了，那线程通信间的方式呢？

共享内存, 锁机制, 信号量机制, 信号机制
```

37.用户态是什么, 内核态是什么? 什么时候会发送用户态到内核态的转化

```
当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；反之，当程序运行在0级特权级上时，就可以称之为运行在内核态。

虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序, 只能受限的访问内存，且不允许访问外围设备
 
用户态切换到内核态的3种方式
a. 系统调用
这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统内核提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

b. 异常
当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

c. 中断信号
当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。
```

38.内存管理的方式

```
在计算机发展历程中, 最古老的内存管理方式是分区式内存管理, 比如固定分区式, 可变分区式, 它们都具有一个共同的特点 --- 连续性
每道程序都要占用内存中一块连续的存储区域, 当系统运行一段时间后, 会在内存中产生很多"碎片", 虽然我们可以利用紧凑技术将内存中的"碎片"重新整合再利用, 但是紧凑技术的系统开销是巨大的.
为了解决这一问题, 出现了非连续的内存分配方式, 也叫离散分配方式, 其基本出发点就是打破程序装入的整体性和存储分配的连续性, 将用户进程的逻辑地址空间划分成多个子部分, 以子部分为单位装入物理内存, 这些子部分可以分布在若干非连续的内存块上, 实现了离散存储, 以充分利用内存.内存的非连续分配方式主要包括页式存储管理和段式存储管理两种方式

页式存储管理:
将用户进程的逻辑地址空间划分为大小相等的区, 每个区称为一页或者一个页面, 同时将物理内存也划分成和页大小相等的区, 每个区成为一个物理块(block). Linux系统中, 一页的大小为4kb, 内存分配的基本单位为页, 当装入一个用户程序时, 按页为单位, 每页装入一个物理块中, 一个用户进程装入内存中时, 各个物理块之间不需要连续.在进行内存分配的时候, 操作系统为进入内存的每个用户作业建立一张页表, 页表用来指出逻辑地址中的页号与内存中物理块号的对应关系, 每个在内存中的用户进程都会建立一张页表, 页表的起始地址和长度都存放在进程的PCB中, 只有某一进程被调度运行时, 系统才会从运行进程的PCB中将页表起始地址和长度装入页表寄存器. 
虚拟地址切分为 页号 + 页内偏移, 利用页号可以从页表中找到对应的物理块号, 然后得到物理地址

段式存储管理:
一个程序往往是由是由若干个逻辑分段组成的,如可由代码分段、数据分段、栈段、堆段组成。因此, 我们可以按照程序的逻辑段结构, 将一个程序按段为单位来分配内存, 一段占用一块连续的内存地址空间, 段与段之间不需要连续.
在页式存储管理中, 逻辑地址如何分页用户是不可见的, 连续的逻辑地址空间根据内存物理块的大小自动分页, 而在段式存储管理中, 则是由用户来决定逻辑地址是如何分段的.
虚拟地址切分为 段选择因子 + 段内偏移, 段选择子里面最重要的是段号，用作段表的索引, 

段页式存储管理:
内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。
先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；
这样，地址结构就由段号、段内页号和页内位移三部分组成。
```

39.内存分配的堆区和栈区有什么区别, 分别存储哪些数据, 底层原理是什么?

```
一般对于一个程序来说, 我们可以将它对应的虚拟内存空间划分为5个段, 从低地址到高地址分别是 代码段 数据段 堆段 共享内存段 栈段

栈中存放的内容使程序在需要的时候分配，在不需要的时候自动清楚的变量的存储区。里面的变量通常是局部变量、函数参数等。 
堆中资源由程序员控制（容易产生memory leak）。
栈资源由编译器自动管理，无需手工控制。

系统响应：
   对于堆，应知道系统有一个记录空闲内存地址的链表，当系统收到程序申请时，遍历该链表，寻找第一个空间大于申请空间的堆结点，删除空闲结点链表中的该结点，并将该结点空间分配给程序（大多数系统会在这块内存空间首地址记录本次分配的大小，这样delete才能正确释放本内存空间，另外系统会将多余的部分重新放入空闲链表中）。
   对于栈，只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则报异常提示栈溢出。
   
栈：在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意
思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是2M（也有
的说是1M，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将
提示overflow。因此，能从栈获得的空间较小。
堆：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储
的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小
受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。

栈由系统自动分配，速度较快。但程序员是无法控制的。
堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便.
```

40.互斥锁和自旋锁

```
互斥锁加锁失败后,线程会释放 CPU ,自己由运行态切换到阻塞态, 将CPU资源分配给其他线程；
自旋锁加锁失败后,线程会忙等待, 仍旧是处于运行态, 不会释放CPU资源, 直到它拿到锁；

线程的上下文切换的是什么？当两个线程是属于同一个进程,因为虚拟内存是共享的,所以在切换时,虚拟内存这些资源就保持不动,只需要切换线程的私有数据、寄存器等不共享的数据。

上下切换的耗时有大佬统计过,大概在几十纳秒到几微秒之间,如果你锁住的代码执行时间比较短,那可能上下文切换的时间都比你锁住的代码执行时间还要长。所以,如果你能确定被锁住的代码执行时间很短,就不应该用互斥锁,而应该选用自旋锁,否则使用互斥锁。

自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap）,在「用户态」完成加锁和解锁操作,不会主动产生线程上下文切换,所以相比互斥锁来说,会快一些,开销也小一些。
自旋锁是最比较简单的一种锁,一直自旋,利用 CPU 周期,直到锁可用。需要注意,在单核 CPU 上,需要抢占式的调度器（即不断通过时钟中断一个线程,运行其他线程）。否则,自旋锁在单 CPU 上无法使用,因为一个自旋的线程永远不会放弃 CPU。

自旋锁与互斥锁使用层面比较相似,但实现层面上完全不同：当加锁失败时,互斥锁用「线程切换」来应对,自旋锁则用「忙等待」来应对。
它俩是锁的最基本处理方式,更高级的锁都会选择其中一个来实现
```

41.乐观锁和悲观锁

```
前面提到的互斥锁、自旋锁、读写锁,都是属于悲观锁。

悲观锁做事比较悲观,它认为多线程同时修改共享资源的概率比较高,于是很容易出现冲突,所以访问共享资源前,先要上锁。

那相反的,如果多线程同时修改共享资源的概率比较低,就可以采用乐观锁。

乐观锁做事比较乐观,它假定冲突的概率很低,它的工作方式是：先修改完共享资源,再验证这段时间内有没有发生冲突,如果没有其他线程在修改资源,那么操作完成,如果发现有其他线程已经修改过这个资源,就放弃本次操作。
可见,乐观锁的心态是,不管三七二十一,先改了资源再说。另外,你会发现乐观锁全程并没有加锁,所以它也叫无锁编程。
乐观锁虽然去除了加锁解锁的操作,但是一旦发生冲突,重试的成本非常高,所以只有在冲突概率非常低,且加锁成本非常高的场景时,才考虑使用乐观锁。(例子, 共享文档)
```

42.说一说锁

```
多线程开发过程中,最常见的就是互斥锁的了,互斥锁加锁失败时,会用「线程切换」来应对,当加锁失败的线程再次加锁成功后的这一过程,会有两次线程上下文切换的成本,性能损耗比较大。

如果我们明确知道被锁住的代码的执行时间很短,那我们应该选择开销比较小的自旋锁,因为自旋锁加锁失败时,并不会主动产生线程切换,而是一直忙等待,直到获取到锁,那么如果被锁住的代码执行时间很短,那这个忙等待的时间相对应也很短。

如果能区分读操作和写操作的场景,那读写锁就更合适了,它允许多个读线程可以同时持有读锁,提高了读的并发性。根据偏袒读方还是写方,可以分为读优先锁和写优先锁,读优先锁并发性很强,但是写线程会被饿死,而写优先锁会优先服务写线程,读线程也可能会被饿死,那为了避免饥饿的问题,于是就有了公平读写锁,它是用队列把请求锁的线程排队,并保证先入先出的原则来对线程加锁,这样便保证了某种线程不会被饿死,通用性也更好点。

互斥锁和自旋锁都是最基本的锁,读写锁可以根据场景来选择这两种锁其中的一个进行实现。

另外,互斥锁、自旋锁、读写锁都属于悲观锁,悲观锁认为并发访问共享资源时,冲突概率可能非常高,所以在访问共享资源前,都需要先加锁。

相反的,如果并发访问共享资源时,冲突概率非常低的话,就可以使用乐观锁,它的工作方式是,在访问共享资源时,不用先加锁,修改完共享资源后,再验证这段时间内有没有发生冲突,如果没有其他线程在修改资源,那么操作完成,如果发现有其他线程已经修改过这个资源,就放弃本次操作。

但是,一旦冲突概率上升,就不适合使用乐观锁了,因为它解决冲突的重试成本非常高。

不管使用的哪种锁,我们的加锁的代码范围应该尽可能的小,也就是加锁的粒度要小,这样执行速度会比较快。再来,使用上了合适的锁,就会快上加快了。
```

43.说一说页式存储管理和段式存储管理

```
在计算机发展历程中, 最古老的内存管理方式是分区式内存管理, 比如固定分区式, 可变分区式, 它们都具有一个共同的特点 --- 连续性
每道程序都要占用内存中一块连续的存储区域, 当系统运行一段时间后, 会在内存中产生很多"碎片", 虽然我们可以利用紧凑技术将内存中的"碎片"重新整合再利用, 但是紧凑技术的系统开销是巨大的.
为了解决这一问题, 出现了非连续的内存分配方式, 也叫离散分配方式, 其基本出发点就是打破程序装入的整体性和存储分配的连续性, 将用户进程的逻辑地址空间划分成多个子部分, 以子部分为单位装入物理内存, 这些子部分可以分布在若干非连续的内存块上, 实现了离散存储, 以充分利用内存.内存的非连续分配方式主要包括页式存储管理和段式存储管理两种方式

页式存储管理:
将用户进程的逻辑地址空间划分为大小相等的区, 每个区称为一页或者一个页面, 同时将物理内存也划分成和页大小相等的区, 每个区成为一个物理块(block). Linux系统中, 一页的大小为4kb, 内存分配的基本单位为页, 当装入一个用户程序时, 按页为单位, 每页装入一个物理块中, 一个用户进程装入内存中时, 各个物理块之间不需要连续.在进行内存分配的时候, 操作系统会为进入内存的每个用户作业建立一张页表, 页表用来指出逻辑地址中的页号与内存中物理块号的对应关系, 每个在内存中的用户进程都会建立一张页表, 页表的起始地址和长度都存放在进程的PCB中, 只有某一进程被调度运行时, 系统才会从运行进程的PCB中将页表起始地址和长度装入页表寄存器.

段式存储管理:
一个程序往往是由是由若干个逻辑分段组成的,如可由代码分段、数据分段、栈段、堆段组成。因此, 我们可以按照程序的逻辑段结构, 将一个程序按段为单位来分配内存, 一段占用一块连续的内存地址空间, 段与段之间不需要连续.
在页式存储管理中, 逻辑地址如何分页用户是不可见的, 连续的逻辑地址空间根据内存物理块的大小自动分页, 而在段式存储管理中, 则是由用户来决定逻辑地址是如何分段的.
```

44.说一说TLB

```
多级页表虽然解决了空间上的问题,但是虚拟地址到物理地址的转换就多了几道转换的工序,这显然就降低了这俩地址转换的速度,也就是带来了时间上的开销。

程序是有局部性的,即在一段时间内,整个程序的执行仅限于程序中的某一部分。相应地,执行所访问的存储空间也局限于某个内存区域。我们就可以利用这一特性,把最常访问的几个页表项存储到访问速度更快的硬件,于是计算机科学家们,就在 CPU 芯片中,加入了一个专门存放程序最常访问的页表项的 Cache,这个 Cache 就是 TLB（Translation Lookaside Buffer） ,通常称为页表缓存、转址旁路缓存、快表等。

在 CPU 芯片里面,封装了内存管理单元（Memory Management Unit）芯片,它用来完成地址转换和 TLB 的访问与交互。
有了 TLB 后,那么 CPU 在寻址时,会先查 TLB,如果没找到,才会继续查常规的页表。TLB 的命中率其实是很高的,因为程序最常访问的页就那么几个。
```

45.说一说程序的局部性原理和虚拟存储(即虚拟内存)

```
程序的局部性原理: 即在一段时间内, 整个程序的执行仅限于程序中的某一部分, 相应的, 执行所访问的存储空间也局限于某一个内存区域.局部性原理表现在时间局部性和空间局部性.
程序的局部性说明, 程序的一次性装入内存与全部驻留内存都是不必要的, 只装入一部分的假设是合理的, 只要操作系统调度得当, 不仅程序可以正确运行, 而且可以在内存中装入更多程序, 充分利用处理器和内存空间.

虚拟存储技术(虚拟内存)的思想是: 将外存作为内存的补充, 因为作业运行时不需要将作业的全部信息放入内存, 将暂时不需要用到的作业信息存放在外存, 通过内存与外存的兑换, 使系统逐步将作业信息放入内存, 最终能够达到运行整个作业, 从逻辑上扩充内存的目的.
```

46.边缘触发模式和水平触发模式的区别

```
epoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。
使用边缘触发模式(ET)时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，也就是内核只通知进程一次有数据到来, 即使进程没有调用 read 函数从内核读取数据或者一次没有读取完所有数据，也依然只通知一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；
使用水平触发模式(LT)时，当被监控的 Socket 上有可读事件发生时，内核不断通知进程某个文件描述符上有数据到来，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；
select和poll只有LT模式, epoll默认为LT模式, 可根据需要自行修改, 通常ET模式和非阻塞IO搭配使用
```

47..页表项都包括哪些字段?

```
页号:
物理页号:
状态位：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。
访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。
修改位：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要		 将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。
硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。
```

