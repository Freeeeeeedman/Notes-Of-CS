### 计算机网络面经总结
### 1. 基础
#### 1.1  TCP/IP ⽹络模型
1. 应⽤层
    应⽤软件所在层，为用户提供服务。⼯作在操作系统中的⽤户态。
2. 传输层
    传输层会有两个传输协议，分别是 TCP 和 UDP。以TCP段为单位传输，超过 MSS（TCP 最⼤报⽂段⻓度） ，就要将数据包分块。注意MSS不包括TCP头部。包含端口号，以区分应用。
3. ⽹络层
    ⽹络层最常使⽤的是 IP 协议（Internet Protocol），如果 IP 报⽂⼤⼩超过 MTU（以太⽹中⼀般为 1500 字节）就会再次进⾏分⽚。注意MTU包括IP头部，TCP头部。包含IP地址，以区分设备。
4. 数据链路层
    要为⽹络层提供链路级别跨⽹络传输的服务。
5. 物理层
    为数据链路层提供⼆进制传输的服务。

### 2. HTTP
#### 2.1 HTTP常见面试题
#### 2.1.1 HTTP基本概念
1. 说一说HTTP协议
    HTTP 是超⽂本传输协议。协议是指HTTP确⽴了一种通信的规范。传输是指HTTP 协议是⼀个双向协议，允许中间有中转。超⽂本指传输的内容是超文本，如图⽚、视频、超链接（能从⼀个超⽂本跳转到另外⼀个超⽂本）等等。
2. HTTP 是⽤于从互联⽹服务器传输超⽂本到本地浏览器的协议，这种说法正确吗？
    不正确，也可以是服务器到服务器
3. 说一说HTTP报文结构
   - HTTP 请求报文由请求行、请求头、请求正文组成
        请求行：请求方法，请求目标（URL），版本号
        请求头：格式为键值对，记录一些客户端属性
        请求正文：要传递的数据
   - HTTP 响应报文由状态行、响应头、响应正文组成
        状态行：状态码、协议版本，状态描述
        响应头：格式为键值对，记录一些服务端属性
        响应正文：要传递的数据
4. 说一说HTTP 首部字段
   分为通用首部字段、请求首部字段、响应首部字段、实体首部字段
5. HTTP 常⻅的状态码有哪些？
   - 1xx:提示信息，表示目前是协议处理中的中间状态，需要后续操作
   - 2xx:服务器成功处理了客户端的请求
        「200 OK」是最常⻅的成功状态码，表示⼀切正常, ⾮ HEAD 请求，服务器返回的响应头都会有 body数据。
         [204 No Content」与 200 OK 基本相同，但响应头没有 body 数据。
         「206 Partial Content」是应⽤于 HTTP 分块下载或断点续传:表示响应返回的 body 数据并不是资源的全部
   - 3xx:重定向,表示客户端请求的资源发送了变动，需要客户端⽤新的 URL 重新发送请求获取资源
        「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改⽤新的 URL 再次访问。
         [302 Found」表示临时重定向，说明请求的资源还在，但暂时需要⽤另⼀个 URL 来访问。
         「304 Not Modified」缓存重定向,不具有跳转的含义，表示资源未修改，重定向已存在的缓冲⽂件
   - 4xx:客户端错误码,客户端发送的报⽂有误，服务器⽆法处
        「400 Bad Request」表示客户端请求的报⽂有错误，但只是个笼统的错误。
        「403 Forbidden」表示服务器禁⽌访问资源，并不是客户端的请求出错。
         [404 Not Found」表示请求的资源在服务器上不存在或未找到，所以⽆法提供给客户端
   - 5xx:服务器端的错误码，客户端请求报⽂正确，但是服务器处理时内部发⽣了错误
        「500 Internal Server Error」与 400 类型，是个笼统通⽤的错误码
        「501 Not Implemented」表示客户端请求的功能还不⽀持
        「502 Bad Gateway」通常是服务器作为⽹关或代理时返回的错误码，表示服务器⾃身⼯作正常，访问后端服务器发⽣了错误
        「503 Service Unavailable」表示服务器当前很忙，暂时⽆法响应
6. http 常⻅字段有哪些？
    Host:客户端指定服务器的域名,可以将请求发往「同⼀台」服务器上的不同⽹站
    Content-Length:服务器在返回数据时，表明本次回应的数据⻓度
    Connection:要求服务器使⽤ TCP 持久连接，以便其他请求复⽤
    Content-Type:服务器回应时表明本次数据是什么格式
    Accept:客户端请求时声明⾃⼰可以接受哪些数据格式
    Content-Encoding:表示服务器返回的数据使⽤了什么压缩格式
    Accept-Encoding:客户端在请求时表明可以接受哪些压缩⽅法
#### 2.1.2 GET与POST方法
1. 说⼀下 GET 和 POST 的区别？
    Get ⽅法的含义是请求从服务器获取资源，如文本图片视频等，POST ⽅法则是相反操作，它向 HOST的URI 指定的资源提交数据，数据就放在报⽂的 body ⾥
2. GET 和 POST ⽅法都是安全和幂等的吗？
    「安全」是指请求⽅法不会「破坏」服务器上的资源。「幂等」，意思是多次执⾏相同的操作，结果都是「相同」的。GET ⽅法就是安全且幂等的，POST是不安全和不幂等的
#### 2.1.3 HTTP 特性
1. HTTP的特性有哪些？
    回答优缺点
2. HTTP（1.1） 的优点有哪些？是怎么体现的？
   - 简单，报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式，便于理解
   - 灵活和易于扩展,请求⽅法、状态码等都可以自定义和扩充。且HTTP工作在应用层，下层可以随意变化。HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层， HTTP/3 甚⾄把 TCP 层换成了基于 UDP 的QUIC。
   - 应⽤⼴泛和跨平台，浏览器到手机APP都可以使用
3. HTTP（1.1） 的缺点有哪些？
   - ⽆状态，服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，能减轻服务器的负担，节约内存和CPU。坏处是在完成有关联性的操作时会⾮常麻烦，如记录登录信息。
   - 明⽂传输，在传输过程中的信息，是可⽅便阅读的，便于调试，缺点是信息没有隐私容易被窃取
   - 不安全，通信使⽤明⽂（盗号），不验证通信⽅的身份（伪装），⽆法证明报⽂的完整性（垃圾广告）。
4. 如何解决HTTP(1.1)的缺点？
   - 无状态：采用cookie，在客户端第⼀次请求后，服务器在响应中加入cookie，后续客户端在请求中加入cookie即可验证
   - 不安全：⽤ HTTPS 的⽅式解决，也就是通过引⼊ SSL/TLS 层
5.  HTTP/1.1 的性能如何？
    - ⻓连接，持久连接。只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。少了HTTP(1.0)TCP 连接的重复建⽴和断开所造成的额外开销，减轻了服务器端的负载。
    - 管道⽹络传输.在同⼀个 TCP 连接⾥⾯，客户端可以连续发起多个请求，不需要等待前一个应答。减少整体的响应时间。但服务器还是按顺序回复请求。
    - 队头阻塞。由于是管道网络传输，服务器还是按顺序回复请求。第一个请求被堵塞则后序所以请求都被堵塞。
    - HTTP性能一般，通过HTTP2/3优化。
#### 2.1.4 HTTP 与 HTTPS
1. HTTP 与 HTTPS 有哪些区别？
   - HTTP明⽂传输，存在安全⻛险的问题。 HTTPS在TCP和HTTP之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。
   - HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。
   - HTTP 的端⼝号是 80， HTTPS 的端⼝号是 443。
   - HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的
2. HTTPS 解决了 HTTP 的哪些问题？
    - 混合加密的⽅式实现信息的机密性，解决了明文传输，被窃听的⻛险。
    - 摘要算法的⽅式来实现完整性，解决了信息被篡改的⻛险。
    - 将服务器公钥放⼊到数字证书中，解决了冒充通信方的⻛险。
3. 说一说混合加密
    对称加密和⾮对称加密结合。在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」。在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。
4. 为什么采用混合加密
    非对称加密公钥可以任意分发⽽私钥保密，虽然安全但是开销大。对称加密只使⽤⼀个密钥，不安全但运算速度快
5. 说一说摘要算法
    客户端用摘要算法算出明文的指纹，一同加密后传输给服务端，服务端解密后用相同的摘要算法计算出指纹，再比对
6. 说一说数字证书
    数字证书用来防止公钥被篡改和掉包，即中间人攻击。将服务器公钥放在数字证书中。而CA的公钥预存在系统中，客户端得到数字证书后，使用CA的公钥确认服务器的数字证书的真实性。再获取服务器的公钥。
7. 什么是中间人攻击？
    在传输过程中，我们采用对称加密的方式对报文进行加密。而采用非对称的方式对加密报文的密钥进行加密。服务器将公钥发给客户端，客户端使用公钥加密加密报文的密钥。并将其发送给服务端。服务端使用私钥解密得到密钥。如果存在中间人，将服务器发送给客户端的公钥替换成自己的公钥，即可解密加密报文的密钥。
8. HTTPS 是如何建⽴连接的？（说一说SSL安全套接字协议/TLS协议传输层加密协议的加密过程）
    首先是客户端和服务端的一般的三次握手过程，再是慢启动，再是SSL/TLS 的四次握手过程。
   - ⾸先，由客户端向服务器发起加密通信请求，传递客户端生产的随机数以及TLS版本号和支持的密码套件
   - 服务器收到客户端请求后，向客户端发出响应，传递服务器生产的随机数和数字证书以及选择的密码套件
   - 客户端收到服务器的回应之后，⾸先通过系统中的 CA 公钥，确认服务器的数字证书的真实性。然后传递一个随机数，该随机数会被服务器公钥加密。并发出将信息传递过程更改为加密算法的通知。通过这个三个随机数计算出会话密钥。客户端握手结束。
   - 服务器收到客户端的第三个随机数，通过协商的加密算法，计算出本次通信的「会话秘钥」。最后。并发出将信息传递过程更改为加密算法的通知。服务端握手结束。之后的通信就进入一般HTTP协议通信，只不过采用会话密钥加密
9. 为什么TCP握手和TLS握手不能合并？
    TCP 和 TLS 是分层的，分别属于内核实现的传输层、 openssl 库实现的表示层。无法合并。HTTP/3可以用QUIC协议将连接建立缩短为1RTT甚至0RTT.

#### 2.1.5 HTTP/1.1, HTTP/2, HTTP/3
1. 说一说HTTP/1.0的缺点
    短连接，不支持管道网络传输
2. HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？
    长连接，支持管道网络传输
3. 说一说HTTP/1.1的性能瓶颈
    - 请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；
    - 每次互相发送相同的⾸部造成的浪费较多；
    - 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；
    - 没有请求优先级控制；
    - 请求只能从客户端开始，服务器只能被动响应。   
4. 对于 HTTP/1.1 的性能瓶颈， HTTP/2 做了什么优化？
   - 压缩头部，在客户端和服务器同时维护⼀张头信息表，对于多个请求，不发生相同字段，只发送索引号
   - ⼆进制格式，HTTP/2 不再像 HTTP/1.1 ⾥的纯⽂本形式的报⽂，⽽是⼆进制格式，称为头信息帧和数据帧。这样解析时就不需要再将报文转换为二进制，直接解析。
   - 数据流，HTTP/2 的数据包不是按顺序发送的，而是数据流。每个数据流都标记着⼀个独⼀⽆⼆的编号来区分对不同请求的响应。客户端还可以指定数据流的优先级。优先级⾼的请求，服务器就先响应该请求。
   - 多路复⽤。HTTP/2 是可以在⼀个连接中并发多个请求或回应。移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现应用层层面「队头阻塞」问题， 降低了延迟，⼤幅度提⾼了连接的利⽤率。例如先回应请求A，发现请求A耗时，回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。
   - 服务器推送。HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发送消息。如在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的等静态资源主动发给客户端，减少延时的等待。
5. 说一说HTTP/3对于HTTP/2的优化
    HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP，因为UDP没有顺序和重传机制，从而避免了队头堵塞和丢包全部重传的问题。
6. HTTP/3采用的UDP是不可靠的怎么办？
    UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到影响。并且 QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。
7. 说一说QUIC协议
    是基于 UDP 协议在传输层实现的协议，具有类似 TCP 的连接管理、拥塞窗⼝、流量控制的⽹络特性。同时满足多路复用。
8. QUIC有什么缺点？
    普及较慢，网络设备无法识别只当作为UDP协议，导致不可靠传输问题。
9.  说一说SSL/TLS 1.2和1.3的区别
    SSL/TLS 1.2 需要 4 握⼿，需要 2 个 RTT 的时延。SSL/TLS 1.3 优化了过程，只需要 1 个 RTT 往返时延，也就是只需要 3 次握⼿。

#### 2.2 HTTP/1.1如何优化
1. HTTP/1.1如何优化
   - 使⽤ KeepAlive 将 HTTP/1.1 从短连接改成⻓链接
   - 利用缓存避免发送 HTTP 请求；
   - 在需要发送 HTTP 请求时，考虑如何减少请求次数；
   - 减少服务器的 HTTP 响应的数据⼤⼩
2. 如何利用缓存避免发送 HTTP 请求？
    对于⼀些具有重复性的 HTTP 请求，⽐如每次请求得到的数据都⼀样的，我们可以把这对「请求-响应」的数据都缓存在本地。当后续发起相同的请求时，就直接读取本地的缓存。
3. 如果缓存过期怎么办？
    服务器在发送 HTTP 响应时，会估算⼀个过期的时间，并把这个信息放到响应头部中，这样客户端在查看响应头部的信息时，⼀旦发现缓存的响应是过期的，则就会重新发送⽹络请求。接着如果服务器通过比对资源的摘要，如果资源没更改，就仅返回不含有包体的 304 Not Modified 响应，更改了就同时回复新的资源。
4. 如何减少 HTTP 请求次数？
    利用代理服务器减少重定向请求次数；
        当需要重定向时，代理服务器直接回复资源而非302应答
    合并请求；
    延迟发送请求
5. 什么是合并请求？（如何在HTTP/1.1内防止对头阻塞）
    如果把多个访问⼩⽂件的请求合并成⼀个⼤的请求，减少了重复发送的 HTTP 头部。同时为了防⽌单个请求的阻塞，所以⼀般浏览器会同时发起 5-6 个请求，每⼀个请求都是不同的 TCP 连接，那么如果合并了请求，也就会减少 TCP 连接的数量，因⽽省去了 TCP 握⼿和慢启动过程耗费的时间。对于服务端可以采用打包资源的方式达到类似的效果。
6. 合并请求会产生什么问题？
    当⼤资源中的某⼀个⼩资源发⽣变化后，客户端必须重新下载整个完整的⼤资源⽂件，这显然带来了额外的⽹络消耗。
7. 什么是延迟发送请求？
    按需获取。先请求需要的资源。例如请求⽹⻚的时候，没必要把全部资源都获取到，⽽是只获取当前⽤户所看到的⻚⾯资源，当⽤户向下滑动⻚⾯的时候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果。
8. 如何减少 HTTP 响应的数据⼤⼩？
    对响应的资源进⾏压缩。按情况分为无损压缩和有损压缩。
9. 什么是无损压缩？
    将常出现的数据⽤较短的⼆进制⽐特序列表示，将不常出现的数据⽤较⻓的⼆进制⽐特序列表示。适用于⽂本⽂件、程序可执⾏⽂件、程序源代码。例如gzip。客户端⽀持的压缩算法，会在 HTTP 请求中通过头部中的 Accept-Encoding 字段告诉服务器
10. 什么是有损压缩？
    舍弃次要的数据如静态帧，提高压缩比。多用于压缩多媒体数据。通过 HTTP 请求头部中的 Accept 字段⾥的「 q 质量因⼦」。
#### 2.3 HTTPS RSA握手解析
1. 什么是密钥交换算法？
    TLS握手过程中使⽤⾮对称加密的⽅式来保护对称加密密钥，这个方式就是密钥交换算法。一般使用 RSA 算法或者ECHDE来实现密钥交换的。
2. 说一说RSA握手过程(即HTTPS的TLS握手过程)
    四步，2RTT
   - ⾸先，由客户端向服务器发起加密通信请求，传递客户端生产的随机数以及TLS版本号和支持的密码套件
   - 服务器收到客户端请求后，向客户端发出响应，传递服务器生产的随机数和数字证书以及选择的密码套件
   - 客户端收到服务器的回应之后，⾸先通过系统中的 CA 公钥，确认服务器的数字证书的真实性。然后传递一个随机数，该随机数会被服务器公钥加密。并发出将信息传递过程更改为加密算法的通知。通过这个三个随机数计算出会话密钥。客户端握手结束。
   - 服务器也通过相同方法计算出相同的会话密钥，通知客户端后续改⽤对称算法加密通信。
3. 如何验证数字证书真实有效？（如何防止中间人篡改数字证书？）
    客户端本地保存有系统的CA公钥，解密证书保存的数字签名与客户端通过hash算法算出来的是否一致。一致则可信，防止了中间人篡改数字证书。同时，证书的验证过程中还存在⼀个证书信任链。
4. 为什么需要证书信任链？
    隔离根证书，防止根证书失守导致信任链崩溃。
5. RSA 算法有什么缺陷？
    不⽀持前向保密。服务器私钥泄漏会导致过去所有的通讯密文被破解。所以要改用ECDHE密钥协商算法。

#### 2.4 HTTPS ECDHE 握⼿解析
1. 说一说DH算法
    客户端和服务端各⾃会⽣成随机数，并以此作为私钥，然后根据公开的 DH 计算公式算出各⾃的公钥。再通过离散对数算出一个随机值作为对称加密的密钥。即使第三⽅截获了 TLS 握⼿阶段传递的公钥，在不知道的私钥的情况下，也是⽆法计算出密钥的，⽽且每⼀次对称加密密钥都是实时⽣成的，实现前向保密。
2. DH算法中离散对数有什么特点？
    没有办法从公钥计算出私钥
3. DH算法有哪几种实现？
    static DH算法：每次协商密钥的时候一方的私钥是静态的，可能会被暴力破解出另一方的私钥。不具有前向安全性。
    DHE算法：双方的私钥都是动态的，改变的，具有前向安全性。
4. 说一说ECDHE算法是什么？
    DHE算法计算性能不高，ECDHE是利用椭圆曲线特性来针对DHE算法的改良，计算效率更高，具有前向安全性。
5. 说一说ECDHE算法的握手过程
    - ⾸先，由客户端向服务器发起加密通信请求，传递客户端生产的随机数以及TLS版本号和支持的密码套件
    - 服务器收到客户端请求后，向客户端发出响应，传递服务器生产的随机数和数字证书以及选择的密码套件，以及由私钥生成的椭圆曲线的公钥，通过发送「Server Key Exchange」消息发送给客户端
    - 客户端收到服务器的回应之后验证证书，且会⽣成⼀个随机数作为客户端椭圆曲线的私钥，再⽣成客户端的椭圆曲线公钥，然后⽤「Client Key Exchange」消息发给服务端。通过随机数以及各自的公钥，自己的私钥计算出会话密钥。并通知诉服务端后续改⽤对称算法加密通信。
    - 服务器也通过相同方法计算出相同的会话密钥，通知客户端后续改⽤对称算法加密通信。
6. 说一说RSA和ECDHE算法的区别
   - 采用的加密算法不同，RSA 密钥协商算法「不⽀持」前向保密， ECDHE 密钥协商算法「⽀持」前向保密；
   - 握手过程不同
     - 使⽤了 RSA 密钥协商算法， TLS 完成四次握⼿后，才能进⾏应⽤数据传输，⽽对于 ECDHE 算法，客户端可以不⽤等服务端的最后⼀次 TLS 握⼿，就可以提前发出加密的 HTTP 数据，节省了⼀个消息的往返时间；
     - 使⽤ ECDHE， 在 TLS 第 2 次握⼿中，会出现服务器端发出的「Server Key Exchange」消息，⽽ RSA 握⼿过程没有该消息；
#### 2.5 HTTPS 如何优化？
1. HTTPs的性能损耗
   - TLS 协议握⼿过程
        对于 ECDHE 算法，握⼿过程中会客户端和服务端都需要⽣成椭圆曲线公私钥；
        客户端验证证书时需要访问CA
        双⽅计算对称加密密钥
   - 握⼿后的对称加密报⽂传输
        一般采用对称加密算法 AES、 ChaCha20
2. HTTPS 如何优化？
   - 硬件优化 
        HTTPS 协议是计算密集型，⽽不是 I/O 密集型，⽀持 AES-NI 特性的 CPU
   - 软件优化
       软件升级，如linux等等
   - 协议优化
        密钥交换算法优化，RSA改ECDHE，RSA不具有前向安全性，且需要2RTT的握手时间。ECDHE具有前向安全性，第三次握手就可以发出加密数据，只需要1RTT握手时间。
        ECDHE椭圆曲线选择最快的。
        TLS 升级到1.3，只需要1次RTT。方法是把第一次握手和第二次握手交换公钥合并为一次，只支持ECDHE算法。
   - 证书优化
        证书传输优化：选择椭圆曲线证书而不是RSA证书，证书大小更小
        证书验证优化：使用OCSP在线证书状态协议来查询证书的有效性而不采用CRL证书吊销列表。后者实时性很差并且大小很大下载慢。
   - 会话复用
          使用Session ID（双方都缓存） 和 Session Ticket（缓存在客户端）缓存会话密钥，再次连接服务器时，就只需要握手两次，即1次RTT。TLS1.3只需要0个RTT，将Ticket和HTTP请求一并发送给服务端。称为Pre-shared Key
3. 会话复用有什么缺点？
   - 都不具备前向安全性
   - 难以应对重放攻击
4. 什么是重放攻击？
    中间⼈截获了Session ID 或 Session Ticket 以及 POST 报⽂，中间⼈就可以利⽤此截获的报⽂，不断向服务器发送该报⽂，这样就会导致数据库的数据被中间⼈改变。一般采用对会话密钥设定⼀个合理的过期时间来解决，

#### 2.6 HTTP/2 
1. HTTP/2是如何兼容 HTTP/1.1
   - HTTP/2 没有在 URI ⾥引⼊新的协议名
   - 只在应⽤层做了改变，还是基于 TCP 协议传输
2. HTTP/2的头部压缩
    HTTP/1.1可以使用头字段 「ContentEncoding」指定 Body 的压缩⽅式。对于报文的头部，常⻅的 HTTP 头部通过静态表压缩和其余的使用动态表压缩。以及使用二进制格式传输。缺点是动态表是占⽤内存影响服务器总体的并发能⼒，因此服务器需要限制 HTTP/2 连接时⻓或者请求次数。
3. 说一说二进制帧
    HTTP/2 把响应报⽂划分成了两个帧（Frame），帧头部以及帧数据，帧头部记录流ID以及优先级,帧数据存放的是压缩过的 HTTP报文。
4. HTTP/2的并发传输（TCP连接的多路复用）
    1个TCP连接包括多个流，一个流又分为多个消息，一个消息又由多个帧组成。不同流的帧可以乱序传递，但对于相同流的帧必须严格有序。因为当 HTTP/2 实现 100 个并发 Stream 时，只需要建⽴⼀次 TCP 连接，⽽ HTTP/1.1 需要建⽴ 100 个 TCP 连接，每个 TCP 连接都要经过TCP 握⼿、慢启动以及 TLS 握⼿过程，耗时。并且HTTP/2 还可以对每个 Stream 设置不同优先级。
5. 服务器⽀持主动推送资源
    HTTP/1.1 不⽀持服务器主动推送资源给客户端，都是由客户端向服务器发起请求后，才能获取到服务器响应的资源。而HTTP/2支持服务器推偶数号流发送资源给客户端。
6. HTTP/2的缺点（TCP协议的缺点）
   - TCP层面的队头阻塞
       - HTTP/2 多个请求是跑在⼀个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该TCP 连接中的所有请求。
       - 因为 TCP 是字节流协议， TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段丢失了，即使序列号较⾼的 TCP 段已经被接收了，应⽤层也⽆法从内核中读取到这部分数据，从 HTTP 视⻆看，就是请求被阻塞了。
   - TCP 与 TLS 的握⼿时延迟
        需要经过TCP三次握手，以及TLS四次握手，需要3个RTT的时延。且TCP有拥塞控制，所有还有慢启动过程。
   - ⽹络迁移需要重新连接
        ⼀个 TCP 连接是由四元组确定的，这意味着如果 IP 地址或者端⼝变动了，就会导致需要 TCP 与 TLS 重新握⼿，这不利于移动设备切换⽹络的场景，⽐如 4G ⽹络环境切换成WIFI。
#### 2.7 HTTP/3
1. 说一说HTTP/3协议
    解决HTTP/2的三个缺点，将TCP协议替换成UDP协议，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输
2. 说一说QUIC协议
    是HTTP/3基于 UDP 协议在传输层实现的协议，具有类似 TCP 的连接管理、拥塞窗⼝、流量控制的⽹络特性，同时满足多路复用。
3. QUIC协议有什么特点？
    ⽆队头阻塞；
        QUIC 连接上的多个流之间并没有依赖，都是独⽴的，某个流发⽣丢包了，只会影响该流，其他流不受影响。   
    更快的连接建⽴；
        QUIC内部包含了 TLS1.3，仅需 1 个 RTT 就可以「同时」完成建⽴连接与密钥协商，甚⾄在第⼆次连接的时候，应⽤数据包可以和 QUIC 握⼿信息（连接信息 + TLS 信息）⼀起发送，达到 0-RTT 的效果
    连接迁移
        QUIC 协议没有⽤四元组的⽅式来“绑定”连接，⽽是通过连接 ID来标记通信的两个端点，只要仍保有上下⽂信息（⽐如连接 ID、 TLS 密钥等），就可以“⽆缝”地复⽤原连接，消除重连的成本

### 3. TCP
#### 3.1 TCP三次握⼿与四次挥⼿
#### 3.1.1 TCP基础
1. TCP头格式
   - 源端口号，端口号（16位）
   - 序列号（32）：⽤来解决⽹络包乱序问题
   - 确认应答号（32）：⽤来解决不丢包的问题
   - 控制位（6）：ACK,RST,SYN,FIN
   - 首部长度（4）：存在选项长度，所以TCP头部大小不确定要标注，4位最大位15，所以TCP头部最大为15 * 4 = 60字节，即选项长度最大为20字节
   - 紧急指针（16）：URG=1时有效，代表紧急数据的字节数。窗口为0也可以发送紧急数据
2. 为什么需要 TCP 协议？ TCP ⼯作在哪⼀层？
   - IP 层是「不可靠」的，它不保证⽹络包的交付、不保证⽹络包的按序交付、也不保证⽹络包中的数据的完整性。
   - TCP 是⼀个⼯作在传输层的可靠数据传输的服务，它能确保接收端接收的⽹络包是⽆损坏、⽆间隔、⾮冗余和按序的
3. 什么是 TCP ？
   - TCP 是⾯向连接的、可靠的、基于字节流的传输层通信协议
   - ⾯向连接：⼀定是「⼀对⼀」才能连接，不能像 UDP 协议可以⼀个主机同时向多个主机发送消息，也就是⼀对多是⽆法做到的
   - 可靠的：⽆论的⽹络链路中出现了怎样的链路变化， TCP 都可以保证⼀个报⽂⼀定能够到达接收端
   - 字节流：消息是「没有边界」的，所以⽆论我们消息有多⼤都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后⾯的字节，那么也不能扔给应⽤层去处理，同时对「重复」的报⽂会⾃动丢弃
4. 什么是 TCP 连接？
    ⽤于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗⼝⼤⼩称为连接
5. 如何唯⼀确定⼀个 TCP 连接？
    TCP 四元组可以唯⼀的确定⼀个连接：源地址，源端⼝，⽬的地址，⽬的端⼝
6. 有⼀个 IP 的服务器监听了⼀个端⼝，它的 TCP 的最⼤连接数是多少？
    最大TCP连接数 = 客户端IP数（32） X 客户端端口数（16） = 2 ^ 48
7. 为什么服务端最⼤并发 TCP 连接数远不能达到理论上限？
   - ⽂件描述符限制， Socket 都是⽂件，所以⾸先要通过 ulimit 配置⽂件描述符的数⽬
   - 内存限制，每个 TCP 连接都要占⽤⼀定内存，操作系统的内存是有限的
8. UDP头部格式（8字节）
   - 源端口号与目标端口号（16）
   - 包长度（16）
   - 校验和（16）
9. TCP 和 UDP 区别
   - 连接
       TCP 是⾯向连接的传输层协议，传输数据前先要建⽴连接。
       UDP 是不需要连接，即刻传输数据。
   - 服务对象
        TCP 是⼀对⼀的两点服务，即⼀条连接只有两个端点
        UDP ⽀持⼀对⼀、⼀对多、多对多的交互通信
   - 可靠性
        TCP 是可靠交付数据的，数据可以⽆差错、不丢失、不重复、按需到达。
        UDP 是尽最⼤努⼒交付，不保证可靠交付数
   - 拥塞控制、流量控制
        TCP 有拥塞控制和流量控制机制，保证数据传输的安全性
        UDP 则没有，即使⽹络⾮常拥堵了，也不会影响 UDP 的发送速率
   - ⾸部开销
        TCP:不确定，无选项头部20字节，最大60字节
        UDP：确定，8字节
   - 传输⽅式
        TCP 是流式传输，没有边界，但保证顺序和可靠。
        UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序
   - 分⽚不同
        TCP 的数据⼤⼩如果⼤于 MSS ⼤⼩，则会在传输层进⾏分⽚，⽬标主机收到后，也同样在传输层组装 TCP数据包，如果中途丢失了⼀个分⽚，只需要传输丢失的这个分⽚[MSS（最大数据报文）+ 首部=数据包]
        UDP 的数据⼤⼩如果⼤于 MTU ⼤⼩，则会在 IP 层进⾏分⽚，⽬标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分⽚，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样传输效率⾮常差，所以通常 UDP 的报⽂应该⼩于 MTU。[以太网(Ethernet)数据帧的长度必须在46-1500字节之间,这是由以太网的物理特性决定的.这个1500字节被称为链路层的MTU(最大传输单元).]
   - 应用场景不同
        TCP:⾯向连接，能保证数据的可靠性交付,FTP ⽂件传输, HTTP / HTTPS
        UDP:⾯向⽆连接，随时发送数据,简单高效：包总量较少的通信，如 DNS，视频、⾳频等多媒体通信⼴播通信 
10. TCP可靠性如何保证？
     校验和；确认应答与序列号；超时重传； 连接管理；流量控制、拥塞控制
11. 为什么 UDP 头部没有「⾸部⻓度」字段，⽽ TCP 头部有「⾸部⻓度」字段呢？
    原因是 TCP 有可变⻓的「选项」字段，⽽ UDP 头部⻓度则是不会变化的，⽆需多⼀个字段去记录 UDP 的⾸部⻓度
12. 为什么 UDP 头部有「包⻓度」字段，⽽ TCP 头部则没有「包⻓度」字段呢？
    TCP数据的长度 = IP总长度（IP首部中） - IP首部长度（IP首部中） - TCP首部长度（TCP首部中）。UDP也可以这么算。真正原因是为了⽹络设备硬件设计和处理⽅便，⾸部⻓度需要是 4 字节的整数倍。
#### 3.1.2 TCP连接建⽴
1. TCP通过什么来建立连接？
    建⽴连接是通过三次握⼿来进⾏的
2. 说一说TCP的三次握手的过程（状态变迁）
   - 首先客户端和服务端都处在CLOSE状态，服务端开始监听端口，接着处于LISTEN状态
   - 然后客户端初始化报文的序列号，SYN标志位置为1，将SYN报文发送给服务端，接着处于SYN_SENT状态
   - 服务端收到SYN报文，初始化自己报文的序列号，确认应答号为收到的SYN报文序列号+1，SYN和ACK标志位置为1，将SYN+ACK报文发给客户端，接着处于SYN_RCVD状态
   - 客户端收到ACK+SYN报文，回应最后一个应答报文，将ACK标志位置为1，确认应答号为ACK+SYN报文的序列号+1，接受处于ESTABLISHED状态
   - 服务端接收到ACK报文，处于ESTABLISHED状态
3. 三次握手可以携带数据吗？
    第三次握⼿是可以携带数据的，前两次握⼿是不可以携带数据的
4. 为什么第三次握⼿是可以携带数据的，前两次握⼿是不可以携带数据的
      第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话，此时客户端已经处于 ESTABLISHED 状态。对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据
5. 如何在 Linux 系统中查看 TCP 状态？
     netstat -napt 命令
6. 为什么是三次握⼿？不是两次握手？
   - ⾸要原因是为了防⽌历史连接初始化了连接
     -  客户端连续发送多次 SYN 建⽴连接的报⽂，在⽹络拥堵情况下：⼀个「旧 SYN 报⽂」⽐「最新的 SYN 」 报⽂早到达了服务端；那么此时服务端就会回⼀个 SYN + ACK 报⽂给客户端；客户端收到后可以根据⾃身的上下⽂，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送RST 报⽂给服务端，表示中⽌这⼀次连接。而如果不是历史连接，则第三次发送的报⽂是 ACK 报⽂，通信双⽅就会成功建⽴连接；
   - 同步双⽅初始序列号
      - 接收⽅可以去除重复的数据；接收⽅可以根据数据包的序列号按序接收；可以标识发送出去的数据包中， 哪些是已经被对⽅收到的；
      - ⼀来⼀回，才能确保双⽅的初始序列号能被可靠的同步
   - 避免资源浪费
        如果客户端的 SYN 阻塞了，重复发送多次 SYN 报⽂，那么服务器在收到请求后就会建⽴多个冗余的⽆效链接，造成不必要的资源浪费
7. 为什么是三次握⼿？不是四次握手？
    三次握⼿就已经理论上最少可靠连接建⽴，所以不需要使⽤更多的通信次数
8. 为什么客户端和服务端的初始序列号 ISN 是随机的？
   - 将不属于本连接的报⽂段丢弃，防止旧连接重用后的历史报文
   - 为了安全性，防⽌⿊客伪造的相同序列号的 TCP 报⽂被对⽅接收
9. 初始序列号 ISN 是如何随机产⽣的？
    随机算法：ISN = M（计时器） + F (哈希算法源 IP、⽬的 IP、源端⼝、⽬的端⼝⽣成⼀个随机数值)
10. 既然 IP 层会分⽚，为什么 TCP 层还需要 MSS 呢？
    IP没有超时重传机制。网络包大于MTU时，IP层就要分片。但如果⼀个 IP 分⽚丢失，整个 IP 报⽂的所有分⽚都得重传。 而TCP负责超时和重传，当接收⽅发现 TCP 报⽂的某一片丢失后，则不会响应 ACK，那么发送⽅的 TCP 在超时后，就会重发整个 TCP 报⽂。建⽴连接的时候通常要协商双⽅的 MSS 值，小于MTU，那么就不用IP分片了。经过 TCP 层分⽚后，如果⼀个 TCP 分⽚丢失后， 进⾏重发时也是以 MSS 为单位，⽽不⽤重传所有的分⽚，⼤⼤增加了重传的效率。
11. 什么是 SYN 攻击？
    客户端发送多个SYN报文，不应达服务端的ACK+SYN报文。会导致服务端处于SYN_REVC的状态的连接增多即SYN半连接队列占满，不能接受新连接。
12. 如何避免 SYN 攻击？
    - 修改 Linux 内核参数，设置半连接队列溢出时，直接回复RST报文丢弃连接
    - 打开tcp_syncookies
    - 减少 SYN+ACK 重传次数，加快处于 SYN_REVC 状态的 TCP 连接断开
#### 3.1.2 TCP 连接断开
1. TCP通过什么断开连接？
    TCP 断开连接是通过四次挥⼿⽅式
2. 说一说TCP四次挥手
   - 先是客户端和服务端都处于ESTABLISH状态。如果是客户端准备关闭连接，则发送FIN标志位为1的FIN报文，进入FIN_WAIT1状态
   - 服务端收到FIN报文，回复ACK报文，进入CLOSED_WAIR状态
   - 客户端收到ACK报文，进入TIME_WAIT2状态
   - 服务端处理完数据后发送FIN报文，进入LAST_ACK状态
   - 客户端收到FIN报文，回复ACK，进入TIME_WAIT状态
   - 服务端收到ACK报文，进入CLOSED状态
   - 客户端在经过2MSL后，进入CLOSED状态，连接关闭
3. 发送FIN报文表示什么
    不能发送数据，但还可以接受数据
4. 为什么挥⼿需要四次？
    因为服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN ⼀般都会分开发送，从⽽⽐三次握⼿导致多了⼀次
5. 为什么需要 TIME_WAIT 状态（TIME_WAIT时间过短会怎么样）？
   - 防⽌旧连接的数据包
        旧的TCP连接被复用后，客户端可能正常接受旧数据，导致数据错乱。经过 2MSL 这个时间， ⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产⽣的
   - 保证双方连接正确关闭
        等待⾜够的时间以确保最后的 ACK 能让被动关闭⽅接收，从⽽帮助其正常关闭。最后一次挥手ACK报文丢失，如果TIME_WAIT状态过短，那么服务端会一直处在LAST_ACK状态。那么当客户端发起新的SYN报文，会导致服务端回复RST报文，新的连接不能建立。而如果TIME_WAIT时间够长，那么当ACK丢失时，服务端会重发FIN报文并等待新的ACK报文。
6. 为什么 TIME_WAIT 等待的时间是 2MSL？
    MSL是报⽂最⼤⽣存时间。从发送方发送报文到接收方回复的报文再被发送方收到要2MSL。这样经过2MSL，TIME_WAIT前的发送的报文基本都会消失。
7. 报文如何消失？
    IP投中TTL 字段，是 IP 数据报可以经过的最⼤路由数，经过一路由即减一。一般 MSL 应该要⼤于等于 TTL 消耗为 0 的时间，以确保报⽂已被⾃然消亡。
8. 如果已经建⽴了连接，但是客户端突然出现故障了怎么办？
    TCP 有保活机制。定义⼀个时间段，在这个时间段内，如果没有任何连接相关的活动，每隔⼀个时间间隔，发送⼀个探测报⽂，如果连续⼏个探测报⽂都没有得到响应，则认为当前的TCP 连接已经死亡，即对方程序崩溃。如果对方回复RST报文，说明TCP连接已重置，即对方的程序崩溃并重启。

#### 3.1.3 Socket 编程
1. 说一说针对 TCP 应该如何 Socket 编程？
    服务端和客户端初始化 socket ，得到⽂件描述符；
    服务端调⽤ bind ，将绑定在 IP 地址和端⼝;
    服务端调⽤ listen ，进⾏监听；
    服务端调⽤ accept ，等待客户端连接；
    客户端调⽤ connect ，向服务器端的地址和端⼝发起连接请求；
    服务端 accept 返回⽤于传输的 socket 的⽂件描述符；
    客户端调⽤ write 写⼊数据；服务端调⽤ read 读取数据；
    客户端断开连接时，会调⽤ close ，那么服务端 read 读取数据的时候，就会读取到了 EOF ，待处理完
    数据后，服务端调⽤ close ，表示连接关闭    
2. socket编程中，三次握手分别对应于哪个阶段
    客户端调用connect主动连接，第一次握手发送SYN报文,收到第二次握手的ACK报文后，connect返回。当第三次握手完成后，服务端accept返回，取出已完成连接的socket。connect和accept都是阻塞的。
3. listen 时候参数 backlog 的意义？
    int listen (int socketfd, int backlog)，accpet 全连接队列⻓度 = min(backlog, somaxconn)
4. 客户端调⽤ close 了，连接断开的流程是什么？
    四次挥手过程。同时两端在发送FIN报文时，会在其中插入文件结束符EOF到末尾，这样双方的应用程序在读到EOF时就知道对方不再发送数据。
5. 四次挥手时如果如果客户端第四次挥⼿ack丢失，服务端超时重发的fin报⽂也丢失，客户端timewait时间超过了2msl，这个时候会发⽣什么？
    当客户端 timewait 时间超过了 2MSL，则客户端就直接进⼊关闭状态。服务端超时重发 fin 报⽂的次数如果超过 tcp_orphan_retries ⼤⼩后，服务端也会关闭 TCP 连接。
6. TCP报文被在IP层MTU分片与在传输层MSS分片有什么区别？
    如果⼀个⼤的 TCP 报⽂是被 MTU 分⽚，那么只有「第⼀个分⽚」才具有 TCP 头部，后⾯的分⽚则没有TCP 头部。如果丢失了其中⼀个分⽚，那么就会等待对⽅超时重传这⼀整个 TCP 报⽂
    如果⼀个⼤的 TCP 报⽂被 MSS 分⽚，那么所有「分⽚都具有 TCP 头部」。如果其中⼀个 MSS 分⽚丢失，发送方没收到对应的ACK，会触发超时重传，就只需要重传这⼀个分⽚就可以。
7. 为什么TCP报文MTU分片丢失要整个重传？而与在传输层MSS分片丢失只需要重传其中一片？
    因为 MTU 分⽚，那么只有「第⼀个分⽚」才具有 TCP 头部，接收⽅ IP 层只有重组了这些分⽚，才会认为是⼀个 TCP 报⽂。而 MSS 分⽚，那么所有「分⽚都具有 TCP 头部」。

#### 3.2  TCP 重传、滑动窗⼝、流量控制、拥塞控制
#### 3.2.1 TCP重传机制
1. TCP在哪些情况下会触发超时重传？
   - 发送方数据包丢失
   - 接收方确认应答丢
2. 超时时间应该设置为多少呢？
    超时重传时间 RTO 的值应该略⼤于报⽂往返 RTT 的值
3. 超时重传时间过大或过小会导致什么情况？
    过大，重发慢，效率低
    过小，重发快，可能包没有丢失就重发，增加⽹络拥塞，导致更多的超时，更多的超时导致更多的重
4. 如何计算超时重传时间？
    ⽹络时常变化，导致RTT也动态变化，进而导致RTO也动态变化。通过采用和统计RTT来计算RTO
5. 多少超时重传会发生什么？   
    超时间隔加倍。达到最大重传次数断开连接。
6. 超时重传缺点是什么？如何改进？
    超时周期可能相对较⻓。利用快速重传机制。
7. 注意超时重传和快速重传是并行使用的，当连续三个回复的ACK都丢失了，说明网络状况很糟糕，会触发超时重传。以及发送方的拥塞发生算法。
8. 说一说快速重传机制
    快速重传机制，它不以时间为驱动，⽽是以数据驱动重传。当发送方丢失了一段数据报文，接收方在收到之后的报文时，会连续发生三个相同的 ACK 报⽂时，提醒发送方重传丢失的报⽂段
9.  快速重传机制的缺点是什么？
    有可能连续丢失了几个报文，重传的时候，是重传之前的⼀个丢失的报文，还是重传之前所有的报文。
10. 如何改进快速重传？
    SACK选择性确认机制。TCP 头部「选项」字段⾥添加SACK，可以将缓存的地图发送给发送⽅，这样发送⽅就可以知道哪些数据收到了，哪些数据没收到，就可以只重传丢失的数据
11. TCP如果发送方丢失了一段数据会发生什么？
    TCP传输数据时是批量发送的，但只会回复ack为最后一段数据的序列号+1的ACK确认报文。如果丢失了一些数据，会触发快速重传和SACK选择性确认机制。同时回复已接受到的数据范围以及三次丢失的数据对应的ACK报文。以及发送方触发拥塞控制的算法。
12. TCP如果传输数据时，接收方应答报文丢失会发生什么？
    首先触发超时重传机制。再触发D-SACK机制。当接收方收到重复的数据时，会向发送方发送有SACK字段的报文，提醒发送方哪些数据是已经被接受的。注意TCP三次握手和四次挥手报文丢失时只会触发超时重传。以及发送方触发拥塞控制的算法。
13. TCP如果传输数据时，有网络延迟会发生什么？
    有网络延迟会导致发送方的部分数据包没有被接受。进而触发快速重传和SACK选择性确认机制。发送方重传后，被延迟的数据包又到达了接收方。这时接收方会回复对应的重复的数据的SACK即DACK提醒发送方已接受被延迟的数据。以及发送方触发拥塞控制的算法。
14. DACK的功能
    可以让「发送⽅」知道，是发出去的包丢了，还是接收⽅回应的 ACK 包丢了;
    可以知道是不是「发送⽅」的数据包被⽹络延迟了;
    可以知道⽹络中是不是把「发送⽅」的数据包给复制了
15. 确认应答号和序列号的关系？
    三次握手中：A发送SYN = 1，seq = 1000， B回复ack = 1001
    传输数据中：A发送seq = 1000(200)，B回复ack = 1200，总之是回复下一个期望收到的TCP报文的序列号，注意1000(200)实际是1000~1999
#### 3.2.2 滑动窗⼝
1. 为什么要有滑动窗口
    有滑动窗口后，发送方就知道可以继续发送数据的最大值，就可以一次性发送多个数据报文，再接受累积应答。而不用等待上一个报文的应答再发送数据效率低。
2. 窗⼝⼤⼩由哪⼀⽅决定？
    通常窗⼝的⼤⼩是由接收⽅的窗⼝⼤⼩来决定的。以及考虑到拥塞窗口，发送窗⼝的值是swnd = min(cwnd, rwnd)，也就是拥塞窗⼝和接收窗⼝中的最⼩值。
3. 发送⽅的发送缓存区由什么组成？
    四部分。
    已发送并收到 ACK确认的数据
    是已发送但未收到 ACK确认的数据
    是未发送但总⼤⼩在接收⽅处理范围内（接收⽅还有空间）
    是未发送但总⼤⼩超过接收⽅处理范围（接收⽅没有空间）
4. 程序是如何表示发送⽅的四个部分的呢？
    用三个指针表示。一个是相对指针，代表发送窗⼝的⼤⼩。第二个是绝对指针，它指向的是已发送但未收到确认的第⼀个字节。第三个是向未发送但可发送范围的第⼀个字节。可以窗口大小为第一个指针减去第二个指针减第三个指针的差
5. 接收⽅的接受缓存区由什么组成？
    三部分。
    已成功接收并确认的数据（等待应⽤进程读取）
    未收到数据但可以接收的数据；
    未收到数据并不可以接收的数据；
6. 程序是如何表示接受⽅的三个部分的呢？
    两个指针表示，第一个指针是相对指针表示接受窗口的大小。第二个指针是绝对指针，表示期望从发送⽅发送来的下⼀个数据字节的序列号 
7. 接收窗⼝和发送窗⼝的⼤⼩是相等的吗？
    是约等于的。因为整个传输过程存在时间延迟。以及考虑到拥塞窗口，发送窗⼝的值是swnd = min(cwnd, rwnd)，也就是拥塞窗⼝和接收窗⼝中的最⼩值。
8. TCP 每次发送/接收数据都会携带 滑动窗口 的大小吗？
    是的除了首包SYN。在TCP头部字段里。接收方回复ACK时值发送变动。

#### 3.2.3 流量控制
1. 说一说TCP的流量控制
    通过接受窗口和发送窗口，让「发送⽅」根据「接收⽅」的实际接收能⼒控制发送的数据量
2. 操作系统缓冲区与滑动窗⼝有什么关系？
    发送窗⼝和接收窗⼝中所存放的字节数，都是放在操作系统内存缓冲区中的，⽽操作系统的缓冲区，会被操作系统调整
3. 如果发送放发送的数据大小超过了接收窗口的大小，会发生什么？
    接收方丢弃数据包，触发重传机制。
4. 操作系统缓冲区减小会发生什么？
    由于发送方是依据之前的接受窗口大小连续发送数据，如果缓冲区直接减小会导致接收方接受窗口大小减小，导致数据⼤⼩超过了接收窗⼝的⼤⼩，数据包丢失。所以TCP 规定是不允许同时减少缓存⼜收缩窗⼝的，⽽是采⽤先收缩窗⼝，过段时间再减少缓存，这样就可以避免了丢包情况
5. 接收方窗口大小为0会发生什么？
    发生窗⼝关闭。如果窗⼝⼤⼩为 0 时，就会阻⽌发送⽅给接收⽅传递数据，直到窗⼝变为⾮0，接收方发生⼀个窗⼝⾮ 0 的 ACK 报⽂。
6. 窗⼝关闭会导致什么问题？
    接收⽅处理完数据后，会向发送⽅通告⼀个窗⼝⾮ 0 的 ACK 报⽂，如果这个通告窗⼝的 ACK 报⽂在⽹络中丢失。会造成死锁现象，发送⽅⼀直等待接收⽅的⾮ 0 窗⼝通知，接收⽅也⼀直等待发送⽅的数据。
7. TCP 是如何解决窗⼝关闭时，潜在的死锁现象呢？
    TCP 连接⼀⽅收到对⽅的零窗⼝通知，就启动持续计时器。如果持续计时器超时，就会发送窗⼝探测 ( Windowprobe ) 报⽂，⽽对⽅在确认这个探测报⽂时，给出⾃⼰现在的接收窗⼝⼤⼩。超过窗口探测次数（3次）会发生RST中断连接。
8. TCP通过滑动窗口进行流量控制可能会导致什么问题？
    会导致糊涂窗⼝综合症
9. 说一说糊涂窗⼝综合症
    当接收方窗口很小或者发送⽅发送⼩数据时，由于TCP + IP 头至少有 40 个字节，会导致传递数据的效率很低
10. 怎么解决糊涂窗⼝综合症
    接收方不通告⼩窗⼝，当「窗⼝⼤⼩」⼩于 min( MSS，缓存空间/2 )，就会向发送⽅通告窗⼝为 0。发送⽅避免发送⼩数据，采用Nagle 算法，要等到窗⼝⼤⼩ >= MSS 或是 数据⼤⼩ >= MSS以及收到之前发送数据的 ack 回包才发送数据。
11. Nagle 算法有什么缺点？
    对于⼀些需要⼩数据包交互的场景的程序，⽐如， telnet 或 ssh 这样的交互性⽐较强的程序，则需要关闭 Nagle 算法.不能和延迟确认机制共用。

#### 3.2.4 拥塞控制
1. 为什么有流量控制还需要拥塞控制（拥塞控制的作用是什么）？
    流量控制是避免「发送⽅」的数据填满「接收⽅」的缓存，但是并不知道⽹络的中发⽣了什么。在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，导致重传数据，但是重传会导致⽹络的负担更重，恶性循环。拥塞控制⽬的就是避免「发送⽅」的数据填满整个⽹络。
2. 什么是拥塞窗⼝？
    拥塞窗⼝ cwnd是发送⽅的状态变量，根据⽹络的拥塞程度动态变化。
3. 拥塞窗⼝和发送窗⼝有什么关系呢？
    发送窗⼝的值是swnd = min(cwnd, rwnd)，也就是拥塞窗⼝和接收窗⼝中的最⼩值。
4. 那么怎么知道当前⽹络是否出现了拥塞呢？
    只要「发送⽅」没有在规定时间内接收到 ACK 应答报⽂，也就是发⽣了超时重传，就会认为⽹络出现了拥塞。具体的实现根据拥塞控制的算法。
5. 拥塞控制有哪些控制算法？
    慢启动
    拥塞避免
    拥塞发⽣
    快速恢复
6. 说一说慢启动
    TCP 在刚建⽴连接完成后，⾸先是有个慢启动的过程。当发送⽅每收到⼀个 ACK，拥塞窗⼝ cwnd 的⼤⼩就会加 1。所以发送包的个数成指数增长。
7. 慢启动什么时候停止？
    到慢启动⻔限停止，之后采用拥塞避免算法
8. 说一说拥塞避免算法
     每当收到⼀个 ACK 时， cwnd 增加 1/cwnd。所以发送包的个数成线性增长。
9. 拥塞避免什么时候停止？
    发生重传时停止，之后采用拥塞发⽣算法
10. 说一说拥塞发⽣算法
    当发生TCP重传时，采用拥塞发⽣算法。重传机制主要有两种：超时重传与快速重传。这两种重传的拥塞发送算法是不同的。
11. 说一说发⽣超时重传的拥塞发⽣算法
    慢启动门限设置为当前拥塞窗口的1/2，当前拥塞窗口重置为1。再重新开始慢启动，会导致⽹络卡顿。
12. 说一说发⽣快速重传的拥塞发⽣算法
    这种方式更好。当接收⽅发现丢了⼀个中间包的时候，发送三次前⼀个包的ACK，于是发送端就会快速地重传，不必等待超时再重传。TCP 认为这种丢弃情况不严重（因为能收到三个ACK），拥塞窗口设置为原来的1/2，慢启动门限再设为拥塞窗口。接着发生快速恢复算法。
13. 说一说快速恢复算法
    快速重传和快速恢复算法⼀般同时使⽤，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明⽹络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。此时拥塞窗⼝为慢启动门限+3，再线性增长到之前的慢启动门限再进入拥塞避免状态。

#### 3.3 TCP 实战抓包分析
1. 如何分析网络包数据（如何对网络进行性能分析）？
    使用tcpdump 和 Wireshark
2. tcpdump 和 Wireshark 有什么区别？
    tcpdump 命令⾏格式. Linux 中抓取和分析⽹络包。Wireshark还提供了可视化分析⽹络包的图形⻚⾯，windows端。一般我们用tcpdump抓包，wireshark分析包。
3. tcpdump 在 Linux 下如何抓包？
    tcpdump -i(指定网络接口) -c(指定数目) icmp(ping的协议，指定协议) -w(保存到*.pcap文件中)
4. Wireshark ⼯具如何分析数据包？
    通过载入tcpdump抓取后的pcap文件来可视化分析
5. 如何模拟SYN,ACK丢包？
   通过设置iptables防火墙，curl申请连接
6. 如果TCP 第⼀次握⼿ SYN 丢包会发生什么？
    当客户端发起的 TCP 第⼀次握⼿ SYN 包，在超时时间内没收到服务端的ACK，就会在超时重传 SYN 数据包，每次超时重传的 RTO 是翻倍上涨的，直到 SYN 包的重传次数到达限定值后，客户端不再发送 SYN 包
7. 如果TCP 第⼆次握⼿ SYN、 ACK 丢包会发生什么？
    当 TCP 第⼆次握⼿ SYN、 ACK 包丢了后，客户端 SYN 包会发⽣超时重传，服务端 SYN、 ACK 也会发⽣超时重传。重传次数由各自的参数控制。
8. 如果TCP 第三次握⼿ ACK 丢包会发生什么？
    服务端⼀直收不到 TCP 第三次握⼿的 ACK，则会⼀直重传 SYN、 ACK 包，直到重传次数超过限定值，服务端就会断开 TCP 连接。客户端则会有两种情况，如果客户端没发送数据包，⼀直处于 ESTABLISHED 状态，达到最大的保活时间断开。如果客户端发送了数据包，⼀直没有收到服务端对该数据包的确认报⽂，则会⼀直重传该数据包，直到达到重传限定值，客户端就会断开 TCP 连接。
9. 说一说TCP 快速建⽴连接（fast open）对http请求的影响
    常规http get请求，需要2.5RTT时延，如果第三次握⼿发起 HTTP GET 请求，需要 2 个 RTT 的时延。对于fastopen，在第⼀次建⽴连接的时候，服务端在第⼆次握⼿产⽣⼀个 Cookie （已加密）并通过 SYN、 ACK 包⼀起发给客户端，还是需要2RTT.但在下次请求，客户端可以直接发送SYN+cookie以及HTTP GET，服务端即可直接回复SYN+ACK+DATA,只需要1RTT时间。
10. 如何在包⾥看出发送窗⼝的⼤⼩？
    很难判断。因为发送窗⼝虽然是由接收窗⼝决定，但是它⼜可以被⽹络因素影响，也就是拥塞窗⼝，实际上发送窗⼝是值是 min(拥塞窗⼝，接收窗⼝)
11. 发送窗⼝和 MSS 有什么关系？
    发送窗⼝决定了⼀⼝⽓能发多少字节，⽽ MSS 决定了这些字节要分多少包才能发完。
12. 发送⽅在⼀个窗⼝发出 n 个包，是不是需要 n 个 ACK 确认报⽂？
    不⼀定，因为 TCP 有累计确认机制，所以当收到多个数据包时，只需要应答最后⼀个数据包的 ACK 报⽂就可以了。
13. 说一说TCP的延迟确认
    没有携带数据的 ACK，它的⽹络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报⽂。当有响应数据要发送时， ACK 会随着响应数据⼀起⽴刻发送给对⽅当没有响应数据要发送时， ACK 将会延迟⼀段时间，以等待是否有响应数据可以⼀起发送如果在延迟等待发送 ACK 期间，对⽅的第⼆个数据报⽂⼜到达了，这时就会⽴刻发送 ACK。
14. Nagle算法或延迟确认会有什么问题？
    Nagle算法和延迟确认同时使用会造成额外的网络时延。当有响应数据要发送时， ACK 会随着响应数据⼀起⽴刻发送给对⽅。当没有响应数据要发送时， ACK 将会延迟⼀段时间，以等待是否有响应数据可以⼀起发送。如果在延迟等待发送 ACK 期间，对⽅的第⼆个数据报⽂⼜到达了，这时就会⽴刻发送 ACK。所以只能同时开启一个。
15. 为什么⽐如三次握⼿之后的那个报⽂的和第三次的确认报文seq一样？
    客户端没有传输数据。长度为0
#### 3.4 半连接和全连接队列

1. 什么是TCP半连接队列和全连接队列？
    第一次握手,服务端收到客户端发起的 SYN 请求后， 内核会把该连接存储到半连接队列.第三次握⼿,服务端收到 ACK 后， 内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调⽤ accept 函数时把连接取出来。

2. 如何知道应⽤程序的 TCP 全连接队列⼤⼩？
    ss -lnt ,Recv-Q：当前全连接队列的⼤⼩,Send-Q：当前全连接最⼤队列⻓度，⾮ LISTEN 状态分别为已收到但未被应⽤进程读取的字节数,已发送但未收到确认的字节数

3. 如何模拟 TCP 全连接队列溢出的场景？
    wrk, HTTP 压测

4. TCP全连接队列溢出后会发生什么?
    默认⾏为tcp_abort_on_overflow = 0,服务器扔掉客户端发过来的ack.也可以设置tcp_abort_on_overflow = 1表示server发送⼀个reset复位报文给 client，表示废掉这个握⼿过程和这个连接.可以通过netstat -s | grep overflowed查看丢弃的连接数

5. tcp_abort_on_overflow为什么默认设置为0
    这样更有利于应对突发流量,提⾼连接建⽴的成功率.因为此时客户端连接状态为ESTABLISHED,只要服务器没有为请求回复 ACK，请求就会被多次重发.如果服务器上的进程只是短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报⽂由于含有 ACK，仍然会触发服务器端成功建⽴连接。只有当TCP 全连接队列会⻓期溢出时，才能设置为 1 以尽快通知客户端

6. 如何增⼤ TCP 全连接队列呢?
    TCP 全连接队列的最⼤值sk_max_ack_backlog取决于 somaxconn(128) 和 backlog(511) 之间的最⼩值

7. 如何查看 TCP 半连接队列⻓度？
    服务端处于 SYN_RECV 状态的 TCP 连接数目，就是 TCP 半连接队列数目. nestat | grep SYN_RECV | wc -l

8. 如何模拟 TCP 半连接队列溢出场景？
    hping3 ⼯具模拟 SYN 攻击, 并关闭 tcp_syncookies。对服务端⼀直发送 TCP SYN 包，但是不回第三次握⼿ ACK。又称 SYN 洪泛、 SYN 攻击、 DDos 攻击。

9. TCP 半连接队列的最⼤值是如何决定的？
    - 半连接队列的⼤⼩并不单单只跟 tcp_max_syn_backlog(512)有关。当 max_syn_backlog > min(somaxconn, backlog) 时， 半连接队列最⼤值 max_qlen_log = min(somaxconn,backlog) * 2;当 max_syn_backlog < min(somaxconn, backlog) 时， 半连接队列最⼤值 max_qlen_log =max_syn_backlog * 2;
    - 每个 Linux 内核版本「理论」半连接最⼤值计算⽅式会不同
      在 Linux 5.0.0 的时候，「理论」半连接最⼤值就是全连接队列最⼤值

10. 第一次握手SYN因队列长度被丢弃的条件
    - 如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；
    - 若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；
    - 如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列⻓度⼩于(max_syn_backlog >> 2)，则会丢弃；


11. 半连接队列最⼤值max_qlen_log 就表示服务端处于 SYN_REVC 状态的最⼤个数吗？
    不一定。如果「当前半连接队列」 没超过「理论半连接队列最⼤值」，但是超过 max_syn_backlog - (max_syn_backlog >> 2)，那么处于 SYN_RECV 状态的最⼤个数就是 max_syn_backlog - (max_syn_backlog >> 2)；如果「当前半连接队列」 超过「理论半连接队列最⼤值」，那么处于 SYN_RECV 状态的最⼤个数就是「理论半连接队列最⼤值」；

12. 如果 SYN 半连接队列已满，只能丢弃连接吗？
      开启 syncookies 功能就可以在不使⽤ SYN 半连接队列的情况下成功建⽴连接。服务器根据当前状态计算出⼀个值，放在⼰⽅发出的 SYN+ACK 报⽂中发出，当客户端返回 ACK 报⽂时，取出该值验证，如果合法，就认为连接建⽴成功
13. 如何查看由于 SYN 半连接队列已满，⽽被丢弃连接的情况？
        netstat -s  | grep
14. SYN半连接满了怎么办？（如何防御 SYN/DDOS 攻击？）
    - 增⼤半连接队列
        想增⼤半连接队列，我们得知不能只单纯增⼤ tcp_max_syn_backlog 的值，还需⼀同增⼤ somaxconn 和 backlog，也就是增⼤全连接队列
    - 开启 tcp_syncookies 功能
    - 减少 SYN+ACK 重传次数
         SYN_REVC 状态的 TCP 连接会重传SYN+ACK ，当重传超过次数达到上限后，就会断开连接

15. TCP 内核参数在哪？
     在/proc/sys/net/ipv4/tcp*

#### 3.5 TCP性能提升策略
#### 3.5.1 三次握⼿的性能提升
1. 客户端优化
     - 优化SYN_SENT状态的SYN超时重传次数。重发的次数由 tcp_syn_retries 参数控制，默认是 5 次，每次超时的时间是上⼀次的 2 倍。怎么调整同下。
2. 服务端优化
     - 优化SYN_RCV 状态的 SYN+ACK 报⽂重传。当⽹络繁忙、不稳定时，报⽂丢失就会变严重，此时应该调⼤重发次数。反之则可以调⼩重发次数。 修改重发次数的⽅法是，调整 tcp_synack_retries 参数
     - 调整SYN半连接队列长度
     - 调整accept全连接队列长度
3.  绕过三次握手
   - 三次握⼿建⽴连接造成的后果是， HTTP 请求必须在⼀个 RTT（从客户端到服务器⼀个往返的时间）后才能发送。
   - 开启 TCP Fast Open 功能，这个功能可以减少 TCP 连接建⽴的时延
4. TCP Fast Open 功能的⼯作⽅式是什么？
   - 第⼀次发起 HTTP GET 请求的时候，还是需要正常的三次握⼿流程。客户端发送 SYN 报⽂，该报⽂包含 Fast Open 选项。⽀持 TCP Fast Open 的服务器⽣成 Cookie，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。
   - 客户端发送 SYN 报⽂，该报⽂包含「数据」以及此前记录的 Cookie；服务器会对收到 Cookie 进⾏校验：如果 Cookie 有效，服务器将在 SYN-ACK 报⽂中对 SYN 和「数据」进⾏确认。如果 Cookie ⽆效，服务器将丢弃 SYN 报⽂中包含的「数据」，且其随后发出的 SYN-ACK 报⽂将只确认 SYN 的对应序列号。如果服务器接受了 SYN 报⽂中的「数据」，服务器可在握⼿完成之前发送「数据」， 这就减少了握⼿带来的1 个 RTT 的时间消耗； 
5. 如果TCP Fast Open的SYN的数据没有被确认会怎样？
    客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报⽂中发送的「数据」没有被确认，则客户端将重新发送「数据」；
6. TFOCookie存放在哪？
    cookie 的值是存放到 TCP option 字段
7. Linux 下怎么打开 TCP Fast Open 功能呢？
    在 Linux 系统中，可以通过设置 tcp_fastopn 内核参数，来打开 Fast Open 功能。

#### 3.5.2 TCP 四次挥⼿的性能提升
1. TCP关闭连接的方式有哪几种？
    RST 报⽂关闭和 FIN 报⽂关闭。如果进程异常退出了，内核就会发送 RST 报⽂来关闭，不⾛四次挥⼿流程而暴⼒关闭连接。安全关闭连接的⽅式必须通过四次挥⼿，它由进程调⽤ close 和 shutdown 函数发起 FIN 报⽂。
2. 调⽤ close 函数和 shutdown 函数有什么区别？
   - 调⽤了 close 函数意味着完全断开连接， 完全断开不仅指⽆法传输数据，⽽且也不能发送数据。 此时，调⽤了close 函数的⼀⽅的连接叫做「孤⼉连接」
   -  shutdown 函数， 它可以控制只关闭⼀个⽅向的连接
      -  SHUT_RD(0)关闭连接的「读」这个⽅向，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数据进⾏ ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。
      -  关闭连接的「写」这个⽅向，这就是常被称为「半关闭」的连接。如果发送缓冲区还有未发送的数据，将被⽴即发送出去，并发送⼀个 FIN 报⽂给对端。
3. 如果遇到恶意攻击， FIN 报⽂根本⽆法发送出去怎么办？
   - ⾸先TCP 必须保证报⽂是有序发送的，当发送缓冲区还有数据没有发送时， FIN 报⽂不能提前发送
   - 其次， TCP 有流量控制功能，当接收⽅接收窗⼝为 0 时，发送⽅就不能再发送数据。所以，当攻击者下载⼤⽂件时，就可以通过接收窗⼝设为 0 ，这就会使得 FIN 报⽂都⽆法发送出去，那么连接会⼀直处于FIN_WAIT1 状态也不能提前发送。
   - 调整 tcp_max_orphans 参数，它定义了「孤⼉连接」的最⼤数量,如果孤⼉连接数量⼤于它，新增的孤⼉连接将不再⾛四次挥⼿，⽽是直接发送 RST 复位报⽂强制关闭。
4. 哪几种情况发送RST报文强制关闭连接
   进程异常退出时和孤儿连接超量时
5. 为什么FIN_WAIT2和 TIME_WAIT默认都要保持 2MSL（60s） 时⻓？
        因为这两个状态都需要保持 2MSL 时⻓，这样当, FIN(FIN_WAIT2)， ACK(TIME_WAIT)丢失时，被动方重发的报文会在第二个MSL内到达，保证连接正常关闭
6. 为什么不是4或者8MSL？
        这意味连续两次丢包，对于丢包率达到百分之⼀的糟糕⽹络，连续两次丢包的概率只有万分之⼀，这个概率实在是太⼩了，忽略它⽐解决它更具性价比
7. TIME_WAIT状态过多会怎样？
   - 如果是客户端，由于客户端 TIME_WAIT 过多，就会导致端⼝资源被占⽤，⽆法创建新连接
   - 如果是服务端，会导致系统资源被占满，⽆法创建新连接
8. 主动方优化
   - 降低主动方FIN重传次数
        主动发起 FIN 报⽂断开连接的⼀⽅，如果迟迟没收到对⽅的 ACK 回复，则会重传 FIN 报⽂，重传的次数由tcp_orphan_retries 参数决定。
   - 调整FIN_WAIT2状态的时间（只适用于close）
        如果 tcp_fin_timeout 秒内没有收到对⽅的 FIN 报⽂，连接就直接关闭。
   - 调整孤儿连接最大个数（只适用于close）
        大于最大个数则直接发送RST复位报文强制关闭，不走四次挥手
   - 调整TIME_WAIT最大个数（ tcp_max_tw_buckets ）
        超过该个数则不经历 TIME_WAIT ⽽直接关闭。当服务器的并发连接增多时应增大，减少不同连接间数据错乱的概率。但也不是越⼤越好，毕竟内存和端⼝都是有限的。
   - 复⽤处于 TIME_WAIT 状态的连接（tcp_tw_reuse ）
        只⽤于客户端（建⽴连接的发起⽅），因为在connect处启用
9. 复⽤处于 TIME_WAIT 状态的连接会不会使得连接无法正常关闭吗？
    不会，该复用要求连接双方必须打开时间戳，而时间戳保证了重复的数据包会因为时间戳过期被⾃然丢弃。当客户端复用连接后再发起新的连接时，会向服务端发送SYN，而LAST_ACK 状态的服务端会回复RST报文从而退出该状态。之后就是正常的三次握手，会花费1s在SYN重传上。
10. 为什么被动方CLOSE_WAIT没有时间限制？
    因为主动发可能是shutdown半关闭连接，还可能发送或接受数据
11. 当通过netstat发现大量CLOSE_WAIT状态该怎么办？
    需要排查应⽤程序，因为可能因为应⽤程序出现了 Bug， read 函数返回 0 时，没有调⽤ close 函数。
12. 什么情况下四次挥手可能会变成三次挥手？
    被动方迅速调用close函数，那么被动⽅的 ACK 和 FIN 有可能在⼀个报⽂中发送
13. 如果连接双⽅同时关闭连接，会怎么样？
    TCP双全工，可以同时发送FIN报文，都进⼊了 FIN_WAIT1 状态。双⽅在等待 ACK 报⽂的过程中，都等来了 FIN 报⽂。连接会进⼊⼀种叫做CLOSING 的新状态，它替代了 FIN_WAIT2 状态。接着，双⽅回复 ACK 确认对⽅发送通道的关闭后，进⼊TIME_WAIT 状态，等待 2MSL 的时间后，连接⾃动关闭。
14. 被动方的优化
    - 出现⼤量 CLOSE_WAIT 状态的连接时，应当从应⽤程序中找问题。
    - 控制重发 FIN 报⽂次数
         LAST_ACK 状态，在未等到 ACK 时，会重发FIN

#### 3.5.3 TCP 传输数据的性能提升
1. TCP超时重传有什么缺点？
   - 影响TCP的传输效率，如果存在大量超时重传说明网络状况很糟糕，超时重传的报文也会占用一部分网络资源
   - 由于TCP超时重传所以当TCP报文发出后，并不会⽴⻢从内存中删除。当连接数量非常多时，会占用系统内存资源
2. TCP如何传输包
   并⾏批量发送报⽂，再批量确认报⽂。如果有包丢失了，也不会进行重发，通过下一个确认应答进行确认。
3. 滑动窗口的作用是什么？
    接受方处理能力优先，发送⽅需要根据「接收⽅」的实际接收能⼒控制发送的数据量。
4. 发送⽅的窗⼝等价于接收⽅的窗⼝吗？
    如果不考虑拥塞控制，发送⽅的窗⼝⼤⼩「约等于」（存在时延）接收⽅的窗⼝⼤⼩
5. 滑动窗口大小是多少？
    定义在TCP头部，2个字节 * 窗⼝扩⼤因⼦（TCP 选项字段），最大为1G
6. 如何扩大滑动窗口的最大值的大小？
    打开窗口扩大因子功能，设置TCP内核参数tcp_window_scaling
7. 如何扩大滑动窗口的大小？
    扩大接受与发送缓冲区的大小，内核缓冲区决定了滑动窗⼝的上限
8. 接受缓冲区越大越好吗？
    不是。网络传输能力有限制，且缓冲区在内存中会影响服务器的并发能力
9. TCP的传输速度取决于什么？
    发送窗⼝与接收窗⼝，以及⽹络设备传输能⼒
10. 如何确定最⼤传输速度？
    带宽时延积BDP = RTT * 带宽.
11. 发送缓冲区大小如何确定？
    发送缓冲区⼤⼩决定了发送窗⼝的上限，⽽发送窗⼝⼜决定了「已发送未确认」的⻜⾏报⽂的上限。因此，发送缓冲区不能超过「带宽时延积」。超过则网络过载丢包，小于则没有充分利用网络
12. 怎样调整缓冲区⼤⼩？
   - 调节发送缓冲区范围
        设置TCP内核参数tcp_wmem最大最小值，系统动态调节
   - 调节接收缓冲区范围
        设置TCP内核参数tcp_rmem，系统动态调节，同时需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能
11. 什么时候调节接受缓冲区的大小？
    接收缓冲区可以根据系统空闲内存的⼤⼩来调节接收窗⼝。如果系统的空闲内存很多，就可以⾃动把缓冲区增⼤⼀些，这样传给对⽅的接收窗⼝也会变⼤，因⽽提升发送⽅发送的传输数据数量；反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常⼯作
12. 如何调节TCP 内存范围
        设置TCP内核参数tcp_mem，系统动态调节。超出最大内存范围将无法建立TCP连接
13. 如何提高服务器的并发能力？
    为了兼顾⽹速与⼤量的并发连接， 我们应当保证缓冲区的动态调整的最⼤值达到带宽时延积，⽽最⼩值保持默认的 4K 不变即可。⽽对于内存紧张的服务⽽⾔，调低默认值是提⾼并发的有效⼿段。同时，如果这是⽹络 IO 型服务器，那么， 调⼤ tcp_mem 的上限可以让 TCP 连接使⽤更多的系统内存，这有利于提升并发能⼒
14. 如何优化TCP 传输数据的性能
    - 扩大窗口大小
    - 调整发送和接受缓冲区范围
    - 打开接受缓冲区动态调节
    - 调整内存范围
15. 讲一讲TCP的性能提升
    - 三次握手的性能提升
    - 四次挥手的性能提升
    - 传输过程中的性能提升
