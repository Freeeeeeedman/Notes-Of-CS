#### python
1. 深拷贝浅拷贝
   - 浅拷贝，指的是重新分配一块内存，创建一个新的对象，但里面的元素是原对象中各个子对象的引用。
   - 深拷贝，是指重新分配一块内存，创建一个新的对象，并且将原对象中的元素，以递归的方式，通过创建新的子对象拷贝到新对象中。因此，新对象和原对象没有任何关联。
   - 浅拷贝:切片，深拷贝：deepcopy()
2. 列表和元组的区别
   - 列表是动态数组，它们可变且可以重设长度（改变其内部元素的个数）。
        实际分配空间大于需要的元素数目，避免额外的内存复制
   - 元组是静态数组，它们不可变，且其内部数据一旦创建便无法改变。
        append添加元素复杂度为O(n),需要分配和复制
   - 元组缓存于Python运行时环境，这意味着我们每次使用元组时无须访问内核去分配内存
        对于长度为1~20的元组，不需要分配新的内存
3. 装饰器的概念，通常用它做什么，哪些场景下
  
   - 装饰器是给现有的模块增添新的小功能，可以对原函数进行功能扩展，而且还不需要修改原函数的内容，也不需要修改原函数的调用。
   - 面向对象编程的开放封闭原则
     - 对扩展开放，意味着有新的需求或变化时，可以对现有代码进行扩展，以适应新的情况。
     - 对修改封闭，意味着类一旦设计完成，就可以独立其工作，而不要对类尽任何修改。
   - 函数装饰器
        ```
        import time
        
        
        def baiyu():
            print("我是攻城狮白玉")
            time.sleep(2)
        
        
        def count_time(func):
            def wrapper(*args, **kwargs):
                t1 = time.time()
                func()
                print("执行时间为：", time.time() - t1)
        
            return wrapper
        
        
        if __name__ == '__main__':
            baiyu = count_time(baiyu)  # 因为装饰器 count_time(baiyu) 返回的时函数对象 wrapper，这条语句相当于  baiyu = wrapper    
        ```
   - 类装饰器
     - 调用__init__方法创建实例，传递参数，并调用__call__方法实现对被装饰函数功能的添加。
      ```
        from functools import wraps
        #类的装饰器写法， 不带参数
        class Hint(object):
            def __init__(self, func):
                self.func = func

            def __call__(self, *args, **kwargs):
                print('{} is running'.format(self.func.__name__))
                return self.func(*args, **kwargs)      
      ```
4. 闭包
    如果一个外函数中定义了一个内函数，且内函数体内引用到了体外的变量，这时外函数通过return返回内函数的引用时，会把定义时涉及到的外部引用变量和内函数打包成一个整体（闭包）返回。
5. python匿名函数
   - lambda关键字来定义函数
   - sum = lambad a, b, c : a + b + c
   - 作为函数的参数或者返回值
   - 任意多个参数和一个返回值
   - 配合内置函数使用，如apply

#### 计算机网络
1. 说一说OSI七层/五层网络模型
    OSI即开放式系统互联，用于描述计算机网络通信的基本框架
    - **应?层**
        - 负责给应?程序提供统?的接?，方便应用从网络中接收的数据
        - HTTP, DNS
    - **表示层**
        - 不同系统之间通信语法问题，主要负责数据格式的转换。比如Linux系统给Windows系统发包
    - **会话层**
        - 负责建?、管理和终?表示层实体之间的通信会话；
    - **传输层**
        - 负责端到端的数据传输；
        - 数据为**段Segments**
        - TCP, UDP
    - **?络层**
        - 将网络地址转化为对应的物理地址，并决定如何将数据从发送方路由到接收方。负责数据的路由、转发、分?；
        - 数据为**包Packages**，路由器工作在这层
        - IP, ICMP, IGMP，NAT
    - **数据链路层**
        - 负责数据的封帧和差错检测，以及 MAC 寻址；
        - 本层将比特数据组成**帧Frames**，交换机工作在这层
        - ARP, RARP
    - **物理层**
        - 负责在物理?络中传输数据帧；主要定义了物理设备的标准，如网线的类型，光纤的接口类型，各种传输介质的传输速率。
        - 这层数据叫做**比特Bits**。网卡工作在这层
2. HTTP 与 HTTPS 有哪些区别？
   - HTTP**明?传输**，存在安全?险的问题。 HTTPS在TCP和HTTP之间加?了 SSL/TLS 安全协议，使得报?能够加密传输。
   - HTTP 连接建?相对简单， TCP 三次握?之后便可进? HTTP 的报?传输。? HTTPS 在 TCP 三次握?之后，还需进? **SSL/TLS 的握?过程**，才可进?加密报?传输。
   - HTTP 的**端?号**是 80， HTTPS 的端?号是 443。
   - HTTPS 协议需要向 CA（证书权威机构）申请**数字证书**，来保证服务器的身份是可信的
3. 对于 HTTP/1.1 的性能瓶颈， HTTP/2 做了什么优化？
   - **压缩头部**，在客户端和服务器同时维护?张头信息表，对于多个请求，不发生相同字段，只发送索引号
   - **?进制格式**，HTTP/2 不再像 HTTP/1.1 ?的纯?本形式的报?，?是?进制格式，称为头信息帧和数据帧。这样解析时就不需要再将报文转换为二进制，直接解析。
   - **数据流**，HTTP/2 的数据包不是按顺序发送的，而是数据流。每个数据流都标记着?个独???的编号来区分对不同请求的响应。客户端还可以指定数据流的优先级。优先级?的请求，服务器就先响应该请求。
   - **多路复?**。HTTP/2 是可以在?个连接中并发多个请求或回应。移除了 HTTP/1.1 中的串?请求，不需要排队等待，也就不会再出现**应用层层面「队头阻塞」问题**， 降低了延迟，?幅度提?了连接的利?率。例如先回应请求A，发现请求A耗时，回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。
   - **服务器推送**。HTTP/2 还在?定程度上改善了传统的「请求 - 应答」?作模式，服务不再是被动地响应，也可以主动向客户端发送消息。如在浏览器刚请求 HTML 的时候，就提前把可能会?到的等静态资源主动发给客户端，减少延时的等待。
4. TCP 和 UDP 区别
   - **连接**
       TCP 是?向连接的传输层协议，传输数据前先要建?连接。
       UDP 是不需要连接，即刻传输数据。
   - **服务对象**
        TCP 是?对?的两点服务，即?条连接只有两个端点
        UDP ?持?对?、?对多、多对多的交互通信
   - **可靠性**
        TCP 是可靠交付数据的，数据可以?差错、不丢失、不重复、按需到达。
        UDP 是尽最?努?交付，不保证可靠交付数
   - **应用场景不同**
        TCP:?向连接，能保证数据的可靠性交付,**FTP ?件传输, HTTP / HTTPS**
        UDP:?向?连接，随时发送数据,简单高效：包总量较少的通信，如 DNS，视频、?频等**多媒体通信?播**通信         
   - **拥塞控制、流量控制**
        TCP 有拥塞控制和流量控制机制，保证数据传输的安全性
        UDP 则没有，即使?络?常拥堵了，也不会影响 UDP 的发送速率
   - **?部开销**
        TCP:不确定，无选项头部20字节，最大60字节
        UDP：确定，8字节
   - **传输?式**
        TCP 是流式传输，面向字节流，一个消息可能被拆分为多个包，没有边界，但保证顺序和可靠。
        UDP 是是面向报文的协议，?个包?个包的发送，消息不会被拆分为多个包，是有边界的，但可能会丢包和乱序
   - **分?不同**
        TCP 的数据??如果**?于 MSS ??，则会在传输层进?分?**，?标主机收到后，也同样在传输层组装 TCP数据包，如果中途丢失了?个分?，只需要传输丢失的这个分?[MSS（最大数据报文）+ 首部=数据包]
        UDP 的数据??如果 **?于 MTU ??，则会在 IP 层进?分?**，?标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了?个分?，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样传输效率?常差，所以**通常 UDP 的报?应该?于 MTU**。（以太网(Ethernet)数据帧的长度必须在46-1500字节之间,这是由以太网的物理特性决定的.这个1500字节被称为链路层的MTU(最大传输单元).）
5. 说一说**TCP的三次握手的过程（状态变迁）**
   - 首先客户端和服务端都处在CLOSE状态，服务端开始监听端口，接着处于LISTEN状态
   - 然后客户端初始化报文的序列号，SYN标志位置为1，将SYN报文发送给服务端，接着处于SYN_SENT状态
   - 服务端收到SYN报文，初始化自己报文的序列号，确认应答号为收到的SYN报文序列号+1，SYN和ACK标志位置为1，将SYN+ACK报文发给客户端，接着处于SYN_RCVD状态
   - 客户端收到ACK+SYN报文，回应最后一个应答报文，将ACK标志位置为1，确认应答号为ACK+SYN报文的序列号+1，接受处于ESTABLISHED状态
   - 服务端接收到ACK报文，处于ESTABLISHED状态
     netstat -napt 命令
6. 为什么是三次握?？不是两次握手？
   - ?要原因是为了**防?历史连接初始化了连接**
     -  客户端连续发送多次 SYN 建?连接的报?，在?络拥堵情况下：?个「旧 SYN 报?」?「最新的 SYN 」 报?早到达了服务端；那么此时服务端就会回?个 SYN + ACK 报?给客户端；**客户端收到后可以根据?身的上下?，判断这是?个历史连接（序列号过期或超时），那么客户端就会发送RST 报?给服务端，表示中?这?次连接。而如果不是历史连接，则第三次发送的报?是 ACK 报?，通信双?就会成功建?连接**；
   - **同步双?初始序列号**
      - 接收?可以去除重复的数据；接收?可以根据数据包的序列号按序接收；可以标识发送出去的数据包中， 哪些是已经被对?收到的；
      - **?来?回，才能确保双?的初始序列号能被可靠的同步。?两次握?只保证了??的初始序列号能被对?成功接收，没办法保证双?的初始序列号都能被确认接收。**
   - **避免资源浪费**
        只有两次握手，导致没有第三次的ACK时，如果客户端的 SYN 阻塞了，客户端就会超时重复发送多次 SYN 报?，而服务器也无法判断客户端是否已接收到第二次发送的ACK，所以会在收到请求后就会建?多个冗余的?效链接，造成不必要的资源浪费
7. 说一说**TCP四次挥手**
   - 先是客户端和服务端都处于ESTABLISH状态。如果是客户端准备关闭连接，则发送FIN标志位为1的FIN报文，进入FIN_WAIT1状态
   - 服务端收到FIN报文，回复ACK报文，进入CLOSED_WAIT状态
   - 客户端收到ACK报文，进入FIN_WAIT2状态
   - 服务端处理完数据后发送FIN报文，进入LAST_ACK状态
   - 客户端收到FIN报文，回复ACK，进入TIME_WAIT状态
   - 服务端收到ACK报文，进入CLOSED状态
   - 客户端在经过2MSL后，进入CLOSED状态，连接关闭
8. **为什么需要 TIME_WAIT 状态（TIME_WAIT时间过短会怎么样）**？
   - **防?旧连接的数据包**
        旧的TCP连接被复用后，客户端可能正常接受旧数据，导致数据错乱。**经过 2MSL 这个时间， ?以让两个?向上的数据包都被丢弃**，使得原来连接的数据包在?络中都?然消失，再出现的数据包?定都是新建?连接所产?的
   - **保证双方连接正确关闭**
        等待?够的时间以确保最后的 ACK 能让被动关闭?接收，从?帮助其正常关闭。**最后一次挥手ACK报文丢失，如果TIME_WAIT状态过短，那么服务端会一直处在LAST_ACK状态。那么当客户端发起新的SYN报文，会导致服务端回复RST报文，新的连接不能建立。而如果TIME_WAIT时间够长，那么当ACK丢失时，服务端会重发FIN报文并等待客户端发新的ACK报文**。
9.  **键??址到??显示的总体过程**
   - 首先浏览器解析 URL
   - 接着对URL进?解析之后，浏览器确定了Web服务器和?件名，?成HTTP请求消息
   - 接着通过DNS服务器查询服务器域名对应的 IP 地址
   - 通过 DNS 获取到 IP 后，就可以把 HTTP 的传输?作交给操作系统中的协议栈
   - 协议栈分为四层,应用程序层,操作系统层,驱动程序层以及硬件层,应?程序调? Socket 库，将应?层数据拷?到 Socket 发送缓冲区中,然后通过操作系统层TCP协议来传输数据
   - TCP 传输数据之前，要先三次握?建?连接,保证双?都有发送和接收的能?.接着生成包含数据的TCP报文给IP协议
   - IP协议将数据封装成?络包
   - 接下来通过ARP协议确定下一步要转发的目的地的MAC地址,再给网络包添加MAC头部
   - 然后网络包通过网卡由数字信息转换为电信号发送到交换机
   - 交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到路由器
   - 路由器通过查表发送给下一个路由器或者目标设备
   - 通过层层转发后网络包到达目的地
   - 数据包抵达服务器后，服务器检查MAC地址是否一致.接着检查IP是否一致,根据IP头中协议项，知道上层是 TCP 协议。接着检查TCP报文的序列号,是否是想要的.是则存入缓存中并返回ACK，不是就丢弃。同时TCP头部??还有端?号，将数据拷?到端口号对应的Socket的接收缓冲区。而HTTP 的服务器正在监听这个端?号,从Socket 接收缓冲区读取数据进行处理.最后服务器返回HTTP响应报文,再经过与之前相同的步骤达到客户端.最后，客户端可以通过四次挥手断开连接.


#### MySQL
1. B+树是如何进行查询的？
    - 从**根节点**开始，先通过**主键二分法**定位到页内范围包含查询值的页，在该页中查找更详细的**目录项**
    - 再在**非叶子节点**中，继续通过二分法快速定位到符合页内范围**包含查询值的页**，到对应叶子节点查找记录
    - 在**叶子节点**中，通过**槽**查找记录时，使用二分法快速定位要查询的记录在哪个槽，定位到槽后，再**遍历槽内的所有记录**，找到所需的记录    
2. 说一说InnoDB为什么使用B+树而不是其他数据结构？
    - **B+Tree与BTree**的区别（聚簇索引的特点，B+树有什么特点,性能比较）
        - **查找IO操作更少，内存占用更少**
            B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据。导致这样使得同样大小的磁盘页可以容纳更多节点元素，树的层级更少，在相同数据量下，Ｏ操作更少。同时如果用B树查找，查找过程中**不需要的节点数据也会加载到内存中**，占用内存资源
        - **性能稳定**
            Ｂ树（平衡多路查找树）的查找只需找到匹配元素即可，最好情况下查找到根节点，最坏情况下查找到叶子结点，所以性能很不稳定，而Ｂ＋树每次必须查找到叶子结点，性能稳定
        - **B+树的插入和删除效率更高**
           - B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快。B 树没有冗余节点，删除节点的时候非常复杂，比如删除根节点中的数据，可能涉及复杂的树的变形
           - B+ 树的插入也是一样，有冗余节点，插入可能存在节点的页分裂（如果节点饱和），但是最多只涉及树的一条路径。而且 B+ 树会自动平衡，不需要像更多复杂的算法，类似红黑树的旋转操作等
        - **更适合范围查找**
           B+树范围查询首先通过二分查找，找到范围下限，然后同过叶子结点的链**表顺序遍历**，直至找到上限即可，效率更高。而B树则是通过**二分法到范围下限，在不断通过中序遍历**，直到查找到范围的上限，整个过程比较耗时；
    - B+Tree vs 平衡二叉搜索树（AVL树）
        - 平衡二叉搜索树查找和插入数据都是O(log2N)基本，连续插入新元素开销不大。
        - 对于有 N 个叶子节点且节点允许的最大子节点个数为 d 个的 B+Tree，其搜索复杂度为O(logdN)。相同数据量，**二叉树相较B+树层级更多，导致查找数据的IO操作更**多
    - B+Tree vs Hash
        Hash等值查询的时候效率高O(1)，但是**范围查询时需要扫描全表**
    - B+Tree vs 有序数组
        有序数组在等值查询和范围查询场景中的性能就都非常优秀O(logN),但**只适用于静态表，增删都会导致很大的开销**
3. 说一说MySQL有哪些索引？
    - 按「**数据结构**」分类：B+tree索引、Hash索引。
    - 按「**物理存储**」分类：聚簇索引（主键索引）、二级索引（辅助索引）。
    - 按「**字段特性**」分类：主键索引、唯一索引、普通索引、前缀索引（后三者都是二级索引）。
    - 按「**字段个数**」分类：单列索引、联合索引
4.  为什么使用联合索引
    - **减少开销**
        建立一个联合索引, 实际上相当于**联合建立了多个单列索引**. 而每多一个索引，都会增加**写操作的开销和磁盘空间的开销**。对于大量数据的表，使用联合索引会大大的减少开销！比如我们对a, b, c三个字段建立一个联合索引(a, b, c), 其实就相当于建立了三个单列索引, 在我们做这样的查询时, 比如:select * from user where a = 10 and b = 11, 我们只需要查询一颗联合索引树就可以得到结果, 不需要查询两个单列索引树, 然后再将各自所得的结果过滤合并, 这样可以大大减少磁盘I/O次数, 减少开销, 提高性能
    - **覆盖索引**
        使用联合索引的话, 有可能出现覆盖索引的情况, 即我们要查询的数据全部在这一棵联合索引树中, 那么我们只要查询一次就可以从叶子节点中得到数据, 而**不用再回表**去聚簇索引树中查找
    - 索引列越多，通过索引筛选出的数据越少, 更加高效
5.  有什么优化索引的方法？
    - **前缀索引优化；**
        使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。**索引页能够存储的索引值越多，需要的IO操作就越少**
    - **覆盖索引优化；**
        查找的项可以直接从二级索引中得到，**避免回表**。
        假设我们只需要查询商品的名称、价格，有什么方式可以避免回表呢？建立一个联合索引
    - **主键索引最好是自增的；**
        InnoDB 创建主键索引默认为聚簇索引，数据被存放在了 B+Tree 的叶子节点上。也就是说，同一个叶子节点内的各个数据是按主键顺序存放的。自增主键插入数据时按序的，不需要移动数据。而非自增主键插入数据可能会导致页分裂，造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。
    - **索引最好设置为 NOT NUL**
        - 索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加**难以优化**，因为可为 NULL 的列会使索引、索引**统计**和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。
        - NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题，会导致更多的存储空间占用，因为 InnoDB 默认行存储格式COMPACT，会用 1 字节空间存储 NULL 值列表
    - **防止索引失效**
6.  说一说索引失效的情况
    - **对索引使用左或者左右模糊匹配有时会导致索引失效**
       也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效；因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。通过前缀查找的过程类似于一般查找，只不过每次查找都要比较当前节点的前缀和要查找的前缀的大小
    - **对索引使用函数或对索引进行表达式计算**
        因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。
    - **对索引隐式类型转换**
        MySQL在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果索引是字符串，而条件是数字，则会将索引转换为数字，就相当于使用了函数
    - **联合索引非最左匹配**
        在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。
    - 在 WHERE 子句中，如果**在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列**，那么索引会失效。
7. 什么是事务？
    **需要保证原子性、隔离性、一致性和持久性的一个或多个数据库操作称之为一个事务**
8. 事务有哪些特性？(**ACID**)
   - **原子性**（Atomicity）：
        一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样；
   - **一致性**（Consistency）：
        如果数据库中的数据全部符合现实世界中的约束，我们说这些数据就是一致的，或者说符合一致性的。
   - **隔离性**（Isolation）：
        数据库允许多个**并发**事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
   - **持久性**（Durability）：
        事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失
9.  InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？
   - 原子性是通过 **undo log（回滚日志）** 来保证的；
   - 持久性是通过 **redo log （重做日志）**来保证的；
   - 隔离性是通过 **MVCC（多版本并发控制） 或锁机制**来保证的；
   - 一致性则是通过**持久性+原子性+隔离性**来保证；
11. 这四种隔离级别具体是如何实现的呢？
   - 读操作利用多版本并发控制（ MVCC ），写操作进行加锁
       - 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；
       - 对于「读已提交」，**「每次读取数据时」都会重新生成一个 Read View**，ReadView的存在本身就保证了事务不可以读取到未提交的事务所做的更改，也就是避免了脏读现象；
       - 对于「可重复读」，「**启动事务时」生成一个 Read View，之后的操作都复用这个ReadView**，这样也就避免了不可重复读和**快照读的幻读**的问题，但是仍可能产生**当前读情况下的幻读**。（ MySQL 在REPEATABLE READ 隔离级别实际上就已经解决了 幻读 问题。）
       - 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；
   - 读、写操作都采用 加锁 的方式
       - 如果我们的一些业务场景（比如银行存款）不允许读取记录的旧版本，而是每次都必须去读取记录的最新版本。这样在读取记录的时候也就需要对其进行 加锁 操作，这样也就意味着 读 操作和 写 操作也像 写-写 操作那样排队执行。
       - 通过加锁可以解决脏写（记录锁），脏读，不可重复读，幻读（next-key锁）的问题
12. 什么是MVCC？
    **MVCC即多版本并发控制, 通过readview和「版本链」来控制并发事务访问同一个记录的行为就是MVCC**
13. ReadView在MVCC中的工作机制是什么？（MVCC是怎么实现的？）
    **通过比对Read View和记录中的事务id，来判断当前事务是否可以访问该记录**
    - ReadView包含四个字段
      - 创建该 Read View 的事务的事务 id
      - 创建 Read View 时的活跃事务列表
      - 创建 Read View 时的活跃事务列表中id最小的事务
      - 创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1；
    - 同时聚簇索引记录中包含两个**隐藏列**
      - 最近修改该记录的事务id
      - 回滚指针，指向上一个旧版本记录的undo日志
    - 这样就可以通过比对Read View和记录中的事务id，来判断当前事务是否可以访问该记录
        - 如果被访问版本的 trx_id 属性值与 ReadView 中的 creator_trx_id 值相同，意味着当前事务在**访问它自己修改过的记录**，所以该版本可以被当前事务访问。
        - 如果被访问版本的 trx_id 属性值小于 ReadView 中的 min_trx_id 值，表明生成该版本的事务**在当前事务生成 ReadView 前已经提交**，所以该版本可以被当前事务访问。
        - 如果被访问版本的 trx_id 属性值大于 ReadView 中的 max_trx_id 值，表明生成该版本的事务**在当前事务生成 ReadView 后才开启**，所以该版本不可以被当前事务访问。
        - 如果被访问版本的 trx_id 属性值在 ReadView 的 min_trx_id 和 max_trx_id 之间，那就需要判断一下**trx_id 属性值是不是在 m_ids 列表中**，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问
14. MySQL 有哪些锁
   - 根据加锁的范围，可以分为全局锁、表级锁和行锁
   - 表级锁包括表锁，元数据锁，意向锁，AUTO-INC锁
15. 为什么redo日志是两阶段提交的？
    - 因为不这么做会导致主从不一致。
    - 如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。MySQL 重启后，通过 redo log 能将 数据恢复，但是 binlog 里面没有记录这次，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这次更新，和主库不一致
    - 如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。那么主库就没有更新数据，而从库则更新了数据，同样造成了主从不一致。
16. 两阶段提交的具体过程
    - 两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是分别是「准备（Prepare）阶段」和「提交（Commit）阶段」
    - 准备阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；
    - 提交阶段：把 XID 写入到 binlog，然后将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit

#### 算法
1. 算法的稳定性
   - 含义
     - 稳定性是指，在需要进行排序操作的数据中，如果存在值相等的元素，在排序前后，相等元素之间的排列顺序不发生改变。
     - 具体看实现，能够保证稳定性的算法不一定是稳定的，比较的时候运算符使用的是 " < " 还是 ” <= “，这就会对 实现的排序算法稳定性产生影响
   - 意义
     - 对于简单的元素如数字，稳定性没有什么意义
     - 但是当每个对象可能具有多个数字属性且每个数字属性的排序都是有意义的。所以在排序时，我们需要关注每个数字属性的排序是否会对其他属性进行干扰。如果确保了稳定性，就可以避免在一个属性相同时，还需要再对其他属性进行排序一次。
   - 稳定的排序：冒泡排序，插入排序，归并排序，基数排序，计数排序，桶排序
   - 不稳定的排序：堆排序，快速排序，希尔排序，选择排序
2. 各种排序的适用场景与改进
   ![a](.\image\算法学习\2EPYBHUD@P68DV_CWXAEMAR.png)
   - 总结
      - sort()并非只是普通的快速排序，除了对普通的快速排序进行优化，它还结合了**插入排序和堆排序**。当数据量较大时采用快速排序，分段递归。一旦分段后的数据量小于某个阀值，为避免递归调用带来过大的额外负荷，便会改用插入排序。而如果递归层次过深，有出现最坏情况的倾向（选取基准值就是最大或最小值），还会改用堆排序。
      - 当n比较小时，可采用直接插入排序和直接选择排序。
           当记录规模较小时，考虑直接插入排序较好；否则因为直接选择移动的记录数少于直接插入，应选直接选择排序为宜
      - 若文件初始状态基本有序(指正序)，则应选用直接插入排序、冒泡排序或随机的快速排序为宜
      - 若n较大，则应采用时间复杂度为O(nlgn)的排序方法：快速排序、堆排序或归并排序
         (1)快速排序是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短；
         (2)堆排序所需的辅助空间少于快速排序，并且不会出现快速排序可能出现的最坏情况。这两种排序都是不稳定的。
         (3)若要求排序稳定，则可选用归并排序。但前面介绍的从单个记录起进行两两归并的排序算法并不值得提倡，通常可以将它和直接插入排序结合在一起使用。先利用直接插入排序求得较长的有序子序列，然后再两两归并之。因为直接插入排序是稳定 的，所以改进后的归并排序仍是稳定的。
      - 希尔排序是对直接插入排序的一种优化，可以用于大型的数组，希尔排序比插入排序和选择排序要快的多，并且数组越大，优势越大。
      - 处理大数据，适合用堆排序，在数据量特别大的时候效果明显
   - 冒泡排序
      O(n^2),O(1),稳定
      应用场景：优化后的冒泡排序可用于当数据已经基本有序，且数据量较小时。
      优化措施：设置一个标志，每轮比较时，如果发现没有进行交换操作，说明数组已经有序，退出循环，停止比较。
   - 插入排序
      O(n^2),O(1),稳定
      应用场景：若数组基本有序且数据规模较小时，选用插入排序较好.
      优化措施：由于每次插入是向已排序数组中插入，可使用二分查找查找到相应位置进行插入.
   - 希尔排序
      O(nlogn) ~ O(n^2),O(1),不稳定
      应用场景：数据量较小且基本有序时
      **注意以上三种排序，最好情况即已经是有序数组的情况下时间复杂度为O(1)**
   - 选择排序
      O(n^2),O(1),不稳定
      应用场景：当数据规模较小时，选择排序性能较好
   - 归并排序
      O(nlogn),O(n),稳定
      应用场景：数据量较大且要求排序稳定时
      优化措施：由于使用递归，递归深度太深容易造成内存溢出，所以可使用非递归版本归并排序
   - 快速排序
      O(nlogn),O(1),不稳定
      应用场景：快速排序适合处理大量数据排序时的场景
      优化措施：如果原数组有序，导致每次选取基准元素时都选到了最小或最大的元素，会导致快排时间复杂度很高，所以可以随机选取基准元素，能有效的提高排序的平均性能，防止时间复杂度达到O(n2)
   - 堆排序
      O(nlogn),O(1),不稳定
      应用场景：堆排序适合处理数据量大的情况，数据呈流式输入时用堆排序也很方便
      优化措施：建立堆的时候不需要对叶子结点进行维护堆性质操作，因此只需要对n/2个数进行维护堆操作
   - 计数排序
      Ο(n+k)或者**O(n)**（其中k是整数的范围）,O(k),稳定
      应用场景：
         适用于：在数据范围不?的场景中，避免占用空间过大。
         不适用于：1.当数列最大最小值差距过大时 2.当数列元素不是整数
   - 桶排序
      Ο(n+k)或者**O(n)**（其中k是整数的范围）,O(k),稳定 
      应用场景：
      适用于：在数据范围不?的场景中避免，占用空间过大。以及满足数据服用均匀分布的条件
      不适用于：1.当数列最大最小值差距过大时 2.当数列元素不是整数 3. 不是均匀分布，退化到O(n^2)
   - 基数排序
      Ο(n+k)或者**O(n)**（其中k是整数的范围）,O(k),稳定
      应用场景：同计数排序
      **注意以上三种均为线性非比较排序方法**
3.  **快速排序**
    - 思路
      快速排序的核心思想也是分治法。其实快速排序的本质就是把基准数大的都放在基准数的右边,把比基准数小的放在基准数的左边,这样就找到了该数据在数组中的正确位置.以后采用递归的方式分别对前半部分和后半部分排序，当前半部分和后半部分均有序时该数组就自然有序了。当左右两部分都有序时，整个数据就完成了排序。
    - 复杂度分析
      分治+比较，时间复杂度也为nlogn,最坏情况是已排序数组O(n^2),最好提前打乱或者随机选取基准值
      空间复杂度为O(1)
    - 代码
      ```
      void quickSort(vector<int> &vec, int left, int right) {
         if(left >= right) return;
         int first = left;
         int last = right;
         int key = vec[first];
         while(first < last) { //不能有'='，不然多出一次循环
            while(first < last && vec[last] >= key) last--;
            if(first < last) vec[first++] = vec[last];//不能省略判断，否找对已排序
                                                       //的数组排序时，出错
            while(first < last && vec[first] <= key) first++;
            if(first < last) vec[last--] = vec[first];
         }
         vec[first] = key;
         quickSort(vec, left, first - 1);
         quickSort(vec, first + 1, right);
      }
      ```