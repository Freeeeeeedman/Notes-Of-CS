
#### 1. 基础操作(数据库->表->列,列数据类型,列属性->插入行)
1. 数据类型
   - 整数
        TINTINT 1字节
        INT     4字节
        BIGINT  8字节
   - 浮点数
        FLOAT   4字节
        DOUBLE  8字节
   - 字符串
        CHAR(M) M个字符 * W字节
        VARCHAR(M) M个字符，不定长
   - 枚举
        ENUM('男', '女')
        SET('打球', '画画', '扯犊子', '玩游戏')
2. 数据库
        **SHOW DATABASES**;
        **CREATE DATABASE** 数据库名;
        **USE** 数据库名称;
        **DROP DATABASE** 数据库名;
3. 表
    - 表操作
        **SHOW TABLES;**
        **CREATE TABLE** 表名 (
            列名1    数据类型    [列的属性],
            列名2    数据类型    [列的属性],
            ...
            列名n    数据类型    [列的属性]
        )COMMENT '表的注释信息';
        **DROP TABLE** 表1, 表2, ..., 表n;
        **DESC** 表名;
        **SHOW CREATE TABLE** 表名;
        SHOW TABLES FROM xiaohaizi;
        SHOW CREATE TABLE xiaohaizi.first_table\G
        **ALTER TABLE 旧表名 RENAME TO 新表名;**
        RENAME TABLE 旧表名1 TO 新表名1, 旧表名2 TO 新表名2, ... 旧表名n TO 新表名n;
    - 表的数据类型和属性操作
      - 添加列
        **ALTER TABLE 表名 ADD COLUMN 列名 数据类型 [列的属性];**
        ALTER TABLE 表名 ADD COLUMN 列名 列的类型 [列的属性] FIRST;
        ALTER TABLE 表名 ADD COLUMN 列名 列的类型 [列的属性] AFTER 指定列名;
      - 删除列
        **ALTER TABLE 表名 DROP COLUMN 列名;**
      - 修改列
        注意MODIFY，CHANGE修改属性时，相当于新增属性，重复的不需要再写
        **ALTER TABLE 表名 MODIFY 列名 新数据类型 [新属性];**
        **ALTER TABLE 表名 CHANGE 旧列名 新列名;**
        **ALTER TABLE 表名 MODIFY 列名 列的类型 列的属性 FIRST;**
        ALTER TABLE 表名 MODIFY 列名 列的类型 列的属性 AFTER 指定列名;
        ALTER TABLE 表名 操作1, 操作2, ..., 操作n;
4. 列
   - **SELECT * FROM** 表名;
    - 批量插入:INSERT INTO 表名(列1, 列2, ...) VALUES(列1的值，列2的值, ...), (列1的值，列2的值, ...), (列1的值，列2的值, ...), ...;
   - 列的属性
       - 默认值
            **列名 列的类型 DEFAULT 默认值**
       - 非空
            **列名 列的类型 NOT NULL**
       - PRIMART主键
            **PRIMARY KEY (列名1, 列名2, ...)**
       - UNIQUE唯一键（约束）
            **UNIQUE KEY [约束名称] (列名1, 列名2, ...)**
       - 外键（约束）
            子表中的某些列的值必须在父表中某些列中可以查找
            **CONSTRAINT [外键名称] FOREIGN KEY(列1, 列2, ...) REFERENCES 父表名(父列1, 父列2, ...);**
       - 自增
            **列名 列的类型 AUTO_INCREMENT**
       - 注释
            **列名 列的类型 列的其他属性 COMMENT '注释内容'**
       - 影响展示外观的ZEROFILL属性
            i1 INT(10) UNSIGNED ZEROFILL
   - 删除属性
       - 非空
         NULL
       - 唯一键，唯一键也是索引
         SHOW CREATE TABLE t1;
         ALTER TABLE t1 DROP INDEX col;
   - **举例（只看格式）**
        ```
        CREATE TABLE student_score (
            id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
            number INT,
            subject VARCHAR(30),
            score TINYINT,
            PRIMARY KEY (number, subject),//主键索引
            UNIQUE KEY uk_id_number (id_number),//唯一索引
            KEY id_name (id),//普通索引
            CONSTRAINT FOREIGN KEY(number) REFERENCES student_info(number)//外键约束
        );
        ```
5. 简单查询
   **- 注意查询的时候并不区分列名的大小写，都一样！**
   - 查询列
        SELECT 列名1, 列名2, ... 列名n FROM 表名;
        **SELECT * FROM 表名;**
        **SELECT 列名 [AS] 列的别名 FROM 表名;**
   - 去除重复值
        **SELECT DISTINCT 列名 FROM 表名;**
        注意默认编码字符串不区分大小写
   - 限制查询结果条数
        **SELECT number, name, id_number, major FROM student_info LIMIT 0, 2;**
   - 排序
        ASC顺序，DESC倒序，默认为ASC
        **SELECT * FROM student_score ORDER BY score ASC;**
        先按照subject列排序，再按照score列排序
        **SELECT * FROM student_score ORDER BY subject ASC, score DESC;**
        结合limit等于求最大最小值
6. 带搜索条件的查询
   - **SELECT * FROM student_info WHERE name = '范剑';**
        =, !=, >, <, >=, <=, BETWEEN...AND, NOT BEYWEEM...AND 
   - 匹配列表中元素
        **SELECT *  FROM student_info WHERE major IN ('软件工程', '飞行器设计');**
   - 匹配NULL值
        **IS NULL, IS NOT NULL，注意必须要用这样的方式而不是=或者!=判断，唯一的！**
   - 多个搜索条件的查询
     - AND, OR, XOR
     - AND操作符的优先级高于OR操作符,所以在一个查询中有多个搜索条件时**最好使用小括号()**来显式的指定各个搜索条件的检测顺序
         SELECT * FROM student_score WHERE (score > 95 OR score < 55) AND subject = '论萨达姆的战争准备';
   - 模糊查询
      - LIKE, NOT LIKE
      - %代表字符串, _代表任意**一个**字符
        SELECT number, name FROM student_info WHERE name LIKE '%香%';
        SELECT number, name FROM student_info WHERE name LIKE '范_';
      - 转义 
        SELECT number, name,  FROM student_info WHERE name LIKE '范\_';
7. 函数
   - 文本处理函数
        **SELECT SUBSTRING**('abc123', 2, 3);
        **SELECT CONCAT**('学号为', number, '的学生在《', subject, '》课程的成绩是：',score) AS 成绩描述 FROM student_score;
   - 日期和时间处理函数
   - 聚集函数
         **SELECT COUNT(*) FROM student_info;**
         **SELECT COUNT(DISTINCT major) FROM student_info;**
         **SELECT MAX(score) FROM student_score;**
         **SELECT SUM(score) FROM student_score;**
         **SELECT AVG(score) FROM student_score;**
         SELECT COUNT(*) AS 成绩记录总数, MAX(score) AS 最高成绩, MIN(score) AS 最低成绩, AVG(score) AS 平均成绩 FROM student_score;
   - 隐式类型转换
        - 根据上下文转换，如数字与字符串的转换
        - MySQL会尽量把值转换为表达式中需要的类型，而不是产生错误
        - 在运算时会自动提升操作数的类型
8. 分组查询
   - 创建分组
        **SELECT subject, AVG(score) FROM student_score GROUP BY subject;**
        注意**不能将非分组列放到查询列表中**，只能放入分组列和聚合函数(count,max,min,avg,sum)
   - 带有WHERE子句的分组查询
        SELECT subject, AVG(score) FROM student_score WHERE score >= 60 **GROUP BY subject;**
        在**分组前**将一些不符合条件的行筛选掉
   - 作用于分组的过滤条件
        SELECT subject, AVG(score) FROM student_score GROUP BY subject **HAVING AVG(score) > 73;**
        注意这里针对分组的条件是指分组列或作用于分组的聚集函数，目的是筛选**分组后**的信息
   - 分组和排序
        SELECT subject, AVG(score) AS avg_score FROM student_score GROUP BY subject ORDER BY avg_score DESC;
   - 嵌套分组
        SELECT department, major, COUNT(*) FROM student_info GROUP BY department, major;
        大组再划分成小组
   - 注意
        - 如果分组列中含有NULL值，那么NULL也会作为一个独立的分组存在
        - 如果存在多个分组列，也就是嵌套分组，**聚集函数将作用在最后的那个分组列上**
        - 如果查询语句中存在WHERE子句和ORDER BY子句，那么**GROUP BY子句必须出现在WHERE子句之后，ORDER BY子句之前**
        - 非分组列不能单独出现在检索列表中(可以被放到聚集函数中)
        - 对于派生表也就是子查询生成的表，使用聚合函数时必须要指定别名
        - 注意这两条语句的不同，聚集函数是作用在分组后的列上
            SELECT subject, COUNT(subject) as count_sub FROM student_score GROUP BY subject;
            SELECT COUNT(*) FROM (SELECT subject FROM student_score GROUP BY subject) as s1;          
9. 子查询
   - 用于多表查询
   - 标量子查询
        SELECT * FROM student_score WHERE number = (SELECT number FROM student_info WHERE name = '杜琦燕');
        子查询（内层查询）的结果单纯是一个值
   - 列子查询
        SELECT * FROM student_score WHERE number IN (SELECT number FROM student_info WHERE major = '计算机科学与工程');
        子查询语句的结果集中并不是一个单独的值，而是一个列
   - 行子查询
        SELECT * FROM student_score WHERE (number, subject) = (SELECT number, '母猪的产后护理' FROM student_info LIMIT 1);
        子查询结果为一行
        注意在想要得到标量子查询或者行子查询，但又不能保证子查询的结果集只有一条记录时，应该使用LIMIT 1子句来限制记录数量
   - 表子查询
        SELECT * FROM student_score WHERE (number, subject) IN (SELECT number, '母猪的产后护理' FROM student_info WHERE major = '计算机科学与工程');
        如果子查询结果集中包含多行多列，那么这个子查询也可以被称之为表子查询
   - EXISTS和NOT EXISTS子查询
        SELECT * FROM student_score WHERE EXISTS (SELECT * FROM student_info WHERE number = 20180108);
        只关心子查询的结果集是不是为空集
   - 不相关子查询和相关子查询
        不相关子查询：子查询和外层查询都没有依赖关系，子查询可以独立运行并产生结果
        相关子查询：有依赖关系
        SELECT number, name, id_number, major FROM student_info WHERE EXISTS (SELECT * FROM student_score WHERE student_score.number = student_info.number);
   - 对同一个表的子查询
        会报错！：SELECT * FROM student_score WHERE subject = '母猪的产后护理' AND score > AVG(score);
        因为聚集函数是用来对分组做数据统计的，而WHERE子句是以记录为单位来执行过滤操作的，在WHERE子句执行完成之后才会得到分组，也就是说：聚集函数不能放到WHERE子句中
        所以需要这样做
         SELECT * FROM student_score WHERE subject = '母猪的产后护理' AND score > (SELECT AVG(score) FROM student_score WHERE subject = '母猪的产后护理');
10. 连接查询
   - 用于多表查询
   - 连接
       **连接的本质就是把各个表中的记录都取出来依次匹配的组合加入结果集并返回给用户。笛卡尔积。**
       **SELECT t1.m1, t1.n1, t2.m2, t2.n2 FROM t1, t2;如果列名不重复也可以直接使用列名**
       SELECT student_info.number, name, major, subject, score FROM student_info, student_score WHERE student_info.number = student_score.number;
   - 驱动表和被驱动表
        驱动表是第一个按条件被查询的表，驱动表筛选后的记录去被驱动表寻找符合条件的记录
   - 内连接
       - SELECT * FROM t1 [INNER | CROSS] JOIN t2 [ON 连接条件] [WHERE 普通过滤条件];
       - 对于内连接的两个表，驱动表中的记录在被驱动表中找不到匹配的记录，**该记录不会加入到最后的结果集**
       - 默认JOIN是内连接，建议显示使用INNER JOIN来区分外连接LEFT JOIN及RIGHT JOIN。
   - 外连接
        SELECT * FROM t1 LEFT | RIGHT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件];
        会将驱动表中的记录在被驱动表中**找不到匹配的记录加入到最后的结果集**
        左外连接：选取左侧的表为驱动表
        右外连接：选取右侧的表为驱动表
   - 连接的过滤条件
        - WHERE子句中的过滤条件
            不论是内连接还是外连接，凡是不符合WHERE子句中的过滤条件的记录都不会被加入最后的结果集
        - ON子句中的过滤条件
           - 对于外连接的驱动表的记录来说，如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用NULL值填充。
           - 内连接中的WHERE子句和ON子句是等价的。因为on的作用就是在外连接中驱动表记录在被驱动表中找不到匹配的记录时保留并将对应项置为NULL。  
        - 一般情况下，我们都把**只涉及单表的过滤条件放到WHERE子句中**，把**涉及两表的过滤条件都放到ON子句中**，我们也一般把放到ON子句中的过滤条件也称之为**连接条件**。  
            SELECT *  FROM student_info LEFT JOIN student_score on student_info.number = student_score.number;   
   - 多表连接
         SELECT * FROM t1 INNER JOIN t2 INNER JOIN t3 WHERE t1.m1 = t2.m2 AND t1.m1 = t3.m3;
   - 表的别名
      - 与列的别名类似，我们也可以为表来定义别名，格式与定义列的别名一致，都是用空白字符或者AS隔开，这个在表名特别长的情况下可以让语句表达更清晰一些
        **SELECT s1.number, s1.name, s1.major, s2.subject, s2.score FROM student_info AS s1 INNER JOIN student_score AS s2 WHERE s1.number = s2.number;** 
   - 自连接
      - SELECT * FROM t1 AS table1, t1 AS table2;
      - 意义：比方说查询与某一行的某一列相同信息的行
            SELECT s2.number, s2.name, s2.major FROM student_info AS s1 INNER JOIN student_info AS s2 WHERE s1.major = s2.major AND s1.name = '史珍香' ;
      - **注意自连接必须使用别名来区分**
   - 连接查询与子查询的转换
        可以转换，服务器优化时会将有的子查询转换为连接查询
11. 组合查询
    - 用于将多条查询语句产生的结果集合并起来
    - 单表的组合查询
         SELECT m1 FROM t1 WHERE m1 < 2 **UNION** SELECT m1 FROM t1 WHERE m1 > 2;
         SELECT m1, n1 FROM t1 WHERE m1 < 2 UNION SELECT m1, n1 FROM t1 WHERE m1 > 2;
         注意：使用UNION连接起来的各个查询语句的查询列表中位置相同的表达式的类型应该是相同的即都是m1，n1，否则会自动转换。且结果集的列名是使用第一个查询中的列名。
    - 不同表的组合查询
        SELECT m1, n1 FROM t1 WHERE m1 < 2 UNION SELECT m2, n2 FROM t2 WHERE m2 > 2;
    - 包含或去除重复的行
        - UNION默认过滤掉重复的记录
        - **UNION ALL保留重复记录**
    - 组合查询中的排序
        于最后的结果集展示的列名是第一个查询中给定的列名，所以ORDER BY子句中指定的排序列也必须是第一个查询中给定的列名（别名也可以）
12. 数据的插入、删除和更新(DELETE, INSERT, UPDATE)
    - 插入数据
        - 插入完整的记录
            指定全部列的数据
            INSERT INTO 表名 VALUES(列1的值，列2的值, ..., 列n的值);
        - 插入记录的一部分
            要求：该列允许存储NULL值，该列有DEFAULT属性，给出了默认值（没有设置默认为NULL）
            INSERT INTO first_table(first_column, second_column) VALUES (3, 'ccc');
        - 批量插入记录
            **INSERT INTO first_table(first_column, second_column) VALUES(7, 'ggg'), (8, 'hhh');**
        - 将某个查询的结果集插入表中
             INSERT INTO second_table(s, i) SELECT second_column, first_column FROM first_table WHERE first_column < 5;
        - **INSERT IGNORE**
            一些是主键或者具有UNIQUE约束的列或者列组合来说，它们不允许重复值的出现。用于批量插入时避免报错。
            INSERT IGNORE INTO first_table(first_column, second_column) VALUES(1, '哇哈哈') ; 
        - INSERT ON DUPLICATE KEY UPDATE
           - 对于那些是主键或者具有UNIQUE约束的列或者列组合来说，如果表中已存在的记录中没有与待插入记录在这些列或者列组合上重复的值，那么就把待插入记录插到表中，否则按照规定去**更新那条重复的记录中某些列的值**
             INSERT INTO first_table (first_column, second_column) VALUES(1, '哇哈哈') **ON DUPLICATE KEY UPDATE** second_column = '雪碧';
           - 我们可以使用VALUES(列名)的形式来引用待插入记录中对应列的值
            INSERT INTO first_table (first_column, second_column) VALUES(2, '红牛'), (3, '橙汁儿') ON DUPLICATE KEY UPDATE second_column = VALUES(second_column);
    - 删除数据
      - **DELETE FROM 表名 [WHERE 表达式];**
          注意一定要写明WHERE
      - 删除最大记录
          DELETE FROM first_table ORDER BY first_column DESC LIMIT 1;
    - 更新数据
      - UPDATE 表名 SET 列1=值1, 列2=值2, ...,  列n=值n [WHERE 布尔表达式];
          **UPDATE first_table SET first_column = 5, second_column = '乳娃娃' WHERE first_column IS NULL;**
      - 更新最大记录
          UPDATE first_table SET second_column='爽歪歪' ORDER BY first_column DESC LIMIT 1;
13. 视图
    - 视图相当于一个查询语句的别名，简化语句的书写
    - 视图也可以被称为虚拟表，因为我们可以对视图进行一些类似表的增删改查操作，只不过我们**对视图的相关操作都会被映射到查询语句对应的底层的表上**
    - **CREATE VIEW 视图名 AS 查询语句**
    - **SELECT * FROM view1;**
    - 利用视图来创建新视图
        CREATE VIEW by_view AS SELECT number, name, score FROM male_student_view;
        在对这种依赖其他的视图而生成的新视图进行查询时，查询语句会先被转换成对它依赖的视图的查询，再转换成对底层表的查询。
    - 创建视图时指定自定义列名
        CREATE VIEW student_info_view(no, n, m) AS SELECT number, name, major FROM student_info;
    - 查看视图
        **视图时默认是将其放在当前数据库下的**
        **SHOW TABLES;**
    - 查看视图的定义
        SHOW CREATE VIEW 视图名;
    - 可更新的视图
        并不是可以在所有的视图上执行更新语句的，**一般我们只在查询语句里使用视图**，而不在INSERT、DELETE、UPDATE语句里使用视图
    - 删除视图
        DROP VIEW 视图名
14. 变量与自定义语句结束分隔符
    - **存储程序可以封装一些语句，然后给用户提供一种简单的方式来调用这个存储程序，从而间接地执行这些语句**
    - 根据调用方式的不同，我们可以把存储程序分为**存储例程、触发器和事件**
    - 存储例程又分为存储函数和存储过程
    - 变量
        SELECT @a;
        SET @a = 1;
        SET @b = @a;
        SET @a = (SELECT m1 FROM t1 LIMIT 1);
        SELECT m1, n1 FROM t1 LIMIT 1 INTO @a, @b;
    - 自定义语句结束分隔符
        目的是写函数时，避免函数体执行
        delimiter $
        delimiter EOF
15. 存储函数
    - mysql的设置默认是不允许创建函数
        1、更改全局配置
        SET GLOBAL log_bin_trust_function_creators = 1;
        有主从复制的时候 , 从机必须要设置 不然会导致主从同步失败
        2、更改配置文件my.cnf
        log-bin-trust-function-creators=1 重启服务生效
    - 存储函数其实就是一种函数，只不过在这个函数里可以执行MySQL的语句而已。
        ```
        mysql> delimiter $
        mysql> CREATE FUNCTION avg_score(s VARCHAR(100))
            -> RETURNS DOUBLE
            -> BEGIN
            ->     RETURN (SELECT AVG(score) FROM student_score WHERE subject = s);
            -> END $
        Query OK, 0 rows affected (0.00 sec)

        mysql> delimiter ;
        ```
    - SHOW FUNCTION STATUS [LIKE 需要匹配的函数名]
    - SHOW CREATE FUNCTION 函数名
    - DROP FUNCTION 函数名
    - 在函数体中定义局部变量
        - DECLARE 变量名1, 变量名2, ... 数据类型 [DEFAULT 默认值];
        - 这些在函数体内声明的变量只在该函数体内有用，当存储函数执行完成后，就不能访问到这些变量了
        -  在存储函数的函数体中，DECLARE语句必须放到其他语句的前边。
        ```
        mysql> delimiter $;
        mysql> CREATE FUNCTION var_demo()
        -> RETURNS INT
        -> BEGIN
        ->     DECLARE c INT DEFAULT 1;
        ->     SET c = 5;
        ->     RETURN c;
        -> END $
        Query OK, 0 rows affected (0.00 sec)

        mysql> delimiter ;
        ```
    - 在函数体中使用自定义变量
        在该函数执行完之后我们仍然可以访问到该自定义变量的值
        ```
        mysql> delimiter $
        mysql> CREATE FUNCTION user_defined_var_demo()
            -> RETURNS INT
            -> BEGIN
            ->     SET @abc = 10;
            ->     return @abc;
            -> END $
        Query OK, 0 rows affected (0.00 sec)

        mysql>
        mysql> delimiter ;
        mysql>
        ```
    - 判断语句的编写
        ```
        IF 表达式 THEN
            处理语句列表
        [ELSEIF 表达式 THEN
            处理语句列表]
        ... # 这里可以有多个ELSEIF语句
        [ELSE
            处理语句列表]
        END IF;
        ```
    - 循环语句
        - WHILE循环语句：
            ```
            WHILE 表达式 DO
                处理语句列表
            END WHILE;
            ```
        - REPEAT循环语句
        - LOOP循环语句
16. 存储过程
    - 存储函数和存储过程都属于存储例程，**都是对某些语句的一个封装。存储函数侧重于执行这些语句并返回一个值，而存储过程更侧重于单纯的去执行这些语句**
    - 定义
        ```
        CREATE PROCEDURE 存储过程名称([参数列表])
        BEGIN
            需要执行的语句
        END
        ```
    - 调用
        CALL 存储过程([参数列表]);
    - 查看和删除存储过程
        SHOW PROCEDURE STATUS [LIKE 需要匹配的存储过程名称]
        SHOW CREATE PROCEDURE 存储过程名称
        DROP PROCEDURE 存储过程名称
    - 存储过程的参数前缀
        参数类型 [IN | OUT | INOUT] 参数名 数据类型
        ```
        mysql> delimiter $
        mysql> CREATE PROCEDURE p_in (
        ->     IN arg INT
        -> )
        -> BEGIN
        ->     SELECT arg;
        ->     SET arg = 123;
        -> END $
        Query OK, 0 rows affected (0.00 sec)

        mysql> delimiter ;
        mysql>
        ```
        IN输入的参数不会被改变，OUT会被改变，INOUT参数既可以在存储过程中被读取，也可以被赋值后被调用者看到
    - 存储过程和存储函数的不同点
        - 存储函数在定义时需要显式用RETURNS语句标明返回的数据类型，而且在函数体中必须使用RETURN语句来显式指定返回的值，存储过程不需要。
        - 存储函数只支持IN参数，而存储过程支持IN参数、OUT参数、和INOUT参数。
        - 存储函数只能返回一个值，而存储过程可以通过设置多个OUT参数或者INOUT参数来返回多个结果。
        - 存储函数执行过程中产生的结果集并不会被显示到客户端，而存储过程执行过程中产生的结果集会被显示到客户端。
        - 存储函数直接在表达式中调用，而存储过程只能通过CALL语句来显式调用
17. 游标
    - 如果某个查询语句的结果集中有多条记录的话，我们就无法把它们赋值给某些变量了，所以为了**方便我们去访问这些有多条记录的结果集，MySQL中引入了游标的概念**
    - 我们可以**根据这个游标取出它对应记录的信息，随后再移动游标，让它执向下一条记录**。
    - 游标的使用步骤
        1.创建游标
        2.打开游标
        3.通过游标访问记录
        4.关闭游标
    - 创建游标
        DECLARE 游标名称 CURSOR FOR 查询语句;
        创建游标的语句一定要放在局部变量声明后头
    - 打开和关闭游标
        OPEN 游标名称;
        CLOSE 游标名称;
    - 使用游标获取记录
        FETCH 游标名 INTO 变量1, 变量2, ... 变量n
    - 遍历结束时的执行策略
        在FETCH语句获取不到记录的时候会触发一个事件，从而我们可以得知所有的记录都被获取过了，然后我们就可以去主动的停止循环
        DECLARE CONTINUE HANDLER FOR NOT FOUND 处理语句;
        ```
        CREATE PROCEDURE cursor_demo()
        BEGIN
            DECLARE m_value INT;
            DECLARE n_value CHAR(1);
            DECLARE not_done INT DEFAULT 1;

            DECLARE t1_record_cursor CURSOR FOR SELECT m1, n1 FROM t1;

            DECLARE CONTINUE HANDLER FOR NOT FOUND SET not_done = 0;

            OPEN t1_record_cursor;

            flag: LOOP
                FETCH t1_record_cursor INTO m_value, n_value;
                IF not_done = 0 THEN
                    LEAVE flag;
                END IF;
                SELECT m_value, n_value, not_done;
            END LOOP flag;

            CLOSE t1_record_cursor;
        END
        ```
18. 触发器
   - 存储例程是需要我们手动调用的，而**触发器和事件是MySQL服务器在特定情况下自动调用的**
   - 创建触发器
        ```
        CREATE TRIGGER 触发器名
        {BEFORE|AFTER}
        {INSERT|DELETE|UPDATE}
        ON 表名
        FOR EACH ROW
        BEGIN
            触发器内容
        END
        ```
        BEFORE	表示在具体的语句执行之前就开始执行触发器的内容
        AFTER	表示在具体的语句执行之后才开始执行触发器的内容
    - NEW和OLD来分别代表新记录和旧记录，来访问该记录中的内容的方式
        对于INSERT语句设置的触发器来说，NEW代表准备插入的记录，OLD无效。
        对于DELETE语句设置的触发器来说，OLD代表删除前的记录，NEW无效。
        对于UPDATE语句设置的触发器来说，NEW代表修改后的记录，OLD代表修改前的记录
        ```
        mysql> delimiter $
        mysql> CREATE TRIGGER bi_t1
            -> BEFORE INSERT ON t1
            -> FOR EACH ROW
            -> BEGIN
            ->     IF NEW.m1 < 1 THEN
            ->         SET NEW.m1 = 1;
            ->     ELSEIF NEW.m1 > 10 THEN
            ->         SET NEW.m1 = 10;
            ->     END IF;
            -> END $
        Query OK, 0 rows affected (0.02 sec)

        mysql> delimiter ;
        ```
    - 查看和删除触发器
        SHOW TRIGGERS;
        SHOW CREATE TRIGGER 触发器名;
        DROP TRIGGER 触发器名;
    - 注意事项
        - 触发器内容中不能有输出结果集的语句
        - 触发器内容中NEW代表记录的列的值可以被更改，OLD代表记录的列的值无法更改
        - 在BEFORE触发器中，我们可以使用SET NEW.列名 = 某个值的形式来更改待插入记录或者待更新记录的某个列的值，但是这种操作不能在AFTER触发器中使用，因为在执行AFTER触发器的内容时记录已经被插入完成或者更新完成了
        - 如果我们的BEFORE触发器内容执行过程中遇到了错误，那这个触发器对应的具体语句将无法执行；如果具体的操作语句执行过程中遇到了错误，那与它对应的AFTER触发器的内容将无法执行
19. 事件
    - 有时候我们想让**MySQL服务器在某个时间点或者每隔一段时间自动地执行一些语句**，这时候就需要去创建一个事件
    - 创建事件
        ```
        CREATE EVENT 事件名
        ON SCHEDULE
        {
            AT 某个确定的时间点| 
            EVERY 期望的时间间隔 [STARTS datetime][END datetime]
        }
        DO
        BEGIN
            具体的语句
        END
        ```
    - 查看和删除事件
       SHOW EVENTS;
       SHOW CREATE EVENT 事件名;
       DROP EVENT 事件名;
    - 注意事项
       -  MySQL服务器并不会帮助我们执行事件，除非我们使用下边的语句手动开启该功能
            SET GLOBAL event_scheduler = ON;
#### 2. 基础问题
1. 在学习MySQL时用到什么资料?
    - MySQL官方文档,不过那个太长了
    - 阿里云的taobao月报可以看看源码
    - 其他人的博客
    - 还有一些书里面的一些章节,如《高性能MySQL》,《MySQL必知必会》
2. 说一说什么是MySQL
    MySQL是关系型数据库，有着免费，开源，跨平台，高性能的优势
3. 说一说什么是关系型数据库
    由行和列组成的表来存放数据，且不同的表之间可以通过某种关系联系起来
4. 你用的MySQL是什么版本的?
    5.7
5. 说一说MySQL的数据类型
       - 整数：INT 4字节
       - 浮点数：float 4， double 8
       - 定点数：DECIMAL(M, D),确保小数位精确
       - 定长字符串：CHAR(M)， M代表**字符数**，分配的空间为定长M x W字节，不足用空格补全
       - 不定长字符串：VARCHAR(M)， M代表最多可记录的**字符数**，需要记录占用字节数，应对记录的字符串长短不一的情况，节省空间
       - 枚举：ENUM('', '', '')
       - 二进制:BINARY(M), VARBINARY(M)
6. 说一说WHERE子句和HAVING子句的区别
    WHERE子句在**分组前**进行过滤，作用于每一条记录，WHERE子句过滤掉的记录将不包括在分组中。而HAVING子句在数据**分组后**进行过滤，作用于整个分组。
7. 简单查询语句中各子句的顺序
    SELECT [DISTINCT] 查询列表
    [FROM 表名]
    [WHERE 布尔表达式]
    [GROUP BY 分组列表 ]
    [HAVING 分组过滤条件]
    [ORDER BY 排序列表]
    [LIMIT 开始行, 限制条数]
8. 为什么要把关系表分开存储？
    - 因为会造成同一个对象的基本信息的冗余存储，会导致**浪费存储空间**
    - 以及当**修改某个列的信息时必须修改多处**，很容易造成信息的不一致，增大维护的困难。
9. 说一说连接查询的过程
    先从定第一个需要查询的表即驱动表按照条件筛选出结果集，再针对从驱动表每获取到的一条记录，到被驱动表中查询匹配的记录。即**驱动表只需要查询一次，被驱动表可能会被查询多次**。
10. 说一说视图
    视图相当于**一个查询语句的别名**，简化语句的书写。视图也可以被称为虚拟表，因为我们可以对视图进行一些类似表的增删改查操作，只不过我们对视图的相关操作都会被映射到查询语句对应的底层的表上。
11. 说一说存储程序，存储函数，存储过程，游标，触发器以及事件
    - 存储程序存储函数和存储过程，都是对某些语句的一个封装。
    - 存储函数侧重于执行这些语句并返回一个值，而存储过程更侧重于单纯的去执行这些语句。
    - 游标是为了在使用存储函数和存储过程，并针对某个查询语句的**结果集有多条记录**的情况下，遍历去访问这些记录。
    - 存储例程是需要我们手动调用的，而触发器和事件是MySQL服务器在特定情况下自动调用的。触发器是在具体的语句如INSERT|DELETE|UPDATE执行之前或之后会自动执行，而事件是在某一个时间点或者某一段时间自动执行一些语句。

#### 3. 架构问题
1. 说一说MySQL的基础架构
    - MySQL可以分为服务器层和存储引擎层。
    - **服务器层包括连接器、查询缓存、分析器、优化器、执行器**，涵盖MySQL的大多数核心服务功能， 以及所有的内置函数，所有跨存储引擎的功能都在这一层实现， 比如存储过程、 触发器、 视图等
    - 而**存储引擎层负责数据的存储和提取**，不同的存储引擎共用一个Server层
2. 说一说一条SQL查询语句是如何执行的
    - 首先客户端会通过**连接器**连接到数据库上。
    - 连接建立完后，执行SELECT语句，首先会**查询缓冲**。如果缓冲命中，则直接返回结果。
    - 如果没有命中查询缓存，MySQL会通过**分析器**对SQL语句做词法分析与语法分析。
    - 分析完成后，**优化器**进行优化，选择最高效率的执行方案。比如在表里面有多个索引的时候， 决定使用哪个索引； 或者在一个语句有多表关联（join）的时候， 决定各个表的连接顺序。等等。
    - 优化完成后，执行器开始执行语句。首先判断对这个表有没有执行查询的权限，有就调用**存储引擎**提供的接口。
3. 说一说MySQL的连接器
    连接器负责跟客户端建立连接、 获取权限、 维持和管理连接。 
4. 如何查看MySQL的客户端的连接信息？如何查看 MySQL 服务被多少个客户端连接了？
    show processlist
5. 空闲连接会一直占用着吗？
    不会，MySQL 定义了空闲连接的最大空闲时长，由 wait_timeout 参数控制的，默认值是 8 小时（28880秒），如果空闲连接超过了这个时间，连接器就会自动将它断开
6. MySQL的连接数有限制吗？
    MySQL服务支持的最大连接数由 max_connections 参数控制
7. 什么是**数据库的长连接与短连接**？
    - 长连接是指连接成功后， 如果客户端持续有请求， 则一直使用同一个连接。
    - 短连接则是指每次执行完很少的几次查询就断开连接， 下次查询再重新建立一个。
    每次连接开销大，应该尽量使用长连接
8. 数据库长连接会导致什么问题？
    会导致MySQL占用内存高，因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。 这些资源会在连接断开的时候才释放。MySQL占用内存过大时会导致系统强行杀掉，即 MySQL 服务异常重启。
9. 如何解决长连接的问题？
   - 定期断开长连接。 
   - 客户端主动重置连接，执行mysql_reset_connection来重新初始化连接资源。 
10. 说一说MySQL的查询缓存
    MySQL查询缓存会用**键值对**的方式将查询语句与结果缓存在内存中。执行SELECT语句时，首先会查询缓冲。如果缓冲命中，则直接返回结果。
11. 查询缓存有什么问题？
    - 查询缓存的**失效非常频繁**，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。对于更新压力大的数据库来说， 查询缓存的命中率会非常低。 除非你的业务就是有一张**静态表**，很长时间才会更新一次。比如， 一个系统配置表，那这张表上的查询才适合使用查询缓存。
    - 应该默认关闭查询缓存，然后要使用查询缓存的语句，可以用SQL_CACHE显式指定
12. 什么是存储引擎？
    存储引擎，就是**如何存储数据**、如何为存储的数据**建立索引**和如何**更新、查询数据**等技术的**实现方法**
13. 当执行一条查询\更新\删除\插入语句的时候会发生什么？
   - 从架构的角度
   - 从执行的角度
   - 从事务的角度
   - 从锁的角度
   - 从日志的角度
13. 执行一条**SELECT**语句会发生什么?
   - 如果SELECT是快照读的情况下
      - 先说架构的角度:查询缓存+分析器+优化器+执行器调用引擎接口
      - 如果查询列是主键或者覆盖索引的情况下,就不需要回表.然后就在B+树中先通过主键二分法定位包含查询值得目录项的页,在该页中查找更详细的目录项页,继续通过二分法定位到包含查询值的叶子节点,再通过二分法定位叶子节点中包含记录的槽,再遍历槽中所有记录
   - 如果SELECT是当前读,即SELECT FOR UPDATE的情况下,根据查找的为唯一索引,还是普通索引还是没有索引以及是范围查找还是单值查找加不同的行锁.别的流程都差不多
14. 执行一条**UPDATE**语句会发生什么?    
    - 先说架构的角度:查询缓存+分析器+优化器+执行器调用引擎接口.
    - 如果该记录所在的页面不在buffer pool里，将数据页从磁盘读入到 buffer pool，返回记录给执行器。
    - 执行器得到记录后，会看一下更新前的记录和更新后的记录是否一样：
      - 如果一样的话就不进行后续更新流程；
      - 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作
    - 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在修改该 Undo 页面前需要先记录对应的 redo log，所以**先记录修改Undo页面的 redo log ，然后再真正的修改 Undo 页面**
    - InnoDB 层开始更新记录，根据 WAL 技术，**先记录修改数据页面的 redo log ，然后再真正的修改数据页面**。修改数据页面的过程是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘
    - 在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘
    - 事务提交，剩下的就是「**两阶段提交**」的事情了（这里不说**组提交**的过程，只说两阶段提交）：
      - prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；
      - commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit
15. 执行一条**DELETE**语句会发生什么?
    - 先说架构的角度:查询缓存+分析器+优化器+执行器调用引擎接口.
    - 如果该记录所在的页面不在buffer pool里，将数据页从磁盘读入到 buffer pool，返回记录给执行器。
    - 根据查找的为唯一索引,还是普通索引还是没有索引以及是范围查找还是单值查找加不同的行锁.
    - 然后再执行 delete mark 操作,并不真正删除,delete mark主要是为了支持MVCC,在通过readview确定没有事务再访问这些记录的时候,会有后台线程来进行真正的删除
16. 执行一条**INSERT**语句会发生什么?
    - 这个操作的流程我没有特别了解过,但是也可以说一说我知道的
    - 先说架构的角度:查询缓存+分析器+优化器+执行器调用引擎接口.
    - 通过B+树定位到应该INSERT的位置,进行插入,
    - 如果插入的位置有间隙锁,那么会加上插入意向锁.如果没有间隙锁那么在一般情况下，新插入一条记录的操作并不加锁，通过隐式锁来保护这条新插入的记录在本事务提交前不被别的事务访问.这个隐式锁是指别的事务通过这条新插入的记录的隐藏列的事务id来判断是否有活跃事务在使用.如果有,那么就会帮助这个事务添加一个独占锁.
17. 说一说数据库的**三大范式**
    - 第一范式确保每列的**原子性**，要求每列都是不可再分的最小数据单元。
    - 第二范式要求实体的**唯一性**，要求表中的每列都和主键相关。
    - 第三范式限制列的**冗余性**,确保每列都和主键列直接相关，而不是间接相关.
18. 范式化有什么优点?
    - **减少数据冗余**
    - 冗余数据少,范式化的**更新操作比反范式化更快**
    - 范式化的表通常比反范式化**更小**
19. 范式化有什么缺点?
    - 范式化的表在查询时经常需要很多的关联，这**会导致性能降低**
    - **增加了索引优化的难度**
20. MySQL的引擎你有什么了解?
    - 目前MySQL默认使用**InnoDB引擎**, 它是一个**事务安全**的存储引擎, 具备**提交, 回滚以及崩溃恢复**的功能,并且支持**MVCC与行级锁**. InnoDB**将用户数据存储在聚簇索引**中以减少基于主键的普通查询所带来的I/O开销, 为了保证数据的完整性, InnoDB还**支持外键约束,** 默认使用**B+Tree数据结构存储索引**.
    - 在MySQL5.0版本之前, 使用的是**MyISAM引擎**, 它**不支持事务, 也不支持外**键, 其**优势是访问速度快**, 但是**表级别的锁定限制了他在读写负载方面的性能**, 因此它经常应用于**只是读或者以读为主**的数据场景, 默认使用**B+树**结构存储索引.
21. 说一下InnoDB存储引擎和MyISAN存储引擎的区别
    - InnoDB:
      - 支持事务, 支持4个事务隔离级别，具备提交, 回滚以及崩溃恢复的功能
      - 行级锁定(更新时锁定当前行)
      - 读写阻塞与事务隔离级别有关(比如在RR级别下,当前读就会阻塞INSERT)
      - 既能缓存索引又能缓存数据
      - 支持外键
    - MyISAM:
      - 不支持事务
      - 表级锁定(更新时锁定整个表)
      - 读写互相阻塞(写入时阻塞读入, 读时阻塞写入, 但是读不会互相阻塞)
      - 只能缓存索引, 不会缓存数据
      - 不支持外键
      - 读取速度快
22. InnoDB 是如何存储数据的
    通过B+树来存储数据，非叶子节点为存放**目录项的数据页**，叶子节点为存放**数据的数据页**。数据页通过文件头里的指针组成了**双向链表**，而数据页中的记录**按照主键顺序组成单向链表**。
23. B+树是如何进行查询的？
    - 从**根节点**开始，先通过**主键二分法**定位到页内范围包含查询值的页，在该页中查找更详细的**目录项**
    - 再在**非叶子节点**中，继续通过二分法快速定位到符合页内范围**包含查询值的页**，到对应叶子节点查找记录
    - 在**叶子节点**中，通过**槽**查找记录时，使用二分法快速定位要查询的记录在哪个槽，定位到槽后，再**遍历槽内的所有记录**，找到所需的记录    
24. 如果给你一个3阶B+树, 每行数据的大小为1KB, 那么B+树能存储多少个数据?
    - InnoDB数据页大小为**16kb**,也就是说叶子节点可以存储16个记录.同时非叶子节点假设是bigint型主键和指针构成,也就是8+6=14字节.那么对于一个页可以存放大概16000 / 14 = 1200 个非叶子节点.对于高度为3的B+树,就可以存放1200 * 1200 * 16 大概是2000多万条记录.所以对于**千万**级别的数据存储,对于B+树大概就只需要**1~3次的IO**操作
    - 两层大概是1200 * 16 = 20000,即**万**级别的数据
    - 四层大概是**百亿**级别的数据
25. 什么是慢查询?
    **运行时间较长的SQL即为慢SQL**, MySQL慢查询，是运行时间超过long_query_time值的SQL。SQL运行快慢是一个相对的概念，不同的业务场景下要求不同，慢SQL的标准也就不同。MySQL中long_query_time参数定义了SQL运行阈值，默认为10s，可通过设置该阈值来调整基准。


#### 4. 索引
1. 什么是索引？
    **索引就是帮助存储引擎快速获取数据的一种数据结构，形象的说就是索引是数据的目录**
2. 说一说InnoDB为什么使用B+树而不是其他数据结构？
    - **B+Tree与BTree**的区别（聚簇索引的特点，B+树有什么特点,性能比较）
        - **查找IO操作更少，内存占用更少**
            B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据。导致这样使得同样大小的磁盘页可以容纳更多节点元素，树的层级更少，在相同数据量下，Ｏ操作更少。同时如果用B树查找，查找过程中**不需要的节点数据也会加载到内存中**，占用内存资源
        - **性能稳定**
            Ｂ树（平衡多路查找树）的查找只需找到匹配元素即可，最好情况下查找到根节点，最坏情况下查找到叶子结点，所以性能很不稳定，而Ｂ＋树每次必须查找到叶子结点，性能稳定
        - **B+树的插入和删除效率更高**
           - B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快。B 树没有冗余节点，删除节点的时候非常复杂，比如删除根节点中的数据，可能涉及复杂的树的变形
           - B+ 树的插入也是一样，有冗余节点，插入可能存在节点的页分裂（如果节点饱和），但是最多只涉及树的一条路径。而且 B+ 树会自动平衡，不需要像更多复杂的算法，类似红黑树的旋转操作等
        - **更适合范围查找**
           B+树范围查询首先通过二分查找，找到范围下限，然后同过叶子结点的链**表顺序遍历**，直至找到上限即可，效率更高。而B树则是通过**二分法到范围下限，在不断通过中序遍历**，直到查找到范围的上限，整个过程比较耗时；
    - B+Tree vs 平衡二叉搜索树（AVL树）
        - 平衡二叉搜索树查找和插入数据都是O(log2N)基本，连续插入新元素开销不大。
        - 对于有 N 个叶子节点且节点允许的最大子节点个数为 d 个的 B+Tree，其搜索复杂度为O(logdN)。相同数据量，**二叉树相较B+树层级更多，导致查找数据的IO操作更**多
    - B+Tree vs Hash
        Hash等值查询的时候效率高O(1)，但是**范围查询时需要扫描全表**
    - B+Tree vs 有序数组
        有序数组在等值查询和范围查询场景中的性能就都非常优秀O(logN),但**只适用于静态表，增删都会导致很大的开销**
3. 说一说B+树和B树各自的适用场景
    存在大量范围检索的场景，适合使用 B+树，比如数据库。而对于**大量的单个索引查询**的场景，可以考虑 B 树，比如 nosql 的MongoDB。
4. 说一说MySQL有哪些索引？
    - 按「**数据结构**」分类：B+tree索引、Hash索引。
    - 按「**物理存储**」分类：聚簇索引（主键索引）、二级索引（辅助索引）。
    - 按「**字段特性**」分类：主键索引、唯一索引、普通索引、前缀索引（后三者都是二级索引）。
    - 按「**字段个数**」分类：单列索引、联合索引
5. InnoDB创建表时没有主键会怎么办？
    如果没有主键，就选择**第一个不包含 NULL 值的唯一列**作为聚簇索引的索引键（key）；如果前面的条件也不满足，InnoDB 将**自动生成一个隐式自增 id 列**作为聚簇索引的索引键（key）
6. 说一说通过主键查询数据的过程
    - 通过主键查询就是通过连续二分遍历B+数的过程 
    - 首先从**根节点**开始，先通过**主键二分法**定位到页内范围包含查询值的页，在该页中查找更详细的**目录项**
    - 再在**非叶子节点**中，继续通过二分法快速定位到符合页内范围**包含查询值的页**，到对应叶子节点查找记录
    - 在**叶子节点**中，通过**槽**查找记录时，使用二分法快速定位要查询的记录在哪个槽，定位到槽后，再**遍历槽内的所有记录**，找到所需的记录   
7. 通过二级索引查询数据的过程
   - 先通过二级索引的B+树找到对应的叶子节点，获取对应的主键值，再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。即回表，需要查询两个B+树。
   - 当然在覆盖索引的情况下就不需要回表了。
8. 主键索引的 B+Tree 和二级索引的 B+Tree 区别
    - 主键索引的 B+Tree的叶子节点存放的是**实际数据**，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
    - 二级索引的 B+Tree的叶子节点存放的是**主键值和索引列数据**，而不是实际数据。
9. 说一说**覆盖索引**
    在查询列表里只包含索引列，省去了回 操作带来的性能损耗。
10. 说一说主键有什么特点
   - **一个表最多只能有一个主键，主键的值不能重复**，通过主键可以找到唯一的一条记录
   - 主键列默认是有NOT NULL属性
   - 一般会为主键列设置**AUTO_INCREMENT属性**
   - 自动建立索引
11. 说一说唯一键
    - 为某个列或多个列的组合添加了一个UNIQUE属性。从此我们插入的记录的该列的值就**不能重复**
    - 自动建立索引
    - 注意二级索引包含**唯一索引**和**普通索引**，两者的区别是唯一索引在插入数据时多了一步来判断数据是否已经存在。
12. 说一说外键
    - 即外键约束。如果A表中的某个列或者某些列依赖与B表中的某个列或者某些列，那么就称A表为子表，B表为父表。子表和父表可以使用外键来关联起来。
    - 子表中的某些列的值必须在父表中某些列中可以查找，否则插入数据时会报错
13. 说一说自增
   - 一个表中**最多有一个**具有AUTO_INCREMENT属性的列
   - 具有AUTO_INCREMENT属性的列**必须建立索引**。
   - 拥有AUTO_INCREMENT属性的列就不能再通过指定DEFAULT属性来指定默认值。
   - 一般拥有AUTO_INCREMENT属性的列都是**作为主键的属性**，来自动生成唯一标识一条记录的主键值。
14. 说一说主键和UNIQUE约束的区别
   - 一张表中只能定义一个主键，却**可以定义多个UNIQUE约束**
   - 主键列不允许存放NULL，而**声明了UNIQUE属性的列可以存放NULL，而且NULL可以重复地出现在多条记录中**
15. NULL值意味着什么？
    NULL其实并不是一个值，它代表不确定，我们平常说某个列的值为NULL，意味着这一列的值尚未被填入
16. **为什么一定要有主键?**
    - 首先主键本身可以利用B+树高效率地进行查找
    - 其次没有主键，更新或删除表中特定行很困难，因为没有安全的方法保证只涉及相关的行。比如**update的时候,不用主键索引,就会锁住整个表**.
17. 说一说表中哪些列需要建立索引？
    - 主键和唯一键自动建立索引
    - 自增列必须建立索引
    - 对于外键，**父表中被子表依赖的列或者列组合必须建立索引**
18. 基于主键索引和普通索引的查询有什么区别？
   需要**回表**，基于非主键索引的查询需要多扫描一棵索引树
19. 为什么主键要设置自增属性且长度不应太大？
   - 为了满足B+树每层节点都是按照索引列的值从小到大的顺序排序，插入新值时可能会导致**页分裂**等性能开销。如果设置自增主键每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录， 也不会触发页分裂。有业务逻辑的字段做主键， 则往往不容易保证有**序插入**， 这样写数据成本相对较高
   - 同时对于非主键索引，叶子节点会存储主键值。所以主键字段的长度不应太大，主键长度越小， 普通索引的叶子节点就越小， 普通索引占用的空间也就越小。
20. 页分裂
    - 因为主键索引是有序的，才能使用二分法来搜索数据。所以如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。
    - 页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率
    - 如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。
21. 有没有什么场景适合**用业务字段直接做主键**的呢？
    因为没**有其他索引**，所以不用担心其他的二级索引内主键占用空间太大
   - 只有一个索引；
   - 该索引必须是唯一索引；
22. 为什么要重建非主键索引?
    - 索引可能因为删除， 或者页分裂等原因， 导致 ， 重建索引的过程会创建一个新的索引， 把数据按顺序插入， 这样页面的利用率最高， 也就是**索引更紧凑、 更省空间**。
    - 对于主键索引，重建的话会**导致整个表重建**
23. 说一说**前缀索引**
    前缀索引是指对字符类型字段的**前几个字符建立的索引**，用处是**减少索引占用的存储空间**，提升查询效率
24. 在一个市民信息表上， 是否有必要将身份证号和名字建立联合索引？
    如果有一个高频请求， 要根据市民的身份证号查询他的姓名， 这个联合索引就有意义了。 它可以在这个高频请求上用到**覆盖索引**， 不再需要回表查整行记录， 减少语句的执行时间。
25. 什么是**联合索引**
    多个普通字段组合在一起创建的索引就叫做联合索引，也叫组合索引. 只会构建出一棵索引树, 每个节点的键值不是单个的, 而是组合值
26. 说一说**最左前缀原则**
    - 概念
        联合索引的时候查询的条件必须从索引的最左边开始，中间不能有间隙，否则不会被命中。同时对于范围列后面的列也无法用到索引。
    - 原因
      - 比如(a,b,c,d)联合索引，a是有序的，在a相同的情况下b是有序的，如果只看b则b是无需的即无法利用B+树只能全表扫描。
      - 对于范围扫描，比如WHERE a > 1 AND b = 2;因为只有在a相同的情况下b才是有序的，索引经过范围查询后的a的数据集中b是无序的
    - 失效情况
      - 中间有间隙
      - 范围扫描
      - where a like "%%"，以%为开头的查询条件索引会失效
    - 注意
      - 查询优化器会自动判断WHERE的顺序
            即WHERE b = 1 AND a = 2;也可以用到ref方法的联合索引
      - WHERE b = 1也可能会利用到联合索引
            即采用index方法，全索引扫描的方法。一般index效率大all，因为索引树扫描只需要扫描索引列，而全表扫描还需要扫描data列。所以index会稍微快一些。同时因为二级索引树的叶子节点只记录索引列和主键值，而聚簇索引还要记录事务id，回滚指针等使得二级索引树比聚簇索引树小，进而导致全扫描二级索引树的IO开销更小。
27. 为什么使用联合索引
    - **减少开销**
        建立一个联合索引, 实际上相当于**联合建立了多个单列索引**. 而每多一个索引，都会增加**写操作的开销和磁盘空间的开销**。对于大量数据的表，使用联合索引会大大的减少开销！比如我们对a, b, c三个字段建立一个联合索引(a, b, c), 其实就相当于建立了三个单列索引, 在我们做这样的查询时, 比如:select * from user where a = 10 and b = 11, 我们只需要查询一颗联合索引树就可以得到结果, 不需要查询两个单列索引树, 然后再将各自所得的结果过滤合并, 这样可以大大减少磁盘I/O次数, 减少开销, 提高性能
    - **覆盖索引**
        使用联合索引的话, 有可能出现覆盖索引的情况, 即我们要查询的数据全部在这一棵联合索引树中, 那么我们只要查询一次就可以从叶子节点中得到数据, 而**不用再回表**去聚簇索引树中查找
    - 索引列越多，通过索引筛选出的数据越少, 更加高效
28. 说一说在建立联合索引的时候有什么要注意的？
    - 如果通**过调整顺序， 可以少维护一个索引**， 那么这个顺序往往就是需要优先考虑采用的。比如联合索引（a,b），因为最左前缀原则，一般就不需要在a上建立索引了
    - 建立联合索引时，要把**区分度大即更少重复的字段排在前面**，这样区分度大的字段越有可能被更多的SQL使用到
29. 说一说索引下推优化
    - 索引下推一般用于减少回表的开销
    - 在索引遍历过程中，对索引中包含的字段先做判断， 直接过滤掉不满足条件的记录， 减少回表次数。比如联合索引（a，b），搜索条件中有b的限制，则会先在存储引擎的层皮判断记录是否满足b的限制，再对满足限制的条件做回表。而不是先对所有的记录做回表再判断是否满足限制
30. 索引有什么缺点？
   - 需要**占用物理空间**，数量越大，占用空间越大；
   - 创建**索引和维护索引要耗费时间**，这种时间随着数据量的增加而增大；
   - 会**降低表的增删改的效率**，因为每次增删改索引，B+ 树为了**维护索引有序性**，都需要进行动态维护 
31. 什么时候适用索引？
    - 字段有**唯一性限制**的。极端情况索引只有两个值，会导致每次搜索即使用到索引也需要再查找50%的数据
    - **经常用于 WHERE 查询条件的字段**，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
    - **经常用于 GROUP BY 和 ORDER BY 的字段**，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的
32. 什么时候不需要创建索引？
    - **WHERE 条件，GROUP BY，ORDER BY 里用不到的字**
        索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。
    - **字段中存在大量重复数据，不需要创建索引**
        比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。
    - **表数据太少的时候，不需要创建索引；**
    - **经常更新的字段不用创建索引**
        比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要**频繁的重建索引**，这个过程是会影响数据库性能的。
33. 有什么优化索引的方法？
    - **前缀索引优化；**
        使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。**索引页能够存储的索引值越多，需要的IO操作就越少**
    - **覆盖索引优化；**
        查找的项可以直接从二级索引中得到，**避免回表**。
        假设我们只需要查询商品的名称、价格，有什么方式可以避免回表呢？建立一个联合索引
    - **主键索引最好是自增的；**
        InnoDB 创建主键索引默认为聚簇索引，数据被存放在了 B+Tree 的叶子节点上。也就是说，同一个叶子节点内的各个数据是按主键顺序存放的。自增主键插入数据时按序的，不需要移动数据。而非自增主键插入数据可能会导致页分裂，造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。
    - **索引最好设置为 NOT NUL**
        - 索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加**难以优化**，因为可为 NULL 的列会使索引、索引**统计**和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。
        - NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题，会导致更多的存储空间占用，因为 InnoDB 默认行存储格式COMPACT，会用 1 字节空间存储 NULL 值列表
    - **防止索引失效**
34. 前缀索引的局限性
    - order by 就无法使用前缀索引；
    - 无法把前缀索引用作覆盖索引；
35. 说一说索引失效的情况
    - **对索引使用左或者左右模糊匹配有时会导致索引失效**
       也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效；因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。通过前缀查找的过程类似于一般查找，只不过每次查找都要比较当前节点的前缀和要查找的前缀的大小
    - **对索引使用函数或对索引进行表达式计算**
        因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。
    - **对索引隐式类型转换**
        MySQL在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果索引是字符串，而条件是数字，则会将索引转换为数字，就相当于使用了函数
    - **联合索引非最左匹配**
        在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。
    - 在 WHERE 子句中，如果**在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列**，那么索引会失效。
36. 对索引使用左或者左右模糊匹配一定会导致索引失效吗？
    不一定。**判断是否使用索引的标准是，使用二级索引+回表的开销小于全表扫描**。而对于数据库表中**只有主键和二级索引字段的情况**，即使使用了左模糊匹配，也会**全扫描二级索引树**，因为二级索引树的叶子节点只记录索引列和主键值，而聚簇索引还要记录**事务id，回滚指针**等，使得二级索引树比聚簇索引树小，进而导致全扫描二级索引树的IO开销更小。
37. 联合索引非最左匹配一定会导致索引失效吗？
    不一定。判断是否使用索引的标准是，使用二级索引+回表的开销小于全表扫描。而对于数据库表中只有主键和二级索引字段的情况，即使使用了联合索引非最左匹配，也会全扫描二级索引树，因为二级索引树的叶子节点只记录索引列和主键值，而聚簇索引还要记录事务id，回滚指针等使得二级索引树比聚簇索引树小，进而导致全扫描二级索引树的IO开销更小。
38. 说一说count(*)，count(1),count(主键)，count(普通字段)的效率
    - 效率：count(*) = count(1) > count(主键) > count(普通字段)
    - count()意义是统计在对应字段的记录中,不为NULL的有多少个
    - 对应count(\*)和count(1)都是求对应字段记录一共有多少行，所以效率相同。对于count(*)，count(1)，count(主键)，如果存在对应的二级索引，那么都会全扫描二级索引，因为这样的IO开销更低，在这种情况下，由于count(\*)和count(1)不需要判断值是否为null，所以效率更高。而对于普通字段，会采用全表扫描的方式，效率最差。
    - 如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个**二级索引**。
39. 如何优化count(*)
    - 近似值,通过show table status 或者 explain 命令来表进行估算
    - 额外表保存计数值
40. 说一说EXPLAIN
    - MySQL 提供了一个 EXPLAIN 命令，它**可以对SQL语句进行分析，并输出SQL执行的详细信息，以供开发人员针对性优化.**
    - 主要字段:
      - **type**: 查询类型,const单值索引查询,index索引扫描,all全表扫描,range索引范围查询
      - **possible_keys**:查询可能用到的key
      - **key**:查询真正使用到的索引
      - **rows**:估算的需要扫描的行数, 这个值直观的显示了SQL的效率好坏, 原则上rows越少越好
      - **extra**:额外信息会在extra字段显示出来, **Using index**表示"覆盖索引扫描", 推荐**Using temporary**查询有使用临时表, 建议优化.“**Using index condition**”，说明使用了索引下推,推荐.Using filesort查询语句中包含 **group by** 操作，而且**无法利用索引完成排序操作**，建议优化.
41. 扫描数据的方式有哪些（执行效率从低到高的顺序）
    - All（全表扫描）；
        扫描的就是聚簇索引的B+树
    - index（全索引扫描）；
        比ALL稍快，但开销依然很大。**判断是否使用索引的标准是，使用二级索引+回表的开销小于全表扫描**
    - range（索引范围扫描）；
        需要范围查找
    - ref（非唯一索引扫描）；
        因为索引值不唯一，索引使用了索引还需要小范围扫描
    - eq_ref（唯一索引扫描）；
        使用主键或唯一索引时产生的访问方式，通常使用在多表联查中。比如，对两张表进行联查，关联条件是两张表的 user_id 相等，且 user_id 是唯一索引，那么使用 EXPLAIN 进行执行计划查看的时候，type 就会显示 eq_ref
    - const（结果只有一条的主键或唯一索引扫描）。
        使用了主键或者唯一索引与常量值进行比较
    - 注意
      - Using filesort 
        当查询语句中包含 **group by** 操作，而且**无法利用索引完成排序操作**的时候， 这时不得不选择相应的排序算法进行，甚至可能会通过文件排序，效率是很低的，所以要避免这种问题的出现。
      - Using temporary：使了**用临时表保存中间结果**，MySQL 在对查询结果排序时使用临时表，常见于排序 **order by** 和分组查询 **group by**。效率低，要避免这种问题的出现。
      - Using index：所需数据只需在索引即可全部获得，不须要再到表中取数据，也就是使用了覆盖索引，避免了回表操作，效率不错


#### 5. 事务
1. 什么是事务？
    **需要保证原子性、隔离性、一致性和持久性的一个或多个数据库操作称之为一个事务**
2. 事务有哪些特性？(**ACID**)
   - **原子性**（Atomicity）：
        一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样；
   - **一致性**（Consistency）：
        如果数据库中的数据全部符合现实世界中的约束，我们说这些数据就是一致的，或者说符合一致性的。
   - **隔离性**（Isolation）：
        数据库允许多个**并发**事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
   - **持久性**（Durability）：
        事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失
3. InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？
   - 原子性是通过 **undo log（回滚日志）** 来保证的；
   - 持久性是通过 **redo log （重做日志）**来保证的；
   - 隔离性是通过 **MVCC（多版本并发控制） 或锁机制**来保证的；
   - 一致性则是通过**持久性+原子性+隔离性**来保证；
4. 并行事务会引发什么问题？
   - **脏写**（ Dirty Write ）
        一个事务修改了另一个**未提交事务**修改过的数据
   - **脏读**（ Dirty Read ）
      - 一个事务读到了另一个**未提交事务**修改过的数据。
      - 比如事务A读取并修改数据而且并未提交，这时事务B又读数据，读到的就是未提交事务A修改后的数据。如果事务 A 发生了回滚，那么事务 B 刚才得到的数据就是过期的数据
   - **不可重复读**（Non-Repeatable Read）
      - 在一个**事务内多次读取**同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。
      - 比如A事务中先读到一个数据，B提交了事务并更新了数据，A再读取数据时发现前后两次数据不一致。
   - **幻读**（Phantom）
      - 在一个**事务内多次查询**某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。
      - 比如事务A先查询满足条件的记录数目，同时事务B也在查询相同条件记录数目，这时事务A添加了符合条件的记录，并提交事务，就会导致事务B再次查询时记录数目不一样。
5. 事务并发时事务A删除记录导致事务B读取记录变少算幻读吗？
    不算。幻读只是重点强调了读取到了之前**读取没有获取到的记录**。这个算不可重复读。
6. 幻读于脏读，不可重复的区别在哪里？
    幻读是针对**一个范围内的已提交记录**而言，不可重复读是针对**一条已提交的记录**，而脏读对应的是**未提交的记录**
7. 如何规避并发事务的问题？
   - 问题严重性：脏写 > 脏读 > 不可重复读 > 幻读
   - 设立一些隔离级别，隔离级别越低，越严重的问题就越可能发生
   - **读未提交**
      - 指一个事务还没提交时，它做的变更就能被其他事务看到； 
      - 可能发生 脏读 、不可重复读和幻读问题
   - **读已提交**
      - 指一个事务提交之后，它做的变更才能被其他事务看到
      - 可能发生不可重复读和幻读问题，但是不可以发生脏读问题
   - **可重复读**
      - 指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的
      - 可能发生幻读问题，但是不可以发生脏读和不可重复读的问题
      - MySQL InnoDB 引擎的**默认隔离级别**,但是其通过next-key lock 锁（行锁和间隙锁的组合）来锁住记录之间的“间隙”和记录本身，防止其他事务在这个记录之间插入新的记录，这样就**在可重复读层次上避免了幻读现象。**
   - **可串行化**
      - 会对记录加上**读写锁**，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；
      - 决幻读现象不建议将隔离级别升级到「串行化」，因为这样会导致数据库在**并发事务时性能很差**
      - 各种问题都不可以发生
   - 脏写这个问题十分严重了，不论是哪种隔离级别，都不允许脏写的情况发生
8. 这四种隔离级别具体是如何实现的呢？
   - 读操作利用多版本并发控制（ MVCC ），写操作进行加锁
       - 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；
       - 对于「读已提交」，**「每次读取数据时」都会重新生成一个 Read View**，ReadView的存在本身就保证了事务不可以读取到未提交的事务所做的更改，也就是避免了脏读现象；
       - 对于「可重复读」，「**启动事务时」生成一个 Read View，之后的操作都复用这个ReadView**，这样也就避免了不可重复读和**快照读的幻读**的问题，但是仍可能产生**当前读情况下的幻读**。（ MySQL 在REPEATABLE READ 隔离级别实际上就已经解决了 幻读 问题。）
       - 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；
   - 读、写操作都采用 加锁 的方式
       - 如果我们的一些业务场景（比如银行存款）不允许读取记录的旧版本，而是每次都必须去读取记录的最新版本。这样在读取记录的时候也就需要对其进行 加锁 操作，这样也就意味着 读 操作和 写 操作也像 写-写 操作那样排队执行。
       - 通过加锁可以解决脏写（记录锁），脏读，不可重复读，幻读（next-key锁）的问题
9. 两种并发方式的区别（性能影响）
    采用 MVCC 方式的话， 读-写 操作彼此并不冲突，性能更高，采用 加锁 方式的话， 读-写 操作彼此需要排队执行，影响性能。一般情况下我们当然愿意采用 MVCC 来解决 读-写 操作并发执行的问题，但是业务在某些特殊情况下，要求必须采用 加锁 的方式执行
10. 什么是MVCC？
    **MVCC即多版本并发控制, 通过readview和「版本链」来控制并发事务访问同一个记录的行为就是MVCC**
11. ReadView在MVCC中的工作机制是什么？（MVCC是怎么实现的？）
    **通过比对Read View和记录中的事务id，来判断当前事务是否可以访问该记录**
    - ReadView包含四个字段
      - 创建该 Read View 的事务的事务 id
      - 创建 Read View 时的活跃事务列表
      - 创建 Read View 时的活跃事务列表中id最小的事务
      - 创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1；
    - 同时聚簇索引记录中包含两个**隐藏列**
      - 最近修改该记录的事务id
      - 回滚指针，指向上一个旧版本记录的undo日志
    - 这样就可以通过比对Read View和记录中的事务id，来判断当前事务是否可以访问该记录
        - 如果被访问版本的 trx_id 属性值与 ReadView 中的 creator_trx_id 值相同，意味着当前事务在**访问它自己修改过的记录**，所以该版本可以被当前事务访问。
        - 如果被访问版本的 trx_id 属性值小于 ReadView 中的 min_trx_id 值，表明生成该版本的事务**在当前事务生成 ReadView 前已经提交**，所以该版本可以被当前事务访问。
        - 如果被访问版本的 trx_id 属性值大于 ReadView 中的 max_trx_id 值，表明生成该版本的事务**在当前事务生成 ReadView 后才开启**，所以该版本不可以被当前事务访问。
        - 如果被访问版本的 trx_id 属性值在 ReadView 的 min_trx_id 和 max_trx_id 之间，那就需要判断一下**trx_id 属性值是不是在 m_ids 列表中**，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问
12. 读已提交是如何实现的？
    - 通过比较readview里的四个字段和聚簇索引记录中包含两个隐藏列来判断当前事务是否可以访问该记录。
    - 同时对于读已提交，是在**每次读取数据时生成一个readview**保证了不会发生读未提交。
        比如事务A,B 先后开始，A修改了记录,还未提交。B读取记录，同时生产了readview。由于此时A还未提交，A的事务id仍然在B的readview记录的活跃事务id范围内，B就不会读取这个版本的记录而是**沿着版本链找到事务id小于最小活跃事务id的记录**来读取。但是如果A提交了，B再读取的时候，又会生成新的readview，这时候就可以读到A修改后的数据了。   
13. 可重复读是如何实现的？
    - 通过比较readview里的四个字段和聚簇索引记录中包含两个隐藏列来判断当前事务是否可以访问该记录。
    - 同时对于可重复读，是在**启动事务时生成一个readview**保证了不会发生不可重复读，并且对于InnoDB而言，也保证了不会发生**快照读的幻读**。
    - 比如事务A,B先后开始，同时生成了各自的readview，即使A在事务内多次修改记录，但由于readview是只在启动事务时生成，对于B来说A仍然在readview内保存的活跃事务id列内，所以这些记录不可以被访问。并且即使A提交了，B因为再次读取时也没有生成新的readview也还是不能访问这些记录，只能通过版本链找到旧记录来访问。
14. 什么是当前读与快照读？
    - 快照读就是普通的查询，即SELECT
    - 当前读是SELECT ... FOR UPDATE，update，insert，delete。获取最新的记录，同时为了防止别人进行修改导致幻读现象，还要加**next-key**锁。
15. InnoDB是怎么解决幻读问题的？
    - 对于**快照读**是通过MVCC机制，在可重复读隔离级别下解决。
    - 对于**当前读**，比如SELECT ... FOR UPDATE，update，insert，delete等是采用**next-key锁**来解决。
        - next-key锁就是记录锁和间隙锁的组合。**记录锁**，会锁住本行的记录；而**间隙锁**，锁的就是两个值之间的空隙。比如事务A通过当前读获取到了一些最新的记录，同时事务B插入了一些记录然后提交，如果事务A再次进行当前读，就会发生幻读现象，即前后记录不一样。通过锁机制就可以避免这种**可重复读隔离级别使用当前读造成的幻读现象**，由于INSERT操作会产生**插入意向锁**,而插入意向锁又和间隙锁冲突从而避免幻读现象。
        - 然后有时候next-key会退化为记录锁或者间隙锁（**引导面试官提问！**）
    - 一般在业务中,隔离级别为RR的情况下,我们使用select...for update避免幻读,比如两个业务都对而非唯一索引order=1000的插入数据,如果先用select检查该记录是否存在,再插入记录,就会导致有两条order相同的记录,即会产生幻读.
16. 所有的select都不会对记录加锁吗？
    不是。在可重复读隔离级别中，普通的 select 语句就是基于 MVCC 实现的**快照读**，也就是不会加锁的。而 select .. for update 语句就不是**快照读**了，而是当前读了，也就是每次读都是拿到最新版本的数据，但是它会对读到的记录加上**next-key lock 锁**。
17. 在执行update的时候要注意什么？
   - 在where条件中要使用唯一索引。由于update是当前读，所以会采用next-key来锁住当前记录以及之后一段间隙的记录。如果采用唯一索引，那么next-key就会退化为**记录锁**，不会对其他并行事务有什么影响，而如果**不采用索引扫描的方式，会导致全表扫描**，即每个值都依次被锁住，相当于整个表被锁住。会导致业务停滞
   - 将 MySQL 里的 sql_safe_updates 参数设置为 1，开启安全更新模式
   - 如果即使在 where 条件中带上了列索引列，而优化器硬要走全表扫描，那么force index([index_name])强制指定
18. 优化器选择走全表扫描可能会导致什么问题
    如果是在update语句中，由于update是当前读，会使用next-key锁，全表扫描就相当于整个表都锁住了。
19. next-key什么情况下会退化为当前锁？
    如update where条件中用到唯一索引，并且优化器也选择使用索引扫描的时候
20. 如何启动事务？
    - 最简单的：begin，commit
    - 默认隐式提交，即执行“增删改”语句的，执行完就自动提交事务的
    - **begin/start transaction** 命令
    - **start transaction with consistent snapshot** 命令
        执行了 begin/start transaction 命令后，**并不代表事务启动**了。只有在执行这个命令后，执行了**增删查改**操作的SQL语句，才是事务真正启动的时机；执行了 start transaction with consistent snapshot 命令，就会马上启动事务
21. 为什么不推荐使用**长事务**？
    - 当没有事务再需要用到这些回滚日志时， 回滚日志会被删除。
    - 长事务意味着系统里面会存在很老的事务视图。 由于这些事务随时可能访问数据库里面的任何数据， 所以这个事务提交之前， 数据库里面它可能用到的回滚记录都必须保留， 这就会导致大量占用存储空间。
22. 如何防止长事务？
   - 客户端
     - **开启自动提交**set autocommit=1,并通过显式语句的方式来启动事务
     - 确认是否有不必要的只读事务
     - 通过SETMAX_EXECUTION_TIME命令，来控制**每个语句执行的最长时间**， 避免单个语句意外执行太长时间
   - 服务端 
     - 监控 information_schema.Innodb_trx表，设置**长事务阈值**， 超过就报警/或者kill
     - 在业务功能测试阶段要求输出所有的general_log， 分析日志行为提前发现问题
#### 6. 锁
1. MySQL 有哪些锁
   - 根据加锁的范围，可以分为全局锁、表级锁和行锁
   - 表级锁包括表锁，元数据锁，意向锁，AUTO-INC锁
2. 说一说全局锁
   - 执行后，整个数据库就处于**只读**状态了，这时其他线程执行以下操作，都会被阻塞：
        对数据的增删改操作，比如 insert、delete、update等语句；
        对表结构的更改操作，比如 alter table、drop table 等语句。
   - 使用全局锁：**flush tables with read lock**
   - 释放全局锁：unlock tables
3. 全局锁应用场景是什么？
    全局锁主要应用于做**全库逻辑备份**，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。
4. 加全局锁又会带来什么缺点呢？
    加上全局锁，意味着整个数据库都是只读状态。那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会**造成业务停滞**。
5. **备份数据库**时如何避免全局锁的问题？/备份数据库时如何避免业务收到影响？/备份数据库时可以更新数据库吗？/主从复制的时候会影响主服务器的更新吗?
    - 如果数据库如InnoDB支持事务，那么就可以在可重复读的隔离级别下，在**备份数据库之前先开启事务**，会先创建 Read View，然后整个事务执行即备份期间都在用Read View。
    - 而且由于 **MVCC 的支持，备份期间业务依然可以对数据进行更新操作**。因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。
    - 对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法
    - 不使用InnoDB就可以采用主从复制的方法备份.
6. 如何备份数据库？
     mysqldump，在使用 mysqldump 时加上 –single-transaction 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。
7. MySQL 表级锁有哪些？
    - 表锁；
    - 元数据锁（MDL）;
    - 意向锁；
    - AUTO-INC锁
8. 说一说表锁
    - 表锁会限制本线程和别的线程的读写。应答尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，尽量使用颗粒度更细的行级锁
    - 表级别的共享锁，也就是读锁
        lock tables t_student read;
    - 表级别的独占锁，也就是写锁
        lock tables t_stuent wirte;
    - 释放当前会话所有锁
        unlock tables
9. 说一说元数据锁（MDL）
    - MDL不需要显示使用。当我们对一张表进行 **CRUD** 操作时，**对表**自动加的是 MDL 读锁；对一张表做**结构变更**操作的时候，加的是 MDL 写锁；
    - 当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。
10. MDL不需要显示调用，那它是在什么时候释放的?
    MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。
11. MDL锁会导致什么问题？
    如果数据库有一个长事务，并且执行了select语句，同时又另一个线程也对表结构做变更操作。则这个线程会被阻塞，同时也会导致后续的其他线程的select请求都被阻塞，会导致数据库线程很快就会饱满
12. 为什么表结构做变更操作阻塞会导致后续select请求都被阻塞？
    申请 MDL 锁的操作会形成一个队列，队列中**写锁获取优先级高于读锁**，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。
13. 如何解决MDL锁的问题？（对表结构进行变更前要注意什么？）
    在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。
14. 说一说共享锁（S锁）与独占锁（X锁）
    **共享锁**：读锁就是共享锁，读与读直接不阻塞
    **独占锁**：写锁就是独占锁，读与写，写与写直接都阻塞
15. 说一说意向锁（IS,IX）
    - 在使用 InnoDB 引擎的表里对某些**记录**加上共享锁之前，需要先在**表级别**加上一个意向共享锁；在使用 InnoDB 引擎的表里对某些**纪录**加上独占锁之前，需要先在**表级别**加上一个意向独占锁
    - 意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和**表锁**发生冲突。
    - 当执行**插入、更新、删除**操作，需要先对表加上意向独占锁，然后对该记录加独占锁。
    - 普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的
    - select 也是可以对记录加共享锁和独占锁的
        select ... lock in share mode;
        select ... for update;**
    - 注意**意向锁和插入意向锁完全不同**!
16. 意向锁的目的是什么?
    意向锁的目的是为了**快速判断表里是否有记录被加锁**.如果没有意向锁，那么加独占表锁时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。
17. 说说AUTO-INC 锁
    - **用于实现AUTO_INCRMENT属性**
    - 在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉而**不是在事务提交后释放**
    - 一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 AUTO_INCREMENT 修饰的字段的值是**连续递增的**
18. AUTO-INC 锁会导致什么问题?
    影响并发. AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞
19. 如何解决AUTO-INC锁的问题?
    使用**轻量级**的锁来实现自增。一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而**不需要等待整个插入语句执行完后才释放锁。**
20. 轻量级的锁有什么问题?
    只使用轻量级锁会导致并发插入时值是不连续的,并且在主从复制的场景中是不安全的。默认是混合使用.
21. MySQL行级锁有哪些？
     - **记录锁**， Record Lock也就是仅仅把一条记录锁上；
     - **间隙锁**，锁定一个范围，但是不包含记录本身；
        - 注意间隙锁与间隙锁之间是不冲突，即两个事务可以同时持有包含共同间隙的间隙锁
        - 其一是两个间隙锁的间隙区间完全一样；
        - 其二是一个间隙锁包含的间隙区间是另一个间隙锁包含间隙区间的子集。
     - **Next-Key Lock**：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。
     - **插入意向锁**,是一种特殊的间隙锁。只有insert会有插入意向锁
        - 每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，那 Insert 语句应该被阻塞，并生成一个插入意向锁 。
        - 插入意向锁只会和间隙锁或 Next-key 锁冲突，间隙锁唯一的作用就是防止其他事务插入记录造成幻读，正是由于在执行 INSERT 语句时需要加插入意向锁，而插入意向锁和间隙锁冲突，从而阻止了插入操作的执行。
22. 行级锁的目的是什么?
    防止在当前读的情况下发生脏读,不可重复读,幻读的情况
23. **MySQL是怎么加锁的?**
    - 对记录加锁时，**加锁的基本单位是 next-key lock**
    - next-key lock 在一些场景下会退化成记录锁或间隙锁。
    - 主要是看是对唯一索引还是普通索引加锁
    - 千万不能在update的时候不加索引这样会锁住全表
24. 唯一索引等值**查询场景**下加锁
    - 当查询的记录是存在的，在用「唯一索引进行等值查询」时，next-key lock 会退化成「记录锁」。
    - 当**查询的记录是不存在**的，在用「唯一索引进行等值查询」时，next-key lock 会退化成「间隙锁」。范围是比查询值要小的最大索引记录到比查询值要大的最小索引记录,比如记录范围为[0, 16]且其中不存在8,查8,则会锁住(8, 9)
25. 唯一索引范围查询场景下加锁
    - 比如select * from t_test where id>=8 and id<9 for update;记录范围为[0, 16]
    - 先查找id = 8，next-key锁退化为记录锁,锁住8
    - 由于是范围查找，next-key锁退化为间隙锁，锁住(8, 9)
    - 两把锁
26. 非唯一索引等值查询
    - 当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁。间隙锁会加到第一个不符合条件的值停止,因为索引是有序的！
        查8，锁分别是 next-key lock (0,8] 和间隙锁 (8,9) 
    - 当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。会锁住查询值后面的所有范围内的值
        查8，锁就是(8, 16)
27. 非唯一索引范围查询
    - 两把next-key lock，不会退化为间隙锁和记录锁
    - 比如select * from t_test where id>=8 and id<9 for update;记录范围为[0, 16]
    - 锁住(0, 8], (8, 9]
28. 总结：唯一索引和普通索引加锁有什么不同?
    - 唯一索引等值查询：
      - 当查询的记录是存在的，next-key lock 会退化成「记录锁」。
      - 当查询的记录是不存在的，next-key lock 会退化成「间隙锁」。
    - 非唯一索引等值查询：
      - 当查询的记录存在时，next-key lock + 间隙锁
      - 当查询的记录不存在时，next-key lock退化为间隙锁
    - 非唯一索引和主键索引的范围查询的加锁规则不同之处在于：
      - 唯一索引在满足一些条件的时候，next-key lock 退化为间隙锁和记录锁。
      - 非唯一索引范围查询，next-key lock 不会退化为间隙锁和记录锁。
29. **Insert**语句是怎么加行级锁的？
    Insert 语句在正常执行时是不会生成锁结构的，它是靠聚簇索引记录自带的 trx_id 隐藏列来作为隐式锁来保护记录的。
30. **隐式锁**
    - 当事务需要加锁的时，如果这个锁不可能发生冲突，InnoDB会跳过加锁环节，这种机制称为隐式锁。隐式锁是 InnoDB 实现的一种**延迟加锁机制**，其特点是只有在可能发生冲突时才加锁，从而减少了锁的数量，提高了系统整体性能。
    - 隐式锁就是在 Insert 过程中不加锁，只有在特殊情况下，才会将隐式锁转换为显示锁
      - 如果记录之间加有间隙锁，为了避免幻读，此时是不能插入记录的；
      - 如果 Insert 的记录和已有记录存在唯一键冲突，此时也不能插入记录
            对于唯一二级索引列重复，会添加next-key锁
31. 说一说MySQL中的**死锁**现象
    一般MySQL死锁是由于插入意向锁和间隙锁冲突导致的.比如对于非唯一索引,事务A,B先后使用SELECT...FOR UPDATE查询(如果用普通SELECT不会上锁会导致幻读)一个不存在的值,就会用间隙锁锁住后面所有的值.间隙锁之间不冲突.如果A,B还要分别插入Insert,由于插入意向锁和间隙锁之间冲突,就会导致双方互相都在等待对方释放间隙锁,导致死锁
32. 如何避免MySQL的死锁?
    - 设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。
    - 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。
    - 还有一个是业务层面,比方说不设置普通索引,用唯一索引保证插入的值不重复
33. MySQL如何查看事务加锁情况
    查看information_schema数据库的一些表,以及通过SHOW ENGINE INNODB STATUS命令查看当前系统中每个事务都加了哪些锁
      - innodb_locks表
        如果一个事务想要获取某个锁但未获取到，该锁信息将被记录。
        如果一个事务因为获取到了某个锁，但是这个锁阻塞了别的事务的话，该锁信息会被记录。
      - innodb_lock_wait表
        表明当前系统中因为等待哪些锁而让事务进入阻塞状态

#### 7. 日志redolog，undolog, binlog
1. 说一说undo日志，redo日志, bin日志
    - undo日志（回滚日志）是用来保证事务的**原子性**的.如果在事务过程中,系统崩溃,会利用undo日志**回滚**.同时undo日志也用来实现**MVCC**
    - redo日志（重做日志）是用来保证事务的**持久性**的.防止事务提交后,对应的脏页还没有刷盘,系统崩溃导致的**数据丢失**
    - bin日志是（归档日志）主要用于**数据备份**和**主从复制**；
2. 说一说undo日志
   - 作用（**为什么需要undo日志**）
       - 用于回滚
         - 比如事务在执行过程中,MySQL发生崩溃，就可以利用undo日志回滚到事务之前的数据
         - Insert插入记录时，记录主键，回滚时根据主键删除对应记录
         - Delete删除记录时，记录内容，回滚时将这些内容组成的记录插入表中
         - Update更新记录时，记录旧值，回滚时将更新的列更新为旧值
         - 注意不同的操作对应的undo日志内容也是不同的
       - 实现MVCC
         - undo log 格式都有最近一次更新这条数据的事务id和指向更新这个事务之前形成undolog的回滚指针
         - 通过回滚指针形成的版本链，结合ReadView机制判断版本链中的哪个版本是当前事务可见的，即可以实现MVCC机制，避免脏读，可重复读与幻读。
   - 类型
        逻辑格式的日志
   - 产生的时机
        根据不同的操作产生不同的undo日志
   - 写入内存的时机
        **事务开始之前**，将当前版本生成的undolog写入**内存缓存**中
   - 刷盘时机
        每次提交后**写入磁盘**
   - 释放时机
       - purge线程通过readview来判断当没有事务再需要用到这些回滚日志，即当系统里没有比这个回滚日志更早的read-view的时候，就可以删除了。（比如说对于RR隔离级别，在第一次执行SELECT时创建readview。当前的readview可见，后面的别的并发事务更新的数据都不可见，即防止了不可重复读与幻读。那么当这个事务提交后，即这个readview释放了，就说明不再需要这个readview前的undo日志了，就可以删除了）
       - insert undo在事务提交之后就可以被释放掉了，而 update undo 由于还需要支持 MVCC ，不能立即删除掉。
3. Undo页是记录什么？
    根据不同的操作产生不同的undo日志
4. 查询一条记录，就只需要缓冲一条记录吗？
    不是的。当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，将页加载到 Buffer Pool 后，再通过页里的「页目录」去定位到某条具体的记录。
5. 说一说redo日志
   - 作用（**为什么需要redo日志**）
      - Buffer Pool 是基于内存的，如果断电重启，会导致未写入磁盘的脏页丢失。而redo日志就可以防止数据丢失，从而达到事务的**持久性**这一特性
      - redo log 是物理日志，记录了某个数据页做了什么修改，对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新.在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。当系统崩溃时，**虽然脏页数据没有持久化，但是 redo log 已经持久化**，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。
      - 利用WAL技术将随机写转为顺序写，提升MySQL 写入磁盘的性能。**WAL技术**： MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上
   - 类型
        物理日志，记录的是物理数据页面的修改的信息
   - 产生时机
        事务开始后就产生redolog到内存中的日志缓存中，随着后台线程刷新等刷盘时机在事务过程中就会被刷新到磁盘
   - 刷盘时机
      - 日志缓存空间不足时
      - 事务提交时（保持持久性）
      - 后台MASTER线程刷新
      - 正常关闭服务器时
      - innodb_flush_log_at_trx_commit 参数控制
   - 磁盘释放时机
        通过checkpoint判断即对应事务的脏页已经刷新到磁盘里后，redo日志占用的磁盘空间就可以复用
6. 被修改 Undo 页面，需要记录对应 redo log 吗？
    需要的。
   - 开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，**undo log 会写入 Buffer Pool 中的 Undo 页面**。
   - 不过，在修改该 Undo**页面**(而不是日志，是往页面添加日志)前需要先记录对应的 redo log，所以先记录修改 Undo 页面的 redo log ，然后再真正的修改 Undo 页面。
7. redo log 和 undo log 区别在哪？
   - redo log 记录了此次事务**完成后的数据状态，记录的是更新之后**的值；
   - undo log 记录了此次事务**开始前的数据状态，记录的是更新之前**的值；
   - 事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务
8.  对于数据库服务器,突然断电再恢复后会发生什么?
    redo日志来重做以提交的事务保证持久性,undo日志回滚未提交的事务保证原子性
9.  为什么要使用redolog日志恢复数据而不是在事务提交前直接将数据写到磁盘?
    - 写入 redo log 的方式使用了追加操作， 所以磁盘操作是**顺序写**，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是**随机写**。WAL 技术的另外一个优点：MySQL 的写操作从磁盘的「随机写」变成了「顺序写」，提升语句的执行性能。
    - redo log体积小，只记录了哪一页修改的内容，因此体积小，刷盘快
10. 产生的 redo log 是直接写入磁盘的吗？
    - redo log 也有自己的缓存—— redo log buffer，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘
    - redo log buffer 默认大小 16 MB，可以通过 innodb_log_Buffer_size 参数动态的调整大小，增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而**提升写 IO 性能**
11. innodb_flush_log_at_trx_commit 参数控制的是什么？
    - 控制刷盘时机
    - 0，提交事务时留在redo log buffer 中 ，该模式下在事务提交时不会主动触发写入磁盘的操作。
    - 1，每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘，这样可以保证 MySQL 异常重启之后数据不会丢失
    - 2，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache（如果你想了解 Page Cache，可以看这篇 (opens new window)），Page Cache 是专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存
12. innodb_flush_log_at_trx_commit 为 0 和 2 的时候，什么时候才将 redo log 写入磁盘？
    - 针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 write() 写到操作系统的 Page Cache，然后调用 fsync() 持久化到磁盘。所以参数为 0 的策略，MySQL 进程的崩溃会**导致上一秒钟所有事务数据的丢失**;
    - 针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，只有**在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失。**
13. redo日志能保证任何情况下数据都不会丢失吗？
    见上问。取决于innodb_flush_log_at_trx_commit参数。
    - 数据库宕机，2，1不会丢失，0丢失
    - 操作系统宕机，1不会丢失，2，0丢失
14. 这三个参数的应用场景是什么？
    - 数据安全性：参数 1 > 参数 2 > 参数 0
    - 写入性能：参数 0 > 参数 2> 参数 1
    - 在一些对数据安全性要求比较高的场景中，显然 innodb_flush_log_at_trx_commit 参数需要设置为 1。
    - 在一些可以容忍数据库崩溃时丢失 1s 数据的场景中，我们可以将该值设置为 0，这样可以明显地减少日志同步到磁盘的 I/O 操作。
    - 安全性和性能折中的方案就是参数 2，虽然参数 2 没有参数 0 的性能高，但是数据安全性方面比参数 0 强，因为参数 2 **只要操作系统不宕机，即使数据库崩溃了，也不会丢失数据**，同时性能方便比参数 1 高。
15. redo log 文件写满了怎么办？
    - redolog存储在重做日志组内，采用循环写的方式工作
    - 通过checkpoint将脏页刷新到磁盘中变成干净页，然后标记 redo log 哪些记录可以被覆盖的过程。
16. 说一说bin日志
   - 作用：
       - MySQL 在完成一条更新操作后，**Server 层还会生成一条 binlog**，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。
       - 用于复制,binlog日志中记录了数据库发生的各种改变的信息,在**主从复制**中，从库利用主库上的binlog进行重播，实现主从同步。
       - 用于恢复,我们不可能每时每刻都全量备份数据库,所以要使用binlog从上一次的全量备份开始重播恢复数据库
   - 类型
        逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
   - 产生时机
        事务开始后就一直在向缓存写入
   - 刷盘时机
        - 事务执行过程中，先把日志写到 binlog cache（Server 层的 cache）
        - 事务提交的时候，再把 binlog cache 写到 操作系统的内存种的binlog 文件中。
        - 最后操作系统通过sync，才是将数据持久化到磁盘的操作
        - 具体通过sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率
   - 磁盘释放时机
        有个保存时机限制，超过保存时间就删除
17. 为什么有了 binlog， 还要有 redo log？
    这个问题跟 MySQL 的时间线有关系。
    - 最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。
    - 而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。
18. 说一说redo日志和bin日志的不同
    - 适用对象不同
      - binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；
      - redo log 是 Innodb 存储引擎实现的日志
    - 文件格式不同
      - binlog有三种格式，一种是逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。第二种是记录实际更新数据的每一行。第三种是混合第一种和第二种格式
      - redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新
    - 写入方式不同：
      - binlog 是**追加写**，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。
      - redo log 是**循环写**，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。
    - 用途不同：
      - binlog 用于备份恢复、主从复制；
      - redo log 用于掉电等故障恢复。
19. 如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？
    不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。
    - 因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。
    - binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据
20. 说一说服务器一般的部署方案
    一主多从，即一台主服务器（Master）和多台从服务器（Slave）。对于改变数据库状态的请求（DDL、DML等），就将它们发送给主服务器，对于单纯的查询（如SELECT语句）请求，就将它们发送给从服务器。这样可以大大减轻数据库压力,提高效率
21. 什么是主从复制
    MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点.binlog日志中正好记录了数据库发生的各种改变的信息，从服务器读取主服务器产生的binlog日志，然后执行这些binlog日志中所记录的数据库变化语句，从而达到主从服务器数据一致的效果。
22. 主从复制的作用是什么?
    - 热备份数据,作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据丢失
    - 读写分离,减轻服务器压力,提高并发效率
    - 从服务器备份不干扰主服务器更新
23. 主从复制的工作流程
    - 写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。
        MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。
    - 同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。
        从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。
    - 回放 Binlog：回放 binlog，并更新存储引擎中的数据。
        从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。
24. 从库是不是越多越好？
    - 不是的。因为从库数量增加，从库连接上来的 I/O 线程也比较多，主库也要创建同样多的 log dump **线程来处理复制的请求**，对主库资源消耗比较高，同时还受限于**主库的网络带宽**。
    - 所以在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。
25. 主从复制的类型
    - 同步复制
        当主库执行完一个事务，然后所有的从库都复制了该事务并成功执行完才返回成功信息给客户端。因为需要等待所有从库执行完该事务才能返回成功信息，所以全同步复制的性能很差。
    - 异步复制
        主库不会主动推送数据到从库，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理.
        MySQL默认的复制,响应速度快，但是会导致当主节点崩溃,从节点提升为主节点后新节点上的数据不完整
    - 半同步复制
        介于同步复制和异步复制之间。主库在执行完一个事务后，**等待至少一个从库**收到并写入到中继日志中才返回给客户端
        兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险。
26. sync_binlog参数的作用？
    - sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由**操作系统决定何时将数据持久化到磁盘**；
        默认值
        性能最好风险最大，一旦主机发生异常重启，在 binlog cache 中的所有 binlog 日志都会被丢失
    - sync_binlog = 1 的时候，表示每次提交事务都会 write，然后**马上执行 fsync**；
        最安全但是性能损耗最大的设置。因为当设置为1的时候，即使主机发生异常重启，也最多丢失 binlog cache 中未完成的一个事务，对实际数据没有任何实质性影响，就是对写入性能影响太大
    - sync_binlog =N(N>1) 的时候，表示每次提交事务都 write，但**累积 N 个事务**后才 fsync。
        能容少量事务的 binlog 日志丢失的风险，为了提高写入的性能，一般会 sync_binlog 设置为 100~1000 中的某个数值
27. 如何查看binlog内容
    mysqlbinlog查看binlog在磁盘中存储的文件
28. 为什么再大的事务的提交（commit）的时间也是很短暂的？
    因为后台线程会每秒都将redo log刷新到磁盘中。开启binlog后可能会造成提交速度减慢，因为是一次性写入的。
29. 怎样让数据库恢复到半个月内任意一秒的状态？
    - 找到最近的一次全量备份，从这个备份恢复到临时库；
    - 从备份的时间点开始， 将备份的binlog依次取出来， 重放到对应的时刻
30. 什么时候需要恢复临时库或者说恢复数据？
    - 误操作时需要恢复数据
    - 当你需要扩容的时候， 也就是需要再多搭建一些备库来增加系统的读能力的时候，要用全量备份加上应用binlog来实现的， 这个“不一致”就会导致你的线上出现主从数据库不一致
31. 一天一备和一周一备有什么区别？
    在一天一备的模式里， 最坏情况下需要应用一天的binlog。一周一备最坏情况就要应用一周的binlog了。但频繁全量备份需要消耗更多存储空间。
32. 为什么redo日志是两阶段提交的？
    - 因为不这么做会导致主从不一致。
    - 如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。MySQL 重启后，通过 redo log 能将 数据恢复，但是 binlog 里面没有记录这次，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这次更新，和主库不一致
    - 如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。那么主库就没有更新数据，而从库则更新了数据，同样造成了主从不一致。
33. 两阶段提交的具体过程
    - 两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是分别是「准备（Prepare）阶段」和「提交（Commit）阶段」
    - 准备阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；
    - 提交阶段：把 XID 写入到 binlog，然后将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit
34. 异常重启会出现什么现象？
    - 准备阶段后异常重启：已经 redo log，还没写入 binlog
    - 提交阶段中异常重启：已经写入 redo log 和 binlog，还没写入 commit 标识
    - MySQL 重启后会按顺序扫描 redo log 文件，以 binlog 写成功为事务提交成功的标识
      - 如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务。对应时刻 A 崩溃恢复的情况
      - 如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务。对应时刻 B 崩溃恢复的情况
35. 事务没提交的时候，redo log 会被持久化到磁盘吗？
    会的。
    - 事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。也就是说，事务没提交的时候，redo log 也是可能被持久化到磁盘的。
36. 如果 mysql 崩溃了，还没提交事务的 redo log 已经被持久化磁盘了，mysql 重启后，数据不就不一致了？
    - 放心，这种情况 mysql 重启会进行**回滚操作**，因为事务没提交的时候，**binlog 是还没持久化到磁盘的**。
    - 所以， redo log 可以在事务没提交之前持久化到磁盘，但是 binlog 必须在事务提交之后，才可以持久化到磁盘。
37. 两阶段提交有什么问题？
    性能差，通过组提交改善
    - **磁盘 I/O 次数高**
      - binlog 和 redo log 在内存中都对应的缓存空间，binlog 会缓存在 binlog cache，redo log 会缓存在 redo log buffer，它们持久化到磁盘的时机分别由下面这两个参数控制。一般我们为了避免日志丢失的风险，会将这两个参数设置为 1：
      - 当 sync_binlog = 1 的时候，表示每次提交事务都会将 binlog cache 里的 binlog 直接持久到磁盘；
      - 当 innodb_flush_log_at_trx_commit = 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘；
      - 可以看到，如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会至少调用 2 次刷盘操作，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈
    - **锁竞争激烈**
      - 两阶段提交虽然能够保证「单事务」两个日志的内容一致
      - 但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。在并发量较大的时候，就会导致对锁的争用，性能不佳。
38. 组提交
    - MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数
    - prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：
      - **flush 阶段**：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；
      - **sync 阶段**：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；
      - **commit 阶段**：各个事务按顺序做 InnoDB commit 操作；
      - 每个阶段都有一个队列，每个阶段有锁进行保护，因此保证了事务写入的顺序
39. 有 binlog 组提交，那有 redo log 组提交吗？
    - 要看 MySQL 版本，MySQL 5.6 没有 redo log 组提交，MySQL 5.7 有 redo log 组提交。
    - 在 MySQL 5.6 的组提交逻辑中，每个事务各自执行 prepare 阶段，也就是各自将 redo log 刷盘，这样就没办法对 redo log 进行组提交。
    - 所以在 MySQL 5.7 版本中，做了个改进，在 prepare 阶段不再让事务各自执行 redo log 刷盘操作，而是推迟到组提交的 flush 阶段，也就是说 **prepare 阶段融合在了 flush 阶段**
40. MySQL 磁盘 I/O 很高，有什么优化的方法？
    事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I/O 很高的现象，我们可以通过控制以下参数，来 **“延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I/O 的频率**：
    - 设置**组提交的两个参数**： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数
        延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也**没有丢失数据的风险**，因为 **binlog 早被写入到 page cache** 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。
    - 将 **sync_binlog** 设置为大于 1 的值（比较常见是 100~1000）
        表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。 
    - 将 **innodb_flush_log_at_trx_commit** 设置为 2。
        表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据。
#### 8. 内存
1. 说一说InnoDB的Buffer Pool（为什么要有 Buffer Pool？）
    MySQL 的数据是存储在磁盘里的，但如果每次查询都从磁盘中读取，性能极差。所以为了提升数据库的读写性能，**Innodb 存储引擎**设计了一个**缓冲池（Buffer Pool）**，当数据从磁盘中取出后，缓存内存中，下次查询同样的数据的时候，直接从内存中读取。
2. Buffer Pool是怎么提升读写性能的？
   - 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。
   - 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。
3. Buffer Pool 有多大？
   - Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 128MB 。
   - 可以通过调整 innodb_buffer_pool_size 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%
4. 为什么MySQL 刚启动的时候，使用的虚拟内存空间很大，而使用到的物理内存空间却很小？
    因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，接着将虚拟地址和物理地址建立映射关系。
5. Buffer Pool 缓存什么？
   - 缓存页，16KB.Buffer Pool 。除了缓存**索引页和数据页**，还包括了**undo页、锁信息**等等。
   - **控制块**，为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个控制块，控制块信息包括缓存页的表空间、页号、缓存页地址、链表节点等等。
   - 还有控制块与缓存页之间的碎片空间
6. 为什么会有碎片空间呢？
    分配完控制块和缓存页后剩余大小不够的空间就被称为了碎片空间
7. 查询一条记录，就只需要缓冲一条记录吗？
    当我们查询一条记录时，InnoDB 是会把**整个页的数据加载**到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。
8. Buffer Pool是如何管理缓存页的？
    Buffer Pool 采用三种页和链表来管理数据
   - **Free链表管理空闲页**
      - Free 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。避免了连续遍历来寻找空闲页。
      - 每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。
   - **Flush链表管理脏页**
      - Buffer bool为了提高数据库的写性能，更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为脏页，然后再由后台线程将脏页写入到磁盘。
      - Flush 链表和Free链表类似，每个节点也都是控制块，对应脏页
   - **LRU算法提高缓冲命中率**
      链表头部的节点是最近使用的，而链表末尾的节点是最久没被使用的。
      - 当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。
      - 当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。
   - **Free Page（空闲页）**，表示此页未被使用，位于 Free 链表；
   - **Clean Page（干净页）**，表示此页已被使用，但是页面未发生修改，位于LRU链表。
   - **Dirty Page（脏页）**，表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 LRU 链表和 Flush 链表。
9. 简单的LRU算法有什么问题？
   - **预读失效**
        MySQL 的预读机制会在加载数据页时，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。但这些被提前加载进来的数据页，并没有被访问，而且占用了LRU链表前排的位置，可能导致频繁访问的页被淘汰，降低了缓存命中率。
   - **Buffer Pool污染**
      - 当某一个SQL语句扫描了**大量的数据**时，如果Buffer Pool 空间有限，可能会将 Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 Buffer Pool 污染。
      - 同时即使查询出来的结果集很小也可能造成Buffer Pool 污染.比如**索引失效导致的全表扫描**会导致LRU young 区域的热点数据都会被替换掉
10. 怎么解决预读失效而导致缓存命中率降低的问题？
    将 LRU 划分了 2 个区域,前半部分为**young 区域, 后半部为old 区域**.预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。注意young里面的数据一直没有被访问时会被移到old区域.
11. 怎么解决出现 Buffer Pool 污染而导致缓存命中率下降的问题？
    - old区域中的页只有同时满足**被访问与在 old 区域停留时间超过 1 秒**两个条件，才会被插入到 young 区域头部,避免了young区域的页被频繁替换
    - 同时，为了防止 young 区域节点频繁移动到头部。**young 区域前面 1/4 被访问不会移动到链表头部**，只有后面的 3/4被访问了才会。
12. 脏页什么时候会被刷入磁盘？
    - 当 **redo log 日志满了**的情况下，会主动触发脏页刷新到磁盘；
    - **Buffer Pool 空间不足时**，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；
    - **MySQL 认为空闲时**，后台线程回定期将适量的脏页刷入到磁盘；
    - **MySQL 正常关闭之前**，会把所有的脏页刷入到磁盘；
13. 如果在脏页还没有来得及刷入到磁盘时，MySQL 宕机了，不就丢失数据了吗？
    InnoDB 的更新操作采用先写日志，再写入磁盘(WAL,  Write Ahead Log)，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。
14. 什么是checkpoint
    判断某些redo日志占用的磁盘空间是否可以覆盖的依据就是它对应的脏页是否已经刷新到磁盘里。如果一个页被刷新到了磁盘，那么其对应的redo日志就可以被覆盖了，此时会移动checkpoint,checkpoint后的redo日志就都可以被覆盖(通过LSN日志序列号判断).
15. 什么是数据库抖动?
    一般一条SQL执行的速度非常快, 但是有时候会执行很慢.这样的情况随机,持续时间短,且很难复现
16. 数据库抖动可能的原因是什么?
    - redo log 写满了，要 flush 脏页.有性能开销
    - 系统内存不足.需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。脏页刷盘就会给数据带来性能开销
17. 如何解决数据库抖动的问题?
    调大 Buffer Pool 空间或 redo log 日志的大小